[
    [
        {
            "section_number": 1,
            "title": "INTRODUCTION",
            "summary": "Explore how the dimensionality of phenotype space influences the complexity of coevolutionary dynamics and patterns of species diversity over evolutionary time, highlighting the transition from complex to simple dynamics as communities reach diversity saturation.",
            "target_length": 1200,
            "origin_content": "One of the fundamental problems in evolutionary biology is to understand how microevolutionary processes generate macroevolutionary patterns. In particular, the emergence of macroevolutionary changes in the speed of evolution <cit.>, and of macroevolutionary changes in patterns of species diversity <cit.> have long been of great interest. For example, <cit.> have recently proposed that over macroevolutionary time scales, relatively short intermittent bursts of high rates of evolutionary change should alternate with long periods of bounded phenotypic fluctuations.\nAlso, there is much discussion about whether species diversity saturates over evolutionary time in a given environment <cit.>. Phylogenetic analysis has been used to shed light on these questions <cit.>, but mechanistic models in which short-term ecological interactions are extrapolated to yield long-term patterns of diversity and evolutionary change have only recently been developed. Most of these models have been used to study the long-term evolution of diversity by analyzing processes of community assembly emerging from short-term ecological dynamics <cit.>.\nIn particular, these papers have mainly focussed on how diversity changes over time, but not on how the nature of the coevolutionary dynamics of a given set of coexisting species changes as the diversity changes. In fact, in all these models, the evolutionary dynamics for a fixed amount of diversity, i.e., for a given set of species, converge to an equilibrium. However, if one wants to understand macroevolutionary changes in the ‚Äútempo and mode‚Äù <cit.> of evolution, one not only needs to consider how diversity changes over evolutionary time, but also how such changes in diversity affect the nature of evolutionary dynamics <cit.>. Indeed, there is evidence from evolution experiments with microbes that evolutionary dynamics in more diverse communities are qualitatively different from the evolutionary dynamics in less diverse communities <cit.>. Here we present a theoretical investigation of the questions of how diversity affects the complexity of coevolutionary dynamics.\n\nIn general, the number of different phenotypes that affect ecological and evolutionary processes is an important quantity. For example,  determining the dimensionality of niche space in ecological food webs is a classical problem <cit.>, and it has recently been shown that including more phenotypic dimensions in models for community assembly has a strong effect on the structure of the emerging food webs <cit.>. Implicitly, the importance of the dimension of phenotype space is also acknowledged in phylogenetic research through the notion of ‚Äúadaptive zones‚Äù <cit.>. In particular, it is thought that much of the extant diversity has evolved as a consequence of lineages entering new adaptive zones, which can be interpreted from the phenotypic perspective as an increase in the dimension of phenotype space. In general, given the large number of phenotypic properties that determine an individual's life history and ecology in almost any species, one would expect that ecological interactions are generally determined by many phenotypic properties, and that selection pressures emerging from ecological interactions in turn affect many phenotypes simultaneously.\n\nFor example, comprehensive modelling of the metabolic network in E. coli cells comprises more than 2000 reactions <cit.>. These reactions are in turn controlled by thousands of genes in a complicated interaction network whose exact workings are largely unknown. Nevertheless, many of the genes contributing to this network of metabolic reactions will be under selection in any given environmental setting, and as a consequence, a large number of phenotypic properties have the potential to undergo evolutionary change. It is generally not known how exactly these phenotypic properties impinge on birth and death rates of individual organisms, and hence what exactly the ecological selection pressures are on these properties. Nevertheless, it seems clear that in general, many phenotypes will evolve at the same time, i.e., that evolution generally takes place in high-dimensional phenotype spaces.\n\nWe have recently argued that if evolution takes place in high-dimensional phenotype spaces, then the evolutionary dynamics, that is, the phenotypic change over evolutionary time, can be very complicated, i.e., non-stationary and often chaotic <cit.>. In low-dimensional phenotype spaces, non-equilibrium evolutionary dynamics are less likely. However, if a species evolving on a simple attractor gives rise to diversification, the effective  dimensionality of the evolving system increases, as the species that emerge from diversification coevolve, driven by both intra- and interspecific ecological interactions.\nThus the total dimensionality of the resulting dynamical system describing multispecies coevolution is the number of species times the dimensionality of the phenotype space in which each species evolves. Based on our earlier results <cit.>, one could then expect that due to the increase in dimensionality, diversification  leads to more complicated evolutionary dynamics in each of the coevolving species. On the other hand, as a multispecies community becomes more diverse and evolves towards saturation, the available niches tend to get filled, and hence evolutionary change has to become highly coordinated between interacting species and thus constrained, potentially leading to simplified evolutionary dynamics. It is thus unclear how the nature of the evolutionary dynamics changes as the pattern of diversity changes during community assembly.\n\nWe investigate these issues by applying the framework of adaptive dynamics <cit.>  to a general class of competition models. The main question we address is, how does the complexity of long-term coevolutionary dynamics depend on the diversity of the coevolving community? We show that in low-dimensional phenotype spaces, there is a humped-shaped relationship between diversity and the complexity of evolutionary dynamics: in communities with low diversity, coevolutionary dynamics are often simple, i.e., stationary in the long-time limit; for intermediate degrees of diversity, non-stationary (complex) coevolutionary dynamics are common, and each of the species in the community evolves on a complicated trajectory in phenotype space; and for high amounts of diversity, coevolutionary dynamics become simple again, i.e., stationary. In particular, as communities reach diversity saturation, e.g. through adaptive diversification <cit.>, coevolutionary dynamics change from complex to simple.\n\nOur results are relevant for a number of issues concerning patterns of macroevolution. For example, the results suggest that during processes of adaptive radiation <cit.>, evolutionary dynamics are more complicated early in the radiation than late in the radiation, a pattern that corresponds to the ‚Äúearly-burst‚Äù perspective of macroevolution that has attracted much attention in recent years <cit.>. Our results also show that the level at which diversity saturates depends on the dimensionality of phenotype space, with higher dimensions allowing for more diversity. This observation is in accordance with data from radiations in fishes <cit.> and points to the possibility of a microevolutionary mechanism for the ‚Äúblunderbass theory\" of temporal patterns of macroevolutionary changes and diversification <cit.>: if evolution operates on the dimension of phenotype space on a very slow time scale, then on shorter time scales diversity may saturate and thereby generate relatively stationary evolutionary dynamics, whereas on longer time scales the dimension of phenotype space may increase, e.g. due to gene duplications, thus generating a new burst of non-equilibrium (co-)evolutionary dynamics until the diversity reaches a new saturation level. Such patterns of intermittent bursts have recently been found in the phylogenies of birds and echinoids <cit.>, and the bursts have been attributed to the evolution of flight capabilities and of novel feeding techniques, respectively, both of which can be interpreted as an increase in the dimensionality of the relevant phenotype space. This perspective may also shed light on the question of whether diversity saturates or not <cit.>: diversity may saturate for a given dimension of phenotype space, but evolutionary innovation in the form of new phenotypic dimensions may intermittently generate room for additional bouts of evolutionary diversification.\n"
        },
        {
            "section_number": 2,
            "title": "METHODS",
            "summary": "Explain the methodology used to study the dynamics of diversification and coevolution in high-dimensional phenotype spaces, focusing on the adaptive dynamics models, competition kernels, and the numerical procedures implemented to simulate multi-cluster evolution.",
            "target_length": 3100,
            "origin_content": "¬ß.¬ß Single-cluster adaptive dynamics\n\nAs in <cit.>, we study a general class of models for frequency-dependent competition in which ecological interactions are determined by d-dimensional phenotypes, where d‚â•1.  For simplicity, we consider homogeneous systems, so no spatial coordinates are included.  The ecological interactions are described by a competition kernel Œ±(ùê±, ùê≤) and by a carrying capacity K(ùê±), where ùê±,ùê≤‚àà‚Ñù^d are the d-dimensional continuous phenotypes of competing individuals. The competition kernel Œ±  measures the  competitive impact that an individual of phenotype ùê± has on an individual of phenotype ùê≤, and we assume that  Œ±(ùê±, ùê±)=1 for all ùê±. Assuming logistic ecological dynamics, K(ùê±) is then the equilibrium density of a population that is monomorphic for phenotype ùê±. The adaptive dynamics of the phenotype ùê± is a system of differential equations for dùê±/dt. To derive the adaptive dynamics, one defines the invasion fitness f(ùê±, ùê≤) as the per capita growth rate of a rare mutant phenotype ùê≤ in the monomorphic resident ùê± population that is at its ecological equilibrium K(ùê±):\n\n\n    f(ùê±, ùê≤) = 1 - Œ±(ùê±, ùê≤) K(ùê±)/K(ùê≤).\n\n\nThe expression for the invasion fitness reflects the fact that the growth rate of the mutant ùê≤ is negatively affected by the effective density experienced by the mutant, Œ±(ùê±, ùê≤) K(ùê±), discounted by the carrying capacity K(ùê≤) of the mutant (see <cit.> for more details).  Note that f(ùê±, ùê±)=0 for all ùê±. The invasion fitness f(ùê±, ùê≤) gives rise to the selection gradients in the i=1,...,d phenotypic components:\n\n\n    s_i(ùê±) ‚â°‚àÇ f(ùê±, ùê≤)/‚àÇ y_i |_ùê≤=ùê± =  - ‚àÇŒ±(ùê±, ùê≤)/‚àÇ y_i |_ùê≤=ùê± + ‚àÇ K(ùê±)/‚àÇ x_i1/K(ùê±),\n\n\nThe selection gradients in turn define the adaptive dynamics as a system of differential equations on phenotype space ‚Ñù^d, which is given by\n\n\n    dùê±/dt = ùêå(ùê±)¬∑ùê¨(ùê±).\n\n\nHere ùê¨(ùê±) is the column vector (s_1(ùê±),...,s_d(ùê±)), and ùêå(ùê±) is the mutational variance-covariance matrix. In this matrix, the diagonal elements contain information about the size and rate of mutations in each of the phenotypic dimensions, whereas the off-diagonal elements contain information about the covariance between mutations in two different phenotypic dimensions. This matrix essentially captures ‚Äúevolvability‚Äù of a population and  generally depends on the current resident phenotype ùê±, and influences the speed and direction of evolution. For simplicity, we assume here that this matrix is the identity matrix. For more details on the derivation of the adaptive dynamics (<ref>) we refer to a large body of primary literature (e.g. <cit.>). We note that the adaptive dynamics (<ref>) can be derived analytically as a large-population limit  of an underlying stochastic, individual-based model that is again defined based on the competition kernel Œ±(ùê±, ùê≤) and the carrying capacity K(ùê±) <cit.>.\n\n\nSpecifically, here we consider a class of systems that are defined by competition kernels of the form\n\n\n    (ùê±,ùê≤)=exp [‚àë_i,j=1^d\n    b_ij(x_i-y_i)x_j\n    -‚àë_i=1^d(x_i-y_i)^2/2_i^2].\n\n\nHere the coefficients b_ij in the first sum on the right hand side are arbitrary and correspond to the simplest form of a generic, non-symmetric competition kernel that can generate non-stationary evolutionary dynamics. It can be interpreted as the lowest-order (non-trivial) term from a Taylor expansion of an unknown non-symmetric competition function. Adaptive dynamics of asymmetric competition has been studied quite extensively (e.g. <cit.>), and is necessary to generate single-species non-equilibrium dynamics in high-dimensional phenotype spaces <cit.>.\nThe second sum on the right hand side represents ‚ÄúGaussian competition‚Äù, according to which the competitive impact between individuals increases with phenotypic similarity between the competing individuals. The parameters _i measure how fast the effect of competition declines as phenotypic distance in the i-component increases. For the carrying capacity we assume\n\n\n    K(ùê±)=exp(-‚àë_i^d x_i^4/4).\n\n\nThis implies that the carrying capacity imposes an element of stabilizing selection for the phenotype ùê±=0, at which the carrying capacity is maximal. Thus, the frequency-dependent component of selection is generated by the competition kernel, whereas the frequency-independent component of selection is due to the carrying capacity. With these assumptions, the adaptive dynamics (<ref>) become\n\n\n    d x_i/dt=‚àë_i=1^d b_ijx_j - x_i^3,    i=1,...,d.\n\n\nWe note that  the terms -x_i^3 in (<ref>) are due to the carrying capacity and serve to contain the trajectories of (<ref>) in a bounded domain of phenotype space. Also, the Gaussian part of the competition kernel does not affect the adaptive dynamics of monomorphic populations, i.e., the _i do not appear in (<ref>), because the Gaussian part always has a maximum at the current resident, and hence the corresponding first derivative in the selection gradient (<ref>) is 0.\n\nThe system of ODEs  (<ref>) describes the trajectory of an evolving monomorphic population in phenotype space ‚Ñù^d. In <cit.> we have shown that for general competition kernels  such trajectories can be very complicated, particularly when the dimension d is large. With complex evolutionary dynamics, trajectories can be quasi-periodic or chaotic, and typically visit many different regions of phenotype space over evolutionary time. When d is low the dynamics tend to be simpler, and often converge to an equilibrium attractor.  We can assess the likelihood of equilibrium dynamics for a given dimension d by choosing the d^2 coefficients  b_ij in (<ref>) randomly and independently, e.g. from a normal distribution with mean 0 and variance 1, solving the resulting adaptive dynamics (<ref>) and checking whether it converges to an equilibrium. If this is done repeatedly, we can approximate the probability of equilibrium dynamics as the fraction of runs that converged to an equilibrium. For d=1 the probability of equilibrium dynamics is of course 1, and for d=2,3,4, the resulting probabilities of equilibrium dynamics are approximately 85%, 81% and 74%, respectively. These are the dimensions that we will primarily use in the analysis presented below, but we note that the probability of equilibrium dynamics goes to 0 for large d <cit.>.\n\n\n\n ¬ß.¬ß Multi-cluster adaptive dynamics\n\nHere we are interested in the question of how diversification and subsequent coexistence of species (also called phenotypic clusters or simply clusters through the text) affects the evolutionary dynamics. While the Gaussian term in the competition kernel (<ref>) does not affect the adaptive dynamics of single monomorphic populations, this term is crucial for determining whether evolutionary diversification occurs. For one-dimensional phenotype spaces (d=1) this is very well known and is encapsulated in the concept of evolutionary branching <cit.>. An evolutionary branching point is an equilibrium point of (<ref>) that is both an attractor for the adaptive dynamics and a fitness minimum. The reason that such points exist in the competition models considered here is precisely that the Gaussian term does not affect the adaptive dynamics, but does affect the curvature of the fitness landscape, i.e., the second derivative of the invasion fitness (<ref>). In particular, small enough _i's in the Gaussian term will make any equilibrium point a fitness minimum, and hence will give rise to evolutionary diversification. Evolutionary branching in scalar traits has been described in a plethora of different models (for an overview we refer to Eva Kisdi's website at the Department of Mathematics and Statistics at the University of Helsinki, http://www.mv.helsinki.fi/home/kisdi/addyn.htm). In high-dimensional phenotype spaces, equilibrium points of (<ref>) can also be fitness minima along some directions in phenotype space. For this to happen the Hessian matrix of second derivatives of the invasion fitness (<ref>), evaluated at the equilibrium, must have positive eigenvalues. Indeed, in higher dimensional phenotype spaces the conditions for the existence of positive eigenvalues of this Hessian matrix, and hence for diversification, generally become less stringent <cit.>.\n\nImportantly, evolutionary diversification can also occur from non-equilibrium adaptive dynamics trajectories <cit.>. If the adaptive dynamics (<ref>) exhibit non-equilibrium dynamics, the crucial quantity determining whether diversification occurs is again the Hessian matrix of second derivatives of the invasion fitness (<ref>), but now restricted to the subspace of phenotype space that is orthogonal to the selection gradient <cit.>. Essentially, diversification can occur in orthogonal directions in which this Hessian has positive curvature, and hence in which the invasion fitness has a minimum. Because the population is still evolving along the selection gradient, elucidating the exact conditions for diversification requires a careful analysis <cit.>. In the present context, the implication of these results is that, just as with equilibrium adaptive dynamics, diversification can occur along non-equilibrium trajectories of (<ref>) if the _i in the Gaussian term of the competition kernel are small enough, i.e., if the frequency dependence generated by Gaussian competition is strong enough <cit.>.\n\nTo investigate the process of diversification and the subsequent coevolutionary dynamics, we extend the adaptive dynamics (<ref>) to several coexisting phenotypic clusters as follows. We assume that an evolving community consists of m monomorphic populations, each given by a phenotype ùê±_r, r=1,...,m, with phenotypic components x_ri, i=1,...d (where d is the dimension of phenotype space). Let N_r be the population density of cluster ùê±_r. Then the ecological dynamics of the m clusters are given by the system of logistic differential equations\n\n\n    d N_r(t)/ d t = N_r( t)( 1 - ‚àë_s=1^m (ùê±_s, ùê±_r) N_s ( t)/K(ùê±_r)),    r=1,...,m.\n\n\nLet N_r^*, r=1,...,m denote the equilibrium of system (<ref>) (more generally, for the purposes of deriving the adaptive dynamics, the quantities N_r^* are suitable time averages of population densities over the ecological attractor of (<ref>); however, our extensive numerical simulations indicated that (<ref>) always converges to an equilibrium). Making the traditional adaptive dynamics assumption that ecological dynamics occur on a faster time scale than evolutionary dynamics, we calculate the invasion fitness function in cluster r based on the densities N_r^* of the various clusters:\n\n\n    f(ùê±_1,...,ùê±_m,ùê±_r')=1 - ‚àë_s=1^m (ùê±_s,ùê±_r')N_s^*/K(ùê±_r').\n\n\nHere ùê±_1,...,ùê±_m describe the phenotypic state of the resident population, and ùê±_r' denotes the mutant trait in cluster r, r=1,...,m.\n\nTaking the derivative of (<ref>) with respect to ùê±_r' and\nevaluating it at the resident, ùê±_r'=ùê±_r, yields the components of the selection gradient ùê¨_r for the cluster r as:\n\n\n    s_ri= ‚àë_sN_s^*(-  1/K(ùê±_r).‚àÇ(ùê±_s,ùê±_r')/‚àÇ\n         x_ri'|_ùê±_r'=ùê±_r +\n     (ùê±_s,ùê±_r)/K^2(ùê±_r)‚àÇ\n       K(ùê±_r)/‚àÇ x_ri),    i=1,...,d.\n\n\nFor coevolutionary adaptive dynamics, one has to take into account that the rate of mutations in each evolving phenotypic cluster is proportional to the current population size of that cluster <cit.>, and hence that the speed of evolution is influenced by the population size. In the single-cluster system such consideration only rescales time without affecting the geometry of the trajectory and thus is usually ignored. However, in the multi-cluster system, instead of assuming that the mutational process is described by the identity matrix as in (<ref>), we now assume that in each cluster r, the mutational variance-covariance matrix M_r is a diagonal matrix with entries N_r^*. This generates the following d¬∑ m differential equations describing the adaptive dynamics in the coevolving community:\n\n\n    d x_ri/dt= N_r^* s_ri,   i=1,‚Ä¶,d,   r=1,‚Ä¶, m.\n\n\nFor the multicluster adaptive dynamics, the equation (<ref>,<ref>,<ref>) replace  their single-cluster analogs (<ref>,<ref>,<ref>).\nIt is important to note that the Gaussian part of the competition kernel  not only affects whether diversification occurs, but in contrast to the adaptive dynamics of single monomorphic populations, the Gaussian term will indeed affect the coevolutionary adaptive dynamics (<ref>) of the phenotypic clusters that coexist after diversification has occurred, because it affects both the ecological dynamics (<ref>) and the selection gradient (<ref>).\n\n\n\n ¬ß.¬ß Numerical procedure\n\nTo study diversification and subsequent multi-cluster adaptive dynamics, we\nimplemented the following iterative numerical scenario:\n\n0.5 cm\nStep 1: Each simulation run is initiated with a randomly generated\nd √ó d matrix of the coefficients  b_ij for\nthe competition kernel (<ref>). The coefficients are drawn from a\nGaussian distribution with zero mean and d^-1/2 variance. As\nexplained in <cit.>, this is done to keep the sum of the d terms\n‚àë_j=1^d b_ij x_j in (<ref>) of order  x_i, i.e. independent of d.\nThen a certain number of clusters, given by a parameter m_0, each with population size of order 1, are randomly placed\n near the phenotype 0, i.e., near the maximum of the carrying capacity.\n\n0.5 cm\nStep 2: For a given set of phenotypic clusters, the population dynamics of all clusters is solved using the ecological dynamics (<ref>). The system of differential equations is integrated using a\n  4th-order Runge-Kutta algorithm for ‚àº 10^3 time steps of duration dt ‚àº 10^-2 to ensure convergence\n  to the equilibrium (or, in case there is no such convergence, to ensure a correct calculation of the time average of the various population\ndensities). If the population density of a given\n  cluster falls below the threshold N_min‚àº10^-8, the\n  cluster is eliminated from the system. During the ecological\n  dynamics the evolutionary dynamics is frozen and evolutionary\n  time does not advance.\n\n0.5 cm\nStep 3: After calculating the N_r^*, r=1,...,m (where m is the current number of clusters), the adaptive dynamics of the phenotypes of the clusters is advanced via\n  (<ref>,<ref>) using a 4th-order Runge-Kutta algorithm with a typical\n  time-step d‚àº 10^-2, by which the evolutionary time is\n  advanced as well. After this evolutionary time step, the ecological dynamics are recalculated, potentially preceded by the following step 4, which is only performed if the corresponding time condition is satisfied.\n\n0.5 cm\nStep 4: The level of diversity, i.e., the number of clusters in the system, is controlled as follows. Each _c time units the distances between clusters are assessed.\n  If the distance between two or more clusters is below a\n  threshold\nx ‚àº 10^-3, these\n  clusters are merged, preserving the total population size of the merged clusters and the position of their centre of mass.  Immediately after this comparison step, the total number of\n  clusters is compared to the target number of clusters, which is given by a system parameter m_max. If the current number of clusters is below m_max, a new\n  cluster is created by randomly picking an existing cluster,\n  splitting it in half and separating the two new clusters in a random direction in phenotype space by\n   the distance  of the merging threshold, x.\n\n0.5 cm\nStep 5: In our simulations, we take measurements at regular time intervals (ranging from _m‚àº 1 - 10 time units). One of the main quantities of interest is the average per capita evolutionary speed v in the evolving community,  which is the average of the norms of the vectors of trait variation (evolution) rates in each cluster, weighted by the cluster\npopulation size,  computed as\n\n    v=‚àë_r=1^mN_r‚àö(‚àë_i=1^d (d x_ri/dt)^2)/‚àë_r=1^m N_r\n\nThis quantity is a strong indicator of the nature of the evolutionary dynamics of the coevolving system. In particular, our very extensive numerical simulations indicate that when the average speed falls below 10^-2, then the system eventually exhibits equilibrium evolutionary dynamics. In contrast, when the average evolutionary speed remains high, the coevolving system tends to exhibit complicated, non-equilibrium dynamics, with the majority of the clusters exhibiting large fluctuations in phenotype space over evolutionary time. An example of such non-equilibrium coevolution is given in the next section. Other measurements include\n  the position and population size of all clusters in the system,\n and the number of ‚Äúdistinct‚Äù clusters\nseparated by a ‚Äúvisible‚Äù distance X=0.1. These measurements can also be averaged over time.\n\n1cm\nFor any given simulation run initiated by step 1 above, steps 2-5 were repeated iteratively until a specified final simulation time is reached, or until evolution comes to a halt, which by our definition occurs when the average evolutionary speed falls below a threshold, v<10^-4.\nOur general approach consisted of simulating many different systems according to the above scheme, and then computing statistical characteristics such as the fraction of runs that result in non-equilibrium dynamics, or the average evolutionary speed as a function of the level of diversity (see Results section).\n\nOne crucial feature of our algorithm is the periodic generation of new clusters in step 4, which mimics diversification events, i.e., evolutionary branching. Diversification is thus modeled by simply adding new phenotypic clusters at certain points in time and close to existing clusters. This mimics the sympatric split of an ancestral lineage. Sympatric diversification is a theoretically robust phenomenon <cit.> and our procedure represents a shortcut for this phenomenon necessitated by computational feasibility. If such splitting is not feasible given the current ecological circumstance, the new cluster will not diverge phenotypically from the ancestor, and hence will be merged again with the ancestor (see below). Alternatively, newly generated clusters may go extinct ecologically. In either case, speciation was not successful. Thus, in our models it is the ecological circumstances that determine whether speciation can occur or not, but the process of speciation itself (i.e., the splitting) is performed in a simplified manner. If speciation is successful and the newly generated clusters diverge and persist ecologically, then diversity has increased (unless other clusters go extinct). We note that by construction, the maximal level of diversity in a given simulation run, i.e., the number of different clusters, cannot exceed the parameter m_max. Therefore, this parameter allows us to control the level of diversity in a given simulation.\n\nThere are in principle other, less artificial ways to model diversification. In particular, stochastic, individual-based based models and partial differential equation models <cit.> have been used to describe the evolutionary dynamics of phenotype distributions. In such models, diversification is an emergent property that is reflected in the formation of new modes in the evolving phenotype distributions. While these techniques are very useful in general, they are currently not computationally feasible for the statistical approach that we employed here, which requires systematic simulation of many different systems. Also, they would not allow for control of the level of diversity, as the number of phenotypic modes would simply be an emergent property of the evolving system. Nevertheless, we have used these alternative techniques to illustrate the robustness of salient results using particular examples. A more detailed description of these techniques is given in the  Appendix. Another alternative would be to assume that new clusters (species) are assigned phenotypes that are chosen randomly in phenotype space, rather than close to an existing cluster. This could correspond to immigration of new species into an existing community. However, we would not expect this to affect our main results, because with complicated evolutionary dynamics, the initial phenotypic position of a given cluster becomes irrelevant after some time.\n\nFinally, we note that the merging of clusters (species) is done solely for computational reasons and has no biological meaning (apart from designating organisms that are closely related and phenotypically very close as belonging to the same species). Merging of clusters only occurs shortly after a new cluster is seeded close to an existing one, and only if the new cluster does not diverge from the existing one (i.e., only if the ecological conditions for diversification are not satisfied). If divergence is successful, the clusters will never again get close enough to other clusters to be merged because of the repelling force of frequency-dependent competition. Thus, the only function of merging is to prevent the number of clusters from artificially becoming very large.\n"
        },
        {
            "section_number": 3,
            "title": "RESULTS",
            "summary": "Discuss the effects of varying levels of diversity on the coevolutionary dynamics of phenotypic clusters in high-dimensional phenotype spaces, highlighting the relationship between diversity constraints, evolutionary speed, and equilibrium dynamics, supported by simulation results and figures.",
            "target_length": 1300,
            "origin_content": "The parameter that controls the level of diversity in our simulations is m_max, which is the maximal number of different phenotypic clusters allowed to be present at any point in time in an evolving community (see step 4 in the Methods section). Our first result is obtained by allowing this parameter to be very large, so that we can estimate the number of clusters that eventually coexist by simply running the simulations for a long time and recording the number of clusters at which the diversity equilibrates.  We denote by M_,d the equilibrium number of clusters for a given phenotypic dimension d and strength of the Gaussian component  in the competition kernel (<ref>).  We found that such equilibrium level of diversity increases exponentially with  the dimension d of phenotype space, and decreases with the strength   (Figure 1).\nHere and below we assume for simplicity that the _i are the same in all phenotypic directions, _i= for i=1,...,d. In the  Appendix we indicate scaling relationships that hold for M_,d as functions of the parameters  and d. In general, diversity is only maintained if ‚â≤1, which is roughly the scale of the phenotypic range set by the carrying capacity (<ref>). Only if ‚â≤1, the equilibrium level of diversity increases exponentially with increasing dimension of phenotype space, Figure 1.\n\n\n\nOur main results are now obtained based on the observation that by fixing the parameter m_max at a value ‚â§ M_,d for a given d and , the community will typically evolve to a diversity level m_cluster of approximately m_max. That is, if the diversity is constrained to be below the maximal level of diversity possible for a given set of parameters, then the diversity will typically evolve to the value set by the constraint. Note that this is an ‚Äúaverage‚Äù statement about many simulations runs, i.e., many different choices of the coefficients b_ij and stochastic realizations of cluster splitting. While some simulation runs will result in a diversity that is lower than m_max (which may reflect an intrinsic state of the system for the given set of coefficients, or a long-living metastable state which has not yet reached its full diversity), most runs will evolve to the level of diversity that is prescribed by this parameter.\n\nThis allows us to then assess, for a given level of diversity, the nature of the coevolutionary dynamics that unfolds in communities with that level of diversity. Two paradigmatic examples are shown in Figure¬†2. We first set the level of diversity  m_max=12, which is far below the saturation level M_œÉ,d for the given system. Starting from very few clusters the diversity quickly evolves to the level set by m_max, and the coexisting clusters then exhibit complicated, non-stationary evolutionary dynamics, with all clusters undergoing sustained and irregular fluctuations in phenotype space (Fig.¬†2a). This type of complicated dynamics is characterized by average evolutionary speeds v>10^-2. In the same system, but now with a value of m_max that lies above the saturation level M_œÉ,d, the diversity evolves to the saturation level, at which the community consists of ca. 30 coexisting phenotypic clusters (Fig.¬†2b). In this saturated state, the average evolutionary speed is much lower than 10^-2, and the community exhibits much more stationary coevolutionary dynamics (that would eventually converge to a coevolutionary equilibrium). Moreover, the saturated community exhibits a characteristic pattern of over-dispersion in phenotype space due to competitive repulsion caused by the Gaussian component of the competition kernel (see also Fig. A1 in the Appendix).\n\nTo obtain a more systematic characterization of the coevolutionary dynamics as a function of the diversity of the evolving community, we ran, for a given dimension of phenotype space d and strength of competition , 100 simulations with randomly chosen coefficients b_ij for each m_max=1,...,M, where M is some number that is larger than the saturation level of diversity M_,d. For each run, we recorded the average per capita evolutionary speed v and the number of phenotypic clusters, i.e., the level of diversity, present at the end of 1000 evolutionary time units (averaged over the last 4 time units). We classified the dynamics into equilibrium dynamics if the average speed v was <10^-2, and non-equilibrium dynamics otherwise. As mentioned earlier, this was based on individual inspection of many simulation that ran longer than 1000 time units, which showed that the threshold 10^-2 is a very good indicator of whether the coevolutionary system eventually equilibrates.\n\n\n\n\nOur main results are shown in Figures 3 and 4. The general pattern is that the probability of non-equilibrium dynamics increases as diversity increases from single-cluster communities to communities with a few clusters (Figure 3).\nFor intermediate diversity, the fraction of non-equilibrium dynamics remains high. For communities with high diversity, the fraction of non-equilibrium dynamics starts to decrease, and almost almost all communities with a diversity close to the saturation level M_,d  exhibit equilibrium coevolutionary dynamics.\nTo illustrates these trends, we  give a more detailed account of the average velocities v defined in (<ref>) in the coevolving communities (Fig.¬†4). It shows that there is an exponential decrease in the average speed as the diversity increases, and that there is a substantial fraction of low-diversity communities that exhibit equilibrium dynamics.\nThe exact shape of these patterns depends on d and  (Figures 3 and 4), but whenever diversification is possible, the overall trend is that non-equilibrium dynamics are most likely at intermediate levels of diversity, and that high levels of diversity tend to generate equilibrium coevolutionary dynamics.\n\n\n\n\n\nThe patterns shown in Figs.¬†3 and 4 are based on many different simulated communities with different levels of diversity. However, similar patterns can be observed in simulations of single communities as they evolve from low to high diversity, i.e., as they undergo an adaptive radiation. Such a radiation, starting from a single phenotypic cluster, is shown in Fig.¬†5A.\nOver time the evolving community becomes more diverse due to adaptive diversification, and as a consequence the nature of the coevolutionary dynamics of the community changes. In the example shown in Figure 5A, the coevolutionary dynamics are fast for low to intermediate levels diversity, and then slow down as the community acquires more and more species, until eventually the community reaches a coevolutionary equilibrium at the diversity saturation level. Again, the slowdown of the evolutionary speed during an adaptive radiation appears to occur exponentially with an increase in diversity. This can also be seen by running a given community defined by a given set of coefficients b_ij for different values of the parameter m_max, determining the level of diversity possible in the evolving community. The evolutionary speed exponentially decreases with the diversity given by m_max (Fig.¬†5B). We currently do not have a mechanistic explanation for the exponential decay in evolutionary rates with increasing diversity. It is informative to watch the process of diversification and subsequent evolutionary slowdown unfold dynamically. To verify that the observed dynamical pattern is not an artifact of the adaptive dynamics approximation, we performed the individual-based and partial differential equation simulations of the same system. The movies in Videos in the Appendix, corresponding to the scenario used for Figures¬†2B and 5A, confirm that all three methods produce qualitatively similar evolutionary pictures. The detailed descriptions of the individual-based and partial differential equation methods are given in the  Appendix.\n\nAnother interesting, although perhaps not so surprising observation for single adaptive radiations concerns the rate of accumulation of new species in the evolving ecosystem. Figure 5C shows the number of species as a function of time during the adaptive radiation scenario used for Figure 5A, illustrating that the rate of diversification is highest at the beginning of the radiation, and then slows down as the community evolves towards the diversity saturation level. The details of these dynamics depend on system parameters, and in particular on the rate at which new species are introduced into the system, but the qualitative behaviour of diversification rates, which are initially high and then slow down, is common to all adaptive radiations generated by our models.\n"
        },
        {
            "section_number": 4,
            "title": "DISCUSSION",
            "summary": "Discuss the implications of our findings on coevolutionary dynamics and diversity saturation in high-dimensional phenotype spaces, highlighting the effects on evolutionary complexity, the relevance of phylogenetic relationships, and the potential for adaptive radiations, while acknowledging the limitations and future directions for research.",
            "target_length": 3200,
            "origin_content": "We investigated the expected long-term evolutionary dynamics resulting from competition for resources in models for gradual evolution in high-dimensional phenotype spaces. In reality, most organisms have many different phenotypic properties that impinge on their ecological interactions in generally complicated ways, and here we assumed that multi-dimensional phenotypes determine logistic ecological dynamics through the competition kernel and the carrying capacity. We then used a coevolutionary adaptive dynamics algorithm to extend the ecological dynamics to macroevolutionary time scales, and we used a statistical approach to capture general properties of the ensuing evolutionary dynamics.\n\nIf the negative frequency-dependence generated by the competition kernel is strong enough, competition results in repeated adaptive diversification, and hence in communities of coevolving phenotypic species. By randomly choosing many different competition kernels, we showed that the complexity of the coevolutionary dynamics in such communities is expected to be highest for intermediate levels of phenotypic diversity. In particular, as the evolving communities increase in diversity towards the saturation level, i.e., the maximal number of different species that can coexist, the evolutionary dynamics becomes simpler, and communities at the saturation level are expected to exhibit a coevolutionary equilibrium. We also showed that the diversity saturation level increases exponentially with the dimension of phenotype space.\n\n\nWe have used a statistical approach to determine the expected long-term evolutionary dynamics resulting from competition for resources. We have assumed that multi-dimensional phenotypes determine logistic ecological dynamics through the competition kernel and the carrying capacity, and we then used a coevolutionary adaptive dynamics algorithm to extend the ecological dynamics to macroevolutionary time scales.\nIf the negative frequency-dependence generated by the competition kernel is strong enough, competition results in repeated adaptive diversification, and hence in communities of coevolving phenotypic species. By randomly choosing many different competition kernels, we showed that the complexity of the coevolutionary dynamics in such communities is expected to be highest for intermediate levels of phenotypic diversity. In particular, as the evolving communities increase in diversity towards the saturation level, i.e., the maximal number of different species that can coexist, the evolutionary dynamics becomes simpler, and communities at the saturation level are expected to exhibit a coevolutionary equilibrium. We also showed that the diversity saturation level increases exponentially with the dimension of phenotype space.\n\nOur interpretation of these findings is that in low-dimensional phenotype spaces such as the ones considered here, evolutionary dynamics of single species are expected to converge to an equilibrium <cit.>. However, as diversity increases, the different phenotypic clusters will ‚Äúpush‚Äù each other around evolutionarily due to frequency-dependent competition. This occurs mostly due to the repulsive nature of pairwise interaction induced by the Gaussian term in the competition kernel (<ref>): clusters that move further apart decrease competition felt from each other. For example,  a splitting of a cluster stuck in an attractive fixed point of the adaptive dynamics creates two offspring which may become moving again if the repulsion between clusters is stronger than the attraction of the fixed point.  As long as diversity is not very high, i.e., as long as there is enough available niche or unoccupied phenotype space, this typically results in non-equilibrium coevolutionary dynamics, thus leading to an increase in evolutionary complexity with phenotypic diversity. As the diversity keeps increasing towards saturation levels, which for each phenotypic dimension is  determined roughly by the ratio of the widths of the carrying capacity and the competition kernel (see Video 2), the available carrying capacity niche gets filled, so that the evolving clusters ‚Äúhave nowhere to go‚Äù evolutionarily. An analogy with gas-liquid-solid phase transitions may illustrate this in the following way: As in the dynamics of molecules, the adaptive dynamics of phenotypic clusters contains a pairwise-repulsive term, which originates from the Gaussian term in the competition kernel. A few-cluster regime qualitatively corresponds to the gas phase, when the range of the repulsive interaction is significantly less than the typical distance between clusters. As the number and thus density of clusters increases, the repulsive interaction becomes more relevant, constraining the individual motion of clusters and resulting in a liquid-like behaviour, where clusters are predominantly localized and occasionally hop to a new location. Finally, the maximum cluster density creates a crystal-like structure, albeit not necessarily entirely symmetric due to the randomly generated b_ij terms in the adaptive dynamics.  The motion of individual clusters is heavily constrained by its neighbours via mutual repulsion, while the collective motion of an ensemble of clusters is limited by the carrying capacity function.\nThus, phenotypic saturation leads to a state in which the coevolving clusters are strongly constrained evolutionarily by the other clusters in the community, and hence to coevolutionary equilibrium dynamics.\n\nSome empirical support for an initial increase in the complexity of evolutionary dynamics with the number of species in an ecosystem comes from the laboratory evolution experiments of <cit.>, who showed that the speed of adaptation to novel environments is higher in bacterial species that are part of microbial communities with a small number of competitors than when evolving in monoculture. However, our results are seemingly in contrast to previous theoretical results about the effect of diversity on evolutionary dynamics <cit.>. These authors essentially argued that while a single species is free to evolve in response to changes in the environment, evolution of the same species is more constrained in a community of competitors, in which other species are more likely to evolutionarily occupy new niches. Hence diversity is expected to slow down evolution.  However, these models only describe evolution in 1-dimensional phenotypes, and may thus miss the complexity arising in higher-dimensional spaces. Moreover, even in higher-dimensional spaces, the arguments for evolutionary slowdown presented in <cit.> essentially correspond to our observation of a slow-down when diversity reaches saturation, at which point evolutionary change in each species is indeed constrained due to competing species occupying all available niches. Our approach also needs to be distinguished from approaches based primarily on ecological dynamics, as in <cit.>. In these approaches, emerging ecological communities are also modelled by periodically adding new species, but there is no underlying phenotype space that would determine competitive interactions. Instead, every time a new species added, its interaction coefficients with the already existing species are chosen according to a specific, randomized procedure. This leads to interesting results, such as saturating levels of diversity after initially fast and fluctuating increases from low levels of diversity. However, since there is no underlying phenotype space, this approach does not reveal the evolutionary dynamics of continuous phenotypes, and in particular, it does not yield any information about the effects of the dimension of phenotype space on the evolutionary dynamics or on the amount of diversity at saturation.\n\nThere has been much interest in recent years in determining the effects of phylogenetic relationships on the functioning of ecosystems (e.g. <cit.>). The intuitive notion is that phylogenetic information has predictive power for ecological interactions if recently diverged species are more likely to interact than those that diverged long ago. More specifically, <cit.> have argued that phylogenetic information is most likely to be relevant for ecosystem dynamics if ecological interactions are based on phenotypic matching, so that species with more similar trait values are more likely to interact strongly. Our models have a component of phenotypic matching due to the Gaussian part of the competition kernel, but they also have a strong component of different types of interactions due to the ‚Äúrandom‚Äù part of the competition kernel given by the coefficients b_ij. As we have shown, it is this non-Gaussian part of the competition kernel that causes the complicated coevolutionary dynamics, and it is this complexity in turn that makes phylogenetic signal largely irrelevant in our models.\n\nA full phylogenetic analysis of the macroevolutionary dynamics generated by our models is beyond the scope of this work, but we can provide some basic insights based on the complicated evolutionary dynamics in phenotype space that the different phenotypic clusters (species) perform when there is an intermediate number of clusters in the coevolving community. An example of this is shown in the movie in Figure A1A. Here, after an initial phase of diversification, the community contains 12 coevolving clusters. These clusters move on a complicated evolutionary trajectory, with each cluster undergoing large evolutionary changes without further diversification. No matter what the phylogenetic relationship between these clusters (as given by their emergence from the single initial cluster), it is clear that because of the large evolutionary fluctuations in phenotype space of each cluster (species), there will be no consistent correlation between phylogenetic relationship and phenotypic distance. Even if there were such a correlation (positive or negative) at a particular point in time, it would change over time due to the large evolutionary fluctuations of each cluster over time. This is illustrated in Figure A1B, which shows  that no persistent correlation pattern between phylogenetic and phenotypic distance should be expected in communities with an intermediate amount of diversity. In particular, recently diverged species are not more likely to interact than those diverged less recently, because the evolving community has a short ‚Äúphenotypic memory‚Äù due to complicated evolutionary dynamics.\n\nHowever, when further diversification is allowed, so that the system reaches its saturation level of diversity, the coevolving community not only becomes more diverse, but the evolutionary dynamics slows down, leading to ever smaller phenotypic fluctuations. In particular, new clusters emerging towards the end of the assembly of the evolutionarily stable community will stay phenotypically closer to their phylogenetically most closely related clusters, i.e., to their parent or sister species. Therefore, in the last phase of community assembly a positive correlation between phylogenetic and phenotypic distance can be expected to build up at least to some extent. This is illustrated in Figure A1B. Thus, weak phylogenetic signals are expected to develop towards the end of community assembly.\n\nRegarding adaptive radiations, two observations emerge from our models. The first concerns the classical notion that rates of diversification should decline over the course of a radiation <cit.>, a pattern that seems to have good empirical support <cit.>. Our models confirm this pattern of declining rates of diversification (Figure 5).  The second observation is that rates of evolution should generally slow down with an increase in diversity. This should not only be true when different ecosystems are compared (Figures 3,4), but also during an adaptive radiation in a single evolving community (Figure 5). Thus, we would expect the evolutionary dynamics to be faster and more complicated early in an adaptive radiation, and to slow down and eventually equilibrate late in the radiation. This corresponds to the so-called ‚Äúearly-burst‚Äù model of macroevolution <cit.> in the context of adaptive radiations. This model predicts that when lineages enter novel ‚Äúadaptive zones‚Äù  <cit.>, such as novel ecological niches, evolutionary rates in the lineage should be fast initially and then slow down as the adaptive zone gets filled with diverse phenotypes. <cit.> found little evidence for the early-burst model when analyzing a large set of data from many different clades. Nevertheless, these authors noted that younger clades have higher rates of evolution than older clades, which points to the fact that evolutionary rates may slow down with clade age. Moreover, few clades in their data set correspond to the type of very fast adaptive radiation envisaged and observed in our models, and they did not consider high-dimensional phenotypes. Finally, <cit.> note that groups with a larger proportion of sympatric species early in their history would be more likely to exhibit an early-burst pattern. In our models, adaptive radiations occur in complete sympatry and indeed produce the early burst pattern.\n\nAccording to <cit.>, the jury on early-burst models is still out, and in fact substantial evidence for this model has accumulated in recent years. For example, <cit.> reported an early burst in body size evolution in mammals, <cit.> observed an early-burst pattern in the evolution of bill shape during adaptive radiation in seabirds,  <cit.> and <cit.> reported early-burst patterns in morphological and functional evolution in cichlids, and <cit.> described patterns of early bursts in the evolution of dinosaur morphology.\n\n<cit.> have incorporated the early-burst concept into a macroevolutionary perspective in which over very long evolutionary time scales, rare but substantial phenotypic bursts alternate with more stationary periods of bounded phenotypic fluctuations, somewhat  reminiscent of the concept of punctuated equilibrium <cit.> when applied to rates of phenotypic evolution <cit.>. We think that the models presented here could provide a microevolutionary basis for such a perspective if they are extended by considering evolutionary change in the dimension of the phenotype space that determines ecological interactions. Such an extended theory would have three time scales: a short, ecological time scale, an intermediate time scale at which co-evolution and single diversifications take place in a given phenotype space, and a long time scale at which the number of phenotypic components increases (or decreases). Our hypothesis would then be that in such systems, periods of bounded evolutionary fluctuations near diversity saturation levels for a given dimension of phenotype space would alternate with bursts of rapid evolutionary change, brought about by an evolutionary increase in phenotypic dimensions and the subsequent increase in diversity and acceleration in evolutionary rates until a new saturation level is reached. The resulting long-term evolutionary dynamics would thus show periods of relative phenotypic stasis alternating with periods of fast evolution. This picture would fit very well with the ‚Äúblunderbass‚Äù pattern envisaged in <cit.>. These authors proposed that the intermittent bursts in evolutionary rates are caused by lineages encountering novel ‚Äúadaptive zones‚Äù <cit.>. Novel adaptive zones would correspond to the opening up of new habitats or new resources, which would in turn correspond to new phenotypes that determine use of the novel adaptive zone. Alternatively, novel adaptive zones could also be generated by the emergence of novel sets of regulatory mechanisms allowing novel uses of already existing habitats and resources (as e.g. when a trade-off constraint is overcome through gene duplication). In either case, novel adaptive zones would correspond to an increase in the dimensionality of ecologically important phenotypes.\n\nIt is interesting to note that such intermittent burst patterns have in fact been observed in phylogenetic data, and that they seem to be connected to novel, ecologically important phenotypes. <cit.> have shown that evolutionary rates in echinoids reveal at least two instances of rapidly accelerating and subsequently declining evolutionary rates, i.e., two intermittent bursts. Moreover, these bursts appear to be associated with the evolution of novel feeding strategies <cit.>. Also, <cit.> have shown that an evolutionary burst occurs in the dinosaur-bird transition, and it is tempting to conjecture that this burst was caused by the increase in phenotype dimensionality due to the proliferation of flight capabilities.\n\n\nThere is also good empirical support for our finding that the level at which diversity saturates increases with the dimension of phenotype space. <cit.> has argued that essentially, the high number of  different ecologically relevant traits is the basis for the spectacular radiations of cichlids in African lakes. In conjunction with ecological opportunity, genetic and phenotypic flexibility, which appears to be at least in part due to gene duplications, has allowed this group of fish to reach a much higher diversity than other groups, such as cichlids in rivers or whitefish in arctic lakes, in which fewer phenotypes appear to be ecologically relevant  <cit.>. In this context, we note that incorporating the evolution of the dimension of phenotype space may also shed light on the ongoing debate about whether diversity saturates over evolutionary time or not <cit.>. It seems that the answer could be ‚Äúyes and no‚Äù: diversity saturates in the intermediate term for a given dimension of phenotype space, but does not saturate in the long term if the dimension of phenotype space increases over long evolutionary time scales, thus generating recurrent increases in saturation levels.\n\n\nOur study has a number of limitations that should be addressed in future research. It is currently impractical to perform the statistical analysis presented here for phenotype spaces with dimensions higher than 4 due to computational limitations. Our results indicate that the diversity saturation level, i.e., the maximal number of coexisting phenotypic clusters, increases rapidly with the dimension d of phenotype space, which makes simulations of communities at saturation levels unfeasible. Nevertheless, we expect the salient result that coevolutionary dynamics slow down as communities reach the saturation level to be true in any dimension as long as the Gaussian component of competition in (<ref>) affects all phenotypic directions. Also, in our approach we have assumed that the phenotypes determining competitive interactions are the same for intra- and inter-specific competition. This may be a fair assumption for closely related species, such as those coevolving in an adaptive radiation. However, for competition in more general ecosystems it may also be relevant to assume that from a total set of d phenotypes, different subsets determine competition within a species and competition with various other species. In addition, to describe general ecosystems and food webs, it will be important to include not just competitive interactions, but also predator-prey and mutualistic interactions, each again determined by potentially high-dimensional phenotypes. Also, throughout we have assumed a simple unimodal form of the carrying capacity to represent the external environment. More complicated forms of the carrying capacity, and hence of the external fitness landscape will likely generate even richer patterns of coevolutionary dynamics and diversification. Finally, we have assumed throughout that evolving populations are well-mixed, and it will be interesting so see how the results generalize to spatially structured ecosystems. All these extensions remain to be developed.\n\nWe are of course aware of the fact that we did not include genetic mixing due to sexual reproduction in our models, and our method of describing diversification by simply adding new phenotypic clusters, although fairly standard, does not take into account the actual process of speciation. In sexual populations, adaptive diversification due to disruptive selection, as envisioned here, requires assortative mating, and the conditions for the evolution of various types of assortative mating, as well as for the likelihood of speciation once assortment is present, have been studied extensively (e.g. <cit.>). A general, if crude conclusion from this work is that when there is enough disruptive selection for diversification to occur in asexual models, then it is likely that adaptive speciation also occurs in the corresponding sexual models, although factors such as the strength of assortment, population size and linkage disequilibrium may become important. It would in principle be possible to incorporate sexual reproduction into the models presented here, e.g. along the lines of <cit.>. Our previous results <cit.> indicate that adaptive diversification is generally more likely in high-dimensional phenotype spaces, and we think that the present models serve well as a first approximation to study adaptive diversification and coevolutionary dynamics in evolving communities.\n\nUltimately, the applicability and relevance of our models for understanding macroevolutionary patterns in nature depends in part on being able to determine evolutionary rates of high-dimensional phenotypes from phylogenetic data, which appears to be a difficult problem <cit.>. Nevertheless, overall we think that our approach of incorporating microevolutionary processes based on ecological interactions in high-dimensional phenotype spaces into statistical models for macroevolutionary dynamics has the potential to shed new light on a number of fundamental conceptual questions in evolutionary biology.\n"
        },
        {
            "section_number": 5,
            "title": "ACKNOWLEDGMENTS",
            "summary": "Describe the funding sources and contributions of the authors to acknowledge their support and equal participation in the research presented in the paper.",
            "target_length": 0,
            "origin_content": "M. D. was supported by NSERC (Canada). I. I. was supported by FONDECYT grant 1151524 (Chile). Both authors contributed equally to this work.\n"
        },
        {
            "section_number": 6,
            "title": "CORRELATION BETWEEN PHYLOGENETIC AND PHENOTYPIC DISTANCE",
            "summary": "Explain the relationship between phylogenetic and phenotypic distances in an evolving community by discussing how these distances are measured, the correlation between them, and how this correlation changes over time with varying levels of community diversity.",
            "target_length": 500,
            "origin_content": "For each pair of clusters (species) in an evolving community we define the phylogenic distance between them, Pg, as the number of links in the path between them on the phylogenic tree. To measure this distance, we add the following scheme to our evolutionary algorithm:\n\n\n  * The system is initialized with a single cluster.\n\n  * Each cluster splitting event produces two offspring separated by the distance 2. The distance between an offspring and all its existing neighbours is incremented by one.\n\n  * When two recently split cluster that failed to diverge are merged, the distance between the newly produced common cluster and each of its neighbours is calculated as the minimum of the distances of the two merged clusters minus one. This reflects the observation that merging events only happen with newly split clusters.\n\n As a result, at any given time we know phylogenic distances between all pairs of clusters currently present in the system. To quantify the relation between the phenotypic and phylogenic similarity, we compute the correlation C between phylogenetic and phenotypic distance as follows:\n\n    C=‚ü® [Pg - ‚ü® Pg ‚ü© ][X - ‚ü® X ‚ü©  ] ‚ü©/œÉ_PgœÉ_X,\n\n\nwhere Ph and X are phylogenic and phenotypic distances between clusters, ‚ü®‚Ä¶‚ü© define the average over all pairs of clusters present in the system and œÉ_Pg and œÉ_X are the standard deviations of distances.\n\nThe above scheme allows us to track the correlation between phylogenetic and phenotypic distance over time, as illustrated in Figure A1. Fig. A1A shows the time dependence of C for the simulation shown in Video 1, and in Fig. A1B shows the time dependence of C for the simulation shown in Video 2. During the early phase of community assembly the correlation C rapidly decays due to complicated coevolutionary dynamics of the emerging clusters. When the diversity of the coevolving community is kept intermediate (by setting the parameter m_C to intermediate values, as in Video 1), the correlation between phylogenetic and phenotypic distance itself undergoes fluctuations around 0 (Fig. A1A). This is because the clusters in the community with intermediate diversity undergo large phenotypic fluctuations while their phylogenetic relationship is constant, because no further diversification (or extinction) occurs. However, when the diversity is allowed to reach saturation levels (by setting m_C to a large value, as in Video 2), a positive correlation between phylogenetic and phenotypic distance develops in the final stages of community assembly, i.e., as the coevolving community reaches the saturation diversity and hence undergoes much smaller phenotypic fluctuations (Fig. A1B). Note that the correlation is still close to 0 during the early stages of community assembly, but some correlation remains at the end due to clusters emerging in the last phase of community assembly, which tend to stay phenotypically closer to their sister species because evolutionary dynamics become slow and stable.\n"
        },
        {
            "section_number": 7,
            "title": "INDIVIDUAL-BASED SIMULATIONS",
            "summary": "Describe the methodology and process of the individual-based simulations using the Gillespie algorithm to model the dynamics of phenotypic diversity and coevolution in high-dimensional spaces, detailing how birth and death events are simulated and updated over time.",
            "target_length": 300,
            "origin_content": "Individual-based realizations of the model\nwere based on the Gillespie algorithm <cit.>\nand consisted of the following steps:\n\n\n  * The system is initialized by creating a set of K_0 ‚àº 10^3 - 10^4 individuals with\n  phenotypes  _k‚ààùêë^d localized around the initial position _0\n  with a small random spread |_k - _0|‚àº10^-3.\n\n  * Each individual k has a\nconstant reproduction rate _Ãäk=1 and a death rate\n\n_Ã£k=‚àë_ l ‚â† k\nA(_l,_k)/[K_0K(_k)], as defined by the logistic ecological dynamics.\n\n  * The total update rate is\ngiven by the sum of all individual rates, U=‚àë_k\n(_Ãäk+_Ã£k).\n\n  * The running time t is incremented by a random number\nt drawn from the exponential distribution P( t)= U exp (- t  U).\n\n  * A particular birth or death event is randomly chosen  with\nprobability equal to the rate of this event divided by the total update\nrate U. If  a reproduction event is chosen, the phenotype of an\noffspring is offset from the parental phenotype by a\nsmall mutation randomly drawn from a uniform distribution with\namplitude = 10^-3 - 10^-2.\n\n  * The individual death rates _Ã£k and the total update rate\nU are updated  to take into account the addition or removal of an\nindividual.\n\n  * Steps 4-6 are repeated until t reaches a specified end time.\n\n\n\nThe movie in Video A2 shows the dynamics of the individual-based model corresponding to the adaptive dynamics simulation shown in Video A1, which is the same as the scenario used for Video 2 in the main text  (note that the movie in Video A1 runs for t=1200 time units, whereas the movie in Video 2 runs for t=400 time units).\n\n\n1cm\n\n\n1 cm\n"
        },
        {
            "section_number": 8,
            "title": "PARTIAL DIFFERENTIAL EQUATION MODELS",
            "summary": "Explain how the deterministic large-population limit of the individual-based model is formulated as a partial differential equation, detailing the role of diffusion in mutation dynamics, the implications of symmetry in the model, and the computational constraints involved in solving the PDE for high-dimensional phenotype spaces.",
            "target_length": 300,
            "origin_content": "A deterministic large-population limit of the individual-based model is obtained as the partial differential equation (PDE)\n\n\n    ‚àÇ N(, t)/‚àÇ t = N(, t)( 1 - ‚à´Œ±(, ) N (, t) dy/K())+D‚àë_i=1^d ‚àÇ^2 N(, t)/‚àÇ x_i^2,\n\n\nwhere  N(, t) is the population distribution at time t <cit.>. The second term of the right hand side is a diffusion term that describes mutations,\nwith the diffusion coefficient typically set to D‚àº 10^-4 - 10^-3. Local maxima of the solution N(x,t) can be interpreted as positions of the centers of the phenotypic clusters. Their dynamics are shown in Video A3.\nFor any given scenario, the corresponding adaptive dynamics solution can be used to determine the single- or few-cluster trajectory, and hence to approximately determine the region occupied by the system in phenotype space over time. Note that the deterministic PDE model is invariant with regard to the coordinate change ‚Üí -, and hence its solutions must be symmetric with regard to simultaneous reflection on all coordinate axes. To numerically solve the PDE model (<ref>)\n we  chose a lattice noticeably\nlarger than the corresponding adaptive dynamics attractor. The number of bins B\nin each dimension of this lattice is strongly constrained by memory limitations: An\nefficient implementation requires computing and storing an array of\nB^d√ó B^d values of the competition kernel Œ±(_i, _j) for the pairwise interactions between\nall pairs of sites i and j.  With B=25 -30 to achieve a reasonable\nspatial resolution, the memory constraint makes the\nPDE implementation feasible only for d=2,3.\n\nThe movie in Video A3 shows the dynamics of the partial differential equation model corresponding to the scenarios shown in Videos A1 and A2.\n"
        },
        {
            "section_number": 9,
            "title": "SCALING RELATIONSHIP FOR THE DIVERSITY AT SATURATION",
            "summary": "Explain the scaling relationships for diversity saturation in high-dimensional phenotype spaces, highlighting how diversity is influenced by the dimensions of the phenotype space and competition strength, and discuss the conditions necessary for maintaining diversity.",
            "target_length": 100,
            "origin_content": "The number of clusters at the diversity saturation level, M_,d, can be estimated to be proportional to the volume of the available phenotype space with the linear dimension L, divided by the volume occupied by each cluster, which has a typical linear size :\n\n\n    M__a,d‚âà C_L^d/^d.\n\n\nHence, the following scaling  relationships hold:\n\n\n    M__a,d=M__b,d(_b/_a)^d   and     M_,d_1=M_,d_2^d_1/d_2,\n\nwhere _a and _b denote different strengths of competition, and C_ is a constant of order 1 that takes into account the ‚Äúimperfect packing‚Äù occurring when  and L have similar magnitude.\nBased on this, the equilibrium level of diversity is expected to increase exponentially with increasing dimension of phenotype space (as illustrated Figure 1), and with increasing frequency-dependence (i.e., decreasing ). In general, diversity is only maintained if ‚â≤1, which is roughly the scale of the phenotypic range set by the carrying capacity given by eq. (5) in the main text.\n"
        },
        {
            "section_number": 10,
            "title": "SPECIFIC SETS OF COEFFICIENTS USED",
            "summary": "Explain how specific sets of coefficients were selected to define the competition kernel for different figures and discuss their role in illustrating the diversity and coevolutionary dynamics in high-dimensional phenotype spaces.",
            "target_length": 100,
            "origin_content": "The following set of coefficients b_ij determining the competition kernel were used for Figures¬†5A in the main text and for the movies.\n\n\n    [  0.407  0.498  0.287; -0.199 -1.102 -0.305;  1.387 -0.896  0.341 ]\n\n\nThe following set of coefficients b_ij determining the competition kernel were used for Figure¬†5B in the main text:\n\n\n    [ -1.289  0.682  0.217 -0.093; -0.223 -0.035  0.697 -0.117; -0.563  0.434 -0.953 -0.198;  0.119  0.398  0.183  0.530 ]\n\n\n2cm\n\n\n\n\nevolution\n"
        }
    ],
    [
        {
            "section_number": 1,
            "title": "INTRODUCTION",
            "summary": "Discuss the methodologies and computational techniques employed in the development of a unified generic market simulation tool for future grid scenario analysis, emphasizing its integration with stability assessment and the challenges it addresses in terms of computational efficiency and accuracy.",
            "target_length": 900,
            "origin_content": "Power systems worldwide are moving away from domination by large-scale synchronous generation and passive consumers.\nInstead, in future grids[We interpret a future grid to mean the study of national grid type structures with the transformational changes over the long-term out to 2050.] new actors, such as variable renewable energy sources (RES)[For the sake of brevity, by RES we mean ‚Äúunconventional‚Äù renewables like wind and solar, but excluding conventional RES, like hydro, and dispatchable unconventional renewables, like concentrated solar thermal.], price-responsive users equipped with small-scale PV-battery systems (called prosumers), demand response (DR), and energy storage will play an increasingly important role.\nGiven this, in order for policy makers and power system planners to evaluate the integration of high-penetrations of these new elements into future grids, new simulation tools need to be developed.\nSpecifically, there is a pressing need to understand the effects of technological change on future grids, in terms of energy balance, stability, security and reliability, over a wide range of highly-uncertain future scenarios.\nThis is complicated by the inherent and unavoidable uncertainty surrounding the availability, quality and cost of new technologies (e.g. battery or photo-voltaic system costs, or concentrated solar thermal (CST) generation operating characteristics) and the policy choices driving their uptake.\nThe recent blackout in South Australia <cit.> serves as a reminder that things can go wrong when the uptake of new technologies is not planned carefully.\n\nFuture grid planning thus requires a major departure from conventional power system planning, where only a handful of the most critical scenarios are analyzed. To account for a wide range of possible future evolutions, scenario analysis has been proposed in many industries, e.g. in finance and economics <cit.>, and in energy <cit.>. In contradistinction to power system planning, where the aim is to find an optimal transmission and/or generation expansion plan, the aim of scenario analysis is to analyze possible evolution pathways to inform power system planning and policy making. Given the uncertainty associated with long-term projections, the focus of future grid scenario analysis is limited only to the analysis of what is technically possible, although it might also consider an explicit costing <cit.>.\nIn more detail, existing future grid feasibility studies have shown that the balance between demand and supply can be maintained even with high penetration of RESs by using large-scale storage, flexible generation, and diverse RES technologies <cit.>.\nHowever, they only focus on balancing and use simplified transmission network models (either copper plate or network flow; a notable exception is the Greenpeace pan-European study <cit.> that uses a DC load flow model). This ignores network related issues, which limits these models' applicability for stability assessment.\n\nTo the best of our knowledge, the Future Grid Research Program, funded by the Australian Commonwealth Scientific and Industrial Research Organisation (CSIRO) is the first to propose a comprehensive modeling framework for future grid scenario analysis that also includes stability assessment. The aim of the project is to explore possible future pathways for the evolution of the Australian grid out to 2050 by looking beyond simple balancing. To this end, a simulation platform has been proposed in <cit.> that consists of a market model, power flow analysis, and stability assessment, Fig.¬†<ref>. The platform has been used, with additional improvements, to study fast stability scanning <cit.>, inertia <cit.>, modeling of prosumers for market simulation <cit.>,  impact of prosumers on voltage stability <cit.>, and power system flexibility using CST <cit.> and battery storage <cit.>.\nIn order to capture the inter-seasonal variations in the renewable generation, computationally intensive time-series analysis needs to be used.\nA major computational bottleneck of the framework is the market simulation.\n\n\n\nWithin this context, the contribution of this paper is to propose a unified generic market simulation tool (MST) based on a unit commitment (UC) problem suitable for future grid scenario analysis, including stability assessment. The tool incorporates the following key features:\n\n\n  * market structure agnostic modeling framework,\n\n  * integration of various types and penetrations of RES and emerging demand-side technologies,\n\n  * generic demand model considering the impact of prosumers,\n\n  * explicit network representation, including HVDC lines, using a DC power flow model,\n\n  * explicit representation of the number of online synchronous generators,\n\n  * explicit representation of system inertia and reactive power support capability of synchronous generators,\n\n  * computational efficiency with sufficient accuracy.\n\n\nThe presented model builds on our existing research¬†<cit.> and combines all these in a single coherent formulation.\n\nIn more detail, to reduce the computational burden, the following techniques are used building on the methods proposed in¬†<cit.>:\n\n\n  * unit clustering,\n\n  * rolling horizon approach,\n\n  * constraint clipping.\n\n\nThe computational advantages of our proposed model are shown on a simplified 14-generator model of the Australian National Energy Market (NEM) as a test grid¬†<cit.>. Four cases for different RES penetration are run for one to seven days horizon length, and computational metrics are reported. To reflect the accuracy of the proposed MST, system inertia and voltage stability margins are used as a benchmark. In simulations, RES and load traces are taken from the National Transmission Network Developed Plan (NTNDP) data, provided by the Australian Energy Market Operator (AEMO)¬†<cit.>.\n\nThe remainder of the paper is organized as follows: Literature review and related work are discussed in Section II, while Section\nIII details the MST. A detailed description\nof the simulation setup is given in Section IV. In Section V results are analyzed and discussed in detail. Finally, Section VI concludes the paper.\n"
        },
        {
            "section_number": 2,
            "title": "RELATED WORK",
            "summary": "Write a detailed section on how existing future grid studies address the challenges of unit commitment (UC) formulations, highlighting the simplifications and approximations made in operational, planning, and scenario analyses to balance computational complexity with functional requirements.",
            "target_length": 800,
            "origin_content": "In order to better explain the functional requirements of the proposed MST, we first describe the canonical UC formulation.\nAn interested reader can find a comprehensive literature survey in <cit.>.\n\n\n\n\n ¬ß.¬ß Canonical Unit Commitment Formulation\n\nThe UC problem is an umbrella term for a large class of problems in power system operation and planning whose objective is to schedule and dispatch power generation at minimum cost to meet the anticipated demand, while meeting a set of system-wide constraints. In smart grids, problems with a similar structure arise in the area of energy management, and they are sometimes also called UC <cit.>.\nBefore deregulation, UC was used in vertically integrated utilities for generation scheduling to minimize production costs. After deregulation, UC has been used by system operators to maximize social welfare, but the underlying optimization model is essentially the same.\n\nMathematically, UC is a large-scale, nonlinear, mixed-integer optimization problem under uncertainty. With some abuse of notation, the UC optimization problem can be represented in the following compact formulation <cit.>:\n\n    minimize_ùê±_c, ùê±_b      f_c(ùê±_c) + f_b(ùê±_b)\n    subject  to      g_c(ùê±_c) ‚â§ùêõ\n        g_b(ùê±_b) ‚â§ùêú\n        h_c(ùê±_c) + h_b(ùê±_b)‚â§ùêù\n       ùê±_c‚àà‚Ñù^+, ùê±_b‚àà{ 0,1 }\n\n\nDue to the time-couplings, the UC problem needs to be solved over a sufficiently long horizon.\nThe decision vector ùê± = {ùê±_c, ùê±_b} for each time interval consist of continuous and binary variables. The continuous variables, ùê±_c, include  generation dispatch levels, load levels, transmission power flows, storage levels, and transmission voltage magnitudes and phase angles. The binary variables, ùê±_b, includes scheduling decisions for generation and storage, and logical decisions that ensure consistency of the solution.\nThe objective (<ref>) captures the total production cost, including fuel costs, start-up costs and shut-down costs.\nThe constraints include, respectively: dispatch related constraints such as energy balance, reserve requirements, transmission limits, and ramping constraints (<ref>); commitment variables, including minimum up and down, and start-up/shut-down constraints (<ref>); and constraints coupling commitment and dispatch decisions, including minimum and maximum generation capacity constraints (<ref>).\n\nThe complexity of the problem stems from the following: (i) certain generation technologies (e.g. coal-fired steam units) require long start-up and shut-down times, which requires a sufficiently long solution horizon; (ii) generators are interconnected, which introduces couplings through the power flow constraints; (iii) on/off decisions introduce a combinatorial structure; (iv) some constraints (e.g. AC load flow constraints) and parameters (e.g. production costs) are non-convex; and (v) the increasing penetration of variable renewable generation and the emergence of demand-side technologies introduce uncertainty.\nAs a result, a complete UC formulation is computationally intractable, so many approximations and heuristics have been proposed to strike a balance between computational complexity and functional requirements. For example, power flow constraints can be neglected altogether (a copper plate model), can be replaced with simple network flow constraints to represent critical inter-connectors, or, instead of (non-convex) AC, a simplified (linear) DC load flow is used.\n\n\n\n\n ¬ß.¬ß UC Formulations in Existing Future Grid Studies\n\nIn operational studies: the nonlinear constraints, e.g. ramping, minimum up/down time (MUDT) and thermal limits are typically linearized; startup and shutdown exponential costs are discretized, and; non-convex and non-differentiable variable cost functions are expressed as piecewise linear function <cit.>. In planning studies, due to long horizon lengths, the UC model is simplified even further. For example: combinatorial structure is avoided by aggregating all the units installed at one location <cit.>; piecewise linear cost functions and constraints are represented by one segment only; some costs (e.g. startup, shutdown and fix costs) are ignored; a deterministic UC with perfect foresight is used, and; non-critical binding constraints are omitted¬†<cit.>[An interested reader can refer to <cit.> for a discussion on binding constraints elimination for generation planning.].\nTo avoid the computational complexity associated with the mixed integer formulation, a recent work¬†<cit.> has proposed a linear relaxation of the UC formulation for flexibility studies, with an accuracy comparable to the full binary mixed integer linear formulation.\n\nIn contrast to operation and planning studies, the computational burden of future grid scenario analysis is even bigger, due to a sheer number of scenarios that need to be analyzed, which requires further simplifications. For example, the Greenpeace study <cit.> uses an optimal power flow for generation dispatch and thus ignores UC decisions. Unlike the Greenpeace study, the Irish All Island Grid Study¬†<cit.> and the European project e-Highway2050 <cit.> ignore load flow constraints altogether, however they do use a rolling horizon UC, with simplifications. The Irish study, for example doesn't put any restriction on the minimum number of online synchronous generators to avoid RES spillage, and the e-Highway2050 study uses a heuristics to include DR. The authors of the e-Highway2050 study, however, acknowledge the size and the complexity of the optimization framework in long term planning, and plan to develop new tools with a simplified network representation¬†<cit.>.\n\nIn summary, a UC formulation depends on the scope of the study. Future grid studies that explicitly include stability assessment bring about some specific requirements that are routinely neglected in the existing UC formulations, as discussed next.\n"
        },
        {
            "section_number": 3,
            "title": "MARKET SIMULATION TOOL",
            "summary": "Write a detailed section on the computationally efficient market simulation tool (MST) for future grid scenario analysis, focusing on its unit commitment formulation, system and network constraints, generation and storage constraints, and the prosumer sub-problem, highlighting the techniques used to enhance computational efficiency and ensure accurate stability assessment.",
            "target_length": 2700,
            "origin_content": "¬ß.¬ß Functional Requirements\n\nThe focus of our work is stability assessment of future grid scenarios. Thus, MST must produce dispatch decisions that accurately capture the kinetic energy stored in rotating masses (inertia), active power reserves and reactive power support capability of synchronous generators, which all depend upon the number of online units and the respective dispatch levels.\n\nFor the sake of illustration, consider a generation plant consisting of three identical (synchronous) thermal units, with the following characteristics: (i) constant terminal voltage of 1pu; (ii) minimum technical limit P_min = 0.4pu; (iii) power factor of 0.8; (iv) maximum excitation limit E_fd^max = 1.5pu; and (v) normalized inertia constant H = 5. We further assume that in the over-excited region, the excitation limit is the binding constraint, as shown in Fig. <ref>. Observe that the maximum reactive power capability depends on the active power generated, and varies between Q_n at P_max = 1pu and Q_max at P_min.\nWe consider three cases defined by the total active power generation of the plant: (i) 0.8pu, (ii) 1.2pu, and (iii) 1.6pu.\nThe three scenarios correspond to the rows  in Fig.¬†<ref>, which shows the active power dispatch level P, reactive power support capability Q, online active power reserves R, and generator inertia H.\nThe three columns show feasible solutions for three different UC formulations: all three units are aggregated into one equivalent unit (AGG), standard binary UC (BUC) when each unit is modeled individually, and the proposed market simulation tool (MST). A detailed comparison of the three formulations is given in Section V.\n\n\n\nAlthough the results are self-explanatory, a few things are worth emphasizing. In case (i), aggregating the units into one equivalent unit (AGG) results in the unit being shut down due to the minimum technical limit. The individual unit representation (BUC), on the other hand, does allow the dispatch of one or two units, but with significantly different operational characteristics. In cases (ii) and (iii), the total inertia in the AGG formulation is much higher, which has important implications for frequency stability. A similar observation can be made for the reactive power support capability, which affects voltage stability. Also, dispatching power from all three units results in a significantly higher active power reserve. And last, a higher reactive power generation due to a lower P reduces the internal machine angle, which improves transient stability.\n\nIn conclusion, a faithful representation of the number of online synchronous machines is of vital importance for stability assessment. An individual unit representation, however, is computationally expensive, so the computational burden should be reduced, as discussed in the following section. Next, an explicit network representation is required. An AC load flow formulation, however, is nonlinear (and non-convex), which results in an intractable mixed-integer nonlinear problem. Therefore, we use a DC load flow representation with a sufficiently small voltage angle difference on transmission lines. Our experience shows that an angle difference of 30 results in a manageable small number of infeasible operating conditions that can be dealt with separately.\n\n\n\n\n ¬ß.¬ß Computational Speedup\n\nThe MST is based on the UC formulation using constant fixed, startup, shutdown and production costs. To improve its computational efficiency, the dimensionality of the optimization problem is reduced employing: (i) unit clustering <cit.> to reduce the number of variables needed to represent a multi-unit generation plant; (ii) a rolling horizon approach <cit.> to reduce the time dimension; and (iii) constraint clipping to remove most non-binding constraints.\n\n\n\n  ¬ß.¬ß.¬ß Unit Clustering\n\nLinearized UC models are computationally efficient for horizons of up to a few days, which makes them extremely useful for operational studies. For planning studies, however, where horizon lengths can be up to a year, or more, these models are still computationally too expensive. Our work builds on the clustering approach proposed in¬†<cit.>, where identical units at each generation plant are aggregated by replacing binary variables with fewer integer variables. The status of online units, startup/shutdown decisions and dispatched power are tracked by three integer variables and one continuous variable per plant per period, as opposed to three binary and one continuous variable per unit per period. Further clustering proposed in¬†<cit.> is not possible in our formulation because of the explicit network representation required in the MST.\n\n\n\n  ¬ß.¬ß.¬ß Rolling Horizon\n\nSolving the UC as one block, especially for long horizons, is computationally too expensive. This can be overcome by breaking the problem into several smaller intervals called sub-horizons¬†<cit.>. To ensure accuracy and consistency of the solution, a proper overlap between sub-horizons is maintained and the terminating state of the previous sub-horizon is used as the initial condition of the next sub-horizon. The minimum sub-horizon length depends on the time constants associated with the decision variables. While these might be in the order of hours for thermal power plants, they can be significantly longer for energy storage. Large-scale hydro dams, for example, require horizon lengths of several weeks, or even months. In our research, however, the sub-horizon length is up to a few days to cater for thermal energy storage (TES) of CST plants and battery storage. The optimization of hydro dams is not explicitly considered, however it can be taken into account heuristically, if needed.\n\n\n\n  ¬ß.¬ß.¬ß Constraint Clipping\n\nThe size of the problem can be reduced by removing non-binding constraints, which doesn't affect the feasible region. For instance, an MUDT constraint on a unit with an MUDT less than the time interval is redundant[This is especially the case when the time resolution is coarse. In our studies, the time step is one hour. In operational studies, where the resolution can be as short as five minutes, constraint clipping is less useful.]. Similarly, a ramp constraint for flexible units is redundant if the time step is sufficiently long. With a higher RES penetration, in particular, where backup generation is provided by fast-ramping gas turbines, this technique can significantly reduce the size of the optimization problem, and hence improves the computational performance due to a larger number of units with higher ramp rates and smaller MUDTs. It should be noted that optimization pre-solvers might not able to automatically remove these constraints.\n\n\n\n\n ¬ß.¬ß MST UC Formulation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  ¬ß.¬ß.¬ß Objective function\n\nThe objective of the proposed MST is to minimize total generation cost for all sub-horizons h:\n\n    Œ©minimize ‚àë_t‚ààùíØ^‚àë_g‚ààùí¢^( c_g^fix s_g,t\n    +c_g^su u_g,t + c_g^sd  d_g,t +c_g^var  p_g,t),\n\nwhere Œ© = {s_g,t,u_g,t,d_g,t,p_g,t, p_s,t, p_l,t} are the decision variables of the problem, and c_g^fix, c_g^su, c_g^sd, and c_g^var are fixed, startup, shutdown and variable cost, respectively.\nAs typically done in planning studies <cit.>, <cit.>, the costs are assumed constant to reduce the computational complexity. The framework, however, also admits a piece-wise linear approximation proposed in <cit.>.\n\n\n\n  ¬ß.¬ß.¬ß System Constraints\n\nSystem Constraints[All the constraints must be satisfied in all time slots t, however, for sake of notational brevity, this is not explicitly mentioned.] include power balance constraints, power reserve and minimum synchronous inertia requirements.\n\nPower balance:\nPower generated at node n must be equal to the node power demand plus the net power flow on transmission lines connected to the node:\n\n    ‚àë_g‚ààùí¢_n^p_g,t =\n    ‚àë_c ‚ààùíû_np_c,t^ + ‚àë_p ‚ààùí´_n p_p,t^g+ - ‚àë_p ‚ààùí´_n p_p,t^g- + ‚àë_s ‚ààùíÆ_np_s,t + ‚àë_l ‚àà‚Ñí_n(p_l,t +Œî p_l,t),\n\nwhere ùí¢_n, ùíû_n, ùí´_n, ùíÆ_n, ‚Ñí_n represent respectively the set of generators, consumers, prosumers[Price-responsive users equipped with small-scale PV-battery systems.], utility storage plants and lines connected to node n.\n\nPower reserves:\nTo cater for uncertainties, active power reserves provided by synchronous generation g ‚ààùí¢^syn are maintained in each region r:\n\n    ‚àë_g ‚àà{ (ùí¢^syn-ùí¢^CST) ‚à©ùí¢^r} (p_g s_g,t - p_g,t) +\n    ‚àë_g ‚àà{ùí¢^CST‚à©ùí¢^r}min(p_g s_g,t - p_g,t,e_g,t-p_g,t)  ‚â•‚àë_n ‚ààùí©_r^p_n,t^r.\n\nFor synchronous generators other than concentrated solar thermal (CST), reserves are defined as the difference between the online capacity and the current operating point. For CST, reserves can either be limited by their online capacity or energy level of their thermal energy system (TES).\nVariable s_g,t in (<ref>) represents the total number of online units at each generation plant, and ùí¢^r and ùí©_r represent the sets of generators and nodes in region r, respectively.\n\nMinimum synchronous inertia requirement:\nTo ensure frequency stability, a minimum level of inertia provided by synchronous generation must be maintained at all times (more details are available in <cit.>) in each region r:\n\n    ‚àë_g ‚àà{ùí¢^syn‚à©ùí¢^r}^ s_g,tH_g S_g ‚â•‚àë_n ‚ààùí©_r^H_n,t.\n\n\n\n\n  ¬ß.¬ß.¬ß Network constraints\n\nNetwork constraints include DC power flow constraints and thermal line limits for AC lines, and active power limits for HVDC lines.\n\nLine power constraints:\nA DC load flow model is used for computational simplicity for AC transmission lines[A sufficiently small (‚àº30) voltage angle difference over a transmission line is used to reduce the number of nonconvergent AC power flow cases.]:\n\n    p_l,t^x,y = B_l(Œ¥_x,t - Œ¥_y,t),    l ‚àà‚Ñí^ùíúùíû,\n\nwhere the variables Œ¥_x,t and Œ¥_y,t represent voltage angles at nodes x ‚ààùí© and y ‚ààùí©, respectively.\n\nThermal line limits:\nPower flows on all transmission lines are limited by the respective thermal limits of line l:\n\n    |  p_l,t|‚â§p_l,\n\nwhere p_l represents the thermal limit of line l.\n\n\n\n  ¬ß.¬ß.¬ß Generation constraints\n\nGeneration constraints include physical limits of individual generation units.\nFor the binary unit commitment (BUC), we adopted a UC formulation requiring three binary variables per time slot (on/off status, startup, shutdown) to model an individual unit. In the MST, identical units of a plant are clustered into one individual unit¬†<cit.>.\nThis requires three integer variables (on/of status, startup, and shutdown) per generation plant per time slot as opposed to three binary variables per generation unit per time slot in the BUC, as discussed in Section III.B of A Computationally Efficient Market Model for Future Grid Scenario Studies.\n\nGeneration limits:\nDispatch levels of a synchronous generator g are limited by the respective stable operating limits:\n\n    s_g,tp_g‚â§ p_g,t‚â§ s_g,tp_g,     g ‚ààùí¢^syn.\n\nThe power of RES[For the sake of brevity, by RES we mean ‚Äúunconventional‚Äù renewables like wind and solar, but excluding conventional RES, like hydro, and dispatchable unconventional renewables, like concentrated solar thermal.] generation is limited by the availability of the corresponding renewable resource (wind or sun):\n\n    s_g,tp_g‚â§ p_g,t‚â§ s_g,tp_g,t^RES,     g ‚ààùí¢^RES.\n\n\nUnit on/off constraints:\nA unit can only be turned on if and only if it is in off state and vice versa:\n\n    u_g,t-d_g,t=s_g,t-s_g,t-1,     t ‚â† 1,  g ‚ààùí¢^syn.\n\nIn a rolling horizon approach, consistency between adjacent time slots is ensured by:\n\n    u_g,t-d_g,t=s_g,t - ≈ù_g,     t =1,  g ‚ààùí¢^syn,\n\nwhere ≈ù_g is the initial number of online units of generator g. Equations (<ref>) and (<ref>) also implicitly determine the upper bound of u_g,t and d_g,t in terms of changes in  s_g,t.\n\nNumber of online units:\nUnlike the BUC, the MST requires an explicit upper bound on status variables:\n\n    s_g,t‚â§U_g.\n\n\n\nRamp-up and ramp-down limits:\nRamp rates of synchronous generation should be kept within the respective ramp-up (<ref>), (<ref>) and ramp-down limits (<ref>), (<ref>):\n\n    p_g,t - p_g,t-1‚â§ s_g,tr^+_g,     t ‚â† 1, g ‚àà{ùí¢^syn | r^+_g < p_g},\n        p_g,t - pÃÇ_g‚â§ s_g,tr^+_g,     t =1, g ‚àà{ùí¢^syn | r^+_g < p_g},\n       pÃÇ_g - p_g,t‚â§ s_g,t-1r^-_g,      t ‚â† 1, g ‚àà{ùí¢^syn | r^-_g < p_g},\n       pÃÇ_g - p_g,t‚â§≈ù_gr^-_g,     t =1, g ‚àà{ùí¢^syn | r^-_g < p_g}.\n\nIn the MST, a ramp limit of a power plant is defined as a product of the ramp limit of an individual unit and the number of online units in a power plant s_g,t. If s_g,t is binary, these ramp constraints are mathematically identical to ramp constraints of the BUC.\nIf a ramp rate multiplied by the length of the time resolution Œît is less than the rated power, the rate limit has no effect on the dispatch, so the corresponding constraint can be eliminated.\nConstraints explicitly defined for t=1 are used to join two adjacent sub-horizons in the rolling-horizon approach.\n\nMinimum up and down times:\nSteam generators must remain on for a period of time  œÑ_g^u once turned on (minimum up time):\n\n    s_g,t‚â•‚àë_tÃÉ=œÑ_g^u-1^0 u_g,t-tÃÉ,     t ‚â•œÑ_g^u,   g ‚àà{ùí¢^syn | œÑ_g^u > Œît},\n        s_g,t‚â•‚àë_tÃÉ=t-1^0u_g,t-tÃÉ  + √ª_g,t,     t < œÑ_g^u,  g ‚àà{ùí¢^syn | œÑ_g^u > Œît}.\n\nSimilarly, they must not be turned on for a period of time  œÑ_g^d once turned off (minimum down time):\n\n    s_g,t‚â§U_g - ‚àë_tÃÉ=œÑ_g^d-1^0 d_g,t-tÃÉ,     t ‚â•œÑ_g^d,  g ‚àà{ùí¢^syn | œÑ_g^d > Œît},\n        s_g,t‚â§U_g - ‚àë_tÃÉ=t-1^0d_g,t-tÃÉ - dÃÇ_g,t,     t < œÑ_g^d,  g ‚àà{ùí¢^syn | œÑ_g^d > Œît}.\n\nSimilar to the rate limits, if the minimum up and down times are smaller than the time resolution Œît, the corresponding constraints can be eliminated.\nDue to integer nature of discrete variables in the MST, the definition of the MUDT constraints in the RH approach requires the number of online units for the last œÑ^u/d time interval to establish the relationship between the adjacent sub-horizons. If the œÑ_g^u/d is smaller than time resolution Œît, then these constraints can be eliminated.\n\n\n\n  ¬ß.¬ß.¬ß CST constraints:\n\nCST constraints include TES energy balance and storage limits.\n\nTES state of charge (SOC)\ndetermines the TES energy balance subject to the accumulated energy in the previous time slot, thermal losses, thermal power provided by the solar farm and electrical power dispatched from the CST plant:\n\n    e_g,t=Œ∑_ge_g,t-1+p_g,t^CST-p_g,t,\t    t ‚â† 1,  g ‚ààùí¢^CST,\n        e_g,t=Œ∑_g√™_g+p_g,t^CST-p_g,t,      t=1,  g ‚ààùí¢^CST,\n\nwhere, p_g,t^CST is the thermal power collected by the solar field of generator g ‚ààùí¢^CST.\n\nTES limits:\tEnergy stored is limited by the capacity of a storage tank:\n\n    e_g‚â§e_g,t‚â§e_g,\t   g ‚ààùí¢^CST.\n\n\n\n\n  ¬ß.¬ß.¬ß Utility storage constraints\n\nUtility-scale storage constraints include energy balance, storage capacity limits and power flow constraints. The formulation is generic and can capture a wide range of storage technologies.\n\nUtility storage SOC limits determine the energy balance of storage plant  s:\n\n    e_s,t=Œ∑_se_s,t-1+p_s,t,\t    t ‚â† 1,\n        e_s,t=Œ∑_s√™_s+p_s,t,\t    t=1.\n\n\nUtility storage capacity limits:\nEnergy stored is limited by the capacity of storage plant s:\n\n    e_s‚â§e_s,t‚â§e_s.\n\n\nCharge/discharge rates limit the charge and discharge powers of storage plant s:\n\n    p_s^- ‚â§p_s,t‚â§p_s^+,\n\nwhere p_s^- and p_s^+ represent the maximum power discharge and charge rates of a storage plant, respectively.\n\n\n\n  ¬ß.¬ß.¬ß Prosumer sub-problem\n\nThe prosumer sub-problem captures the aggregated effect of prosumers. It is modeled using a bi-level framework in which the upper-level unit commitment problem described above minimizes the total generation cost, and the lower-level problem maximizes prosumers' self-consumption. The coupling is through the prosumers' demand, not through the electricity price, which renders the proposed model market structure agnostic. As such, it implicitly assumes a mechanism for demand response aggregation. The Karush-Kuhn-Tucker optimality conditions of the lower-level problem are added as the constraints to the upper-level problem, which reduces the problem to a single mixed integer linear program.\n\nThe model makes the following assumptions: (i) the loads are modeled as price anticipators; (ii) the demand model representing an aggregator consists of a large population of prosumers connected to an unconstrained distribution network who collectively maximize self-consumption; (iii) aggregators do not alter the underlying power consumption of the prosumers; and (iv) prosumers have smart meters equipped with home energy management systems for scheduling of the PV-battery systems, and, a communication infrastructure is assumed that allows a two-way communication between the grid, the aggregator and the prosumers. More details can be found in <cit.>.\n\nProsumer Objective function:\nProsumers aim to minimize electricity expenditure:\n\n    p_p^g+/‚Äì, p_p^bminimize‚àë_t‚ààùíØ^ p_p,t^g+ - Œª p_p,t^g-,\n\nwhere Œª is the applicable feed-in price ratio. In our research, we assumed Œª = 0, which corresponds to maximization of self-consumption.\n\nThe prosumer sub-problem is subject to the following constraints:\n\nProsumer power balance:\nElectrical consumption of prosumer p, consisting of grid feed-in power, p_p,t^g-, underlying consumption, p_p,t^, and battery charging power, p_p,t^b, is equal to the power taken from the grid, p_p,t^g+, plus the power generated by the PV system, p_p,t^pv:\n\n    p_p,t^g+ + p_p,t^pv =  p_p,t^g- +  p_p,t^ + p_p,t^b.\n\n\nBattery charge/discharge limits:\nBattery power should not exceed the charge/discharge limits:\n\n    p_p^b-‚â§p_p,t^b‚â§p_p^b+,\n\nwhere p_b^- and p_b^+ represent the maximum power discharge and charge rates of the prosumer's battery, respectively.\n\nBattery storage capacity limits:\nEnergy stored in a battery of prosumer p should always be less than its capacity:\n\n    e_p^b‚â§e_p,t^b‚â§e_p^b.\n\n\nBattery SOC limits:\nBattery SOC is the sum of the  power inflow and the SOC in the previous period:\n\n    e_p,t^b = Œ∑_p^be_p,t^b +  p_p,t^b,      t ‚â† 1,\n       e_p,t^b = Œ∑_p^b√™_p^b  +  p_p,t^b,     t=1,\n\nwhere √™_p^b represents the initial SOC and is used to establish the connection between adjacent sub-horizons.\n"
        },
        {
            "section_number": 4,
            "title": "SIMULATION SETUP",
            "summary": "Describe the simulation setup used to evaluate the computational efficiency of the proposed market simulation tool, including the modifications made to the IEEE test system, the test cases with varying renewable energy penetrations, and the modeling assumptions that were applied.",
            "target_length": 500,
            "origin_content": "The case studies provided in this section compare the computational efficiency of the proposed MST with alternative formulations. For detailed studies on the impact of different technologies on future grids, an interested reader can refer to our previous work¬†<cit.>.\n\n\n\n\n ¬ß.¬ß Test System\n\nWe use a modified 14-generator IEEE test system that was initially proposed in <cit.> as a test bed for small-signal analysis. The system is loosely based on the Australian National Electricity Market (NEM), the interconnection on the Australian eastern seaboard. The network is stringy, with large transmission distances and loads concentrated in a few load centres. Generation, demand and the transmission network were modified to meet future load requirements. The modified model consists of 79 buses grouped into four regions, 101 units installed at 14 generation plants and 810 transmission lines.\n\n\n\n\n ¬ß.¬ß Test Cases\n\nTo expose the limitations of the different UC formulations, we have selected a typical week with sufficiently varying operating conditions.\nFour diverse test cases with different RES penetrations are considered.\nFirst, RES0 considers only conventional generation, including hydro, black coal, brown coal, combined cycle gas and open cycle gas. The generation mix consists of 2.31 hydro, 39.35 of coal and 5.16 of gas, with the peak load of 36.5. To cater for demand and generation variations, 10 reserves are maintained at all times. The generators are assumed to bid at their respective short run marginal costs, based on regional fuel prices¬†<cit.>.\n\nCases RES30, RES50, RES75 consider, respectively, 30, 50 and 75 annual energy RES penetration, supplied by wind, PV and CST. Normalized power traces for PV, CST and wind farms (WFs) for the 16-zones of the NEM are taken from the AEMO's planning document¬†<cit.>. The locations of RESs are loosely based on the AEMO's 100% RES study <cit.>.\n\n\n\n\n ¬ß.¬ß Modeling Assumptions\n\nPower traces of all PV modules and wind turbines at one plant are aggregated and represented by a single generator. This is a reasonable assumption given that PV and WF don't provide active power reserves, and are not limited by ramp rates, MUDT, and startup and shutdown costs, which renders the information on the number of online units unnecessary.\n\nAlso worth mentioning is that RES can be modeled as negative demand, which can lead to an infeasible solution. Modeling RES (wind and solar PV) as negative demand is namely identical to preventing RES from spilling energy. Given the high RES penetration in future grids, we model RES explicitly as individual generators.\nUnlike solar PV and wind, CST requires a different modeling approach. Given that CST is synchronous generation it also contributes to spinning reserves and system inertia. Therefore, the number of online units in a CST plant needs to be modeled explicitly.\n\nAn optimality gap of 1% was used for all test cases. Simulation were run on Dell OPTIPLEX 9020 desktop computer with Intel(R) Core(TM) i7-4770 CPU with 3.40 clock speed and 16B RAM.\n"
        },
        {
            "section_number": 5,
            "title": "RESULTS AND DISCUSSION",
            "summary": "Discuss the computational efficiency and accuracy of the proposed Market Simulation Tool (MST) in comparison to Binary Unit Commitment (BUC) and Aggregated Formulation (AGG), focusing on techniques like unit clustering, rolling horizon, and constraint clipping, and their impact on system stability assessments in future grid scenarios.",
            "target_length": 1400,
            "origin_content": "To showcase the computational efficiency of the proposed MST, we first benchmark its performance for different horizon lengths against the BUC formulation employing three binary variables per unit per time slot and the AGG formulation where identical units at each plant are aggregated into a single unit, which requires three binary variables per plant per time slot.\nWe pay particular attention to the techniques used for computational speedup, namely unit clustering, rolling horizon, and constraint clipping. Last, we compare the results of the proposed MST with BUC and AGG formulations for voltage and frequency stability studies.\n\n\n\n\n ¬ß.¬ß Binary Unit Commitment (BUC)\n\nWe first run the BUC for horizon lengths varying from one to seven days, Fig.¬†<ref> (top).\n\nAs expected, with the increase in the horizon length, the solution time increases exponentially. For a seven-day horizon, the solution time is as high as 25000 (7). Observe how the computational burden is highly dependent on the RES penetration. The variability of the RES results in an increased cycling of the conventional thermal fleet, which increases the number of on/off decisions and, consequently the computational burden. In addition to that, a higher RES penetration involves an increased operation of CST. This poses an additional computational burden due to the decision variables associated with TES that span several time slots.\nIn summary, the computational burden of the BUC renders it inappropriate for scenario analysis involving extended horizons.\n\n\n\n\n ¬ß.¬ß Aggregated Formulation (AGG)\n\nAggregating identical units at a power plant into a single unit results in a smaller number of binary variables, which should in principle reduce the computational complexity.\nFig.¬†<ref> confirms that this is mostly true, however, for RES50-HL7 the computation time is higher than in the BUC formulation. The reason for that is that, in this particular case, the BUC formulation has a tighter relaxation than the AGG formulation and, consequently, a smaller root node gap. Compared to the MST formulation, with a similar number of variables than the AGG formulation, the MST has considerably shorter computation time due to a smaller root node gap.\n\nIn terms of accuracy, the AGG formulation works well for balancing studies¬†<cit.>. On the other hand, the number of online synchronous generators in the dispatch differs significantly from the BUC, which negatively affects the accuracy of voltage and frequency stability analysis, as shown later. Due to a large number of online units in a particular scenario, a direct comparison of dispatch levels and reserves from each generator is difficult. Therefore, we compare the total number of online synchronous generators, which serves as a proxy to the available system inertia. Fig.¬†<ref> shows the number of online generators of four different RES penetration levels for a horizon length of seven days. For most of the hours there is a significant difference between the number of online units obtained from the BUC and the AGG formulation.\n\n\nIn conclusion, despite its computational advantages, the AGG formulation is not appropriate for stability studies due to large variations in the number of online synchronous units in the dispatch results. In addition to that, the computational time is comparable to the BUC in some cases.\n\n\nWe now evaluate the effectiveness of the techniques for the computational speedup.\n\n\n\n  ¬ß.¬ß.¬ß Unit Clustering\n\nIn unit clustering, binary variables associated with the generation unit constraints are replaced with a smaller number of integer variables, which allows aggregating several identical units into one equivalent unit, but with the number of online units retained. This results in a significant reduction in the number of variables and, consequently, in the computational speedup. Compared to the BUC, the number of variables in the MST with this technique alone reduces from 24649 to 5990 for RES75 with a horizon length of seven days. Therefore, the solution time for RES75-HL7 reduces from 25000 in the BUC to 450 in MST with unit clustering alone.\n\n\n\n  ¬ß.¬ß.¬ß Rolling Horizon Approach\n\nA rolling horizon approach splits the UC problem into shorter horizons. Given the exponential relationship between the computational burden and the horizon length, as discussed in Section¬†<ref>, solving the problem in a number of smaller chunks instead of in one block results in a significant computational speedup. The accuracy and the consistency of the solution are maintained by having an appropriate overlap between the adjacent horizons. However, the overlap depends on the time constants of the problem. Long term storage, for example, might require longer solution horizons. The solution times for different RES penetrations are shown in Table¬†<ref>. Observe that in the RES75 case, the effect of rolling horizon is much more pronounced, which confirms the validity of the approach for studies with high RES penetration.\n\n\n\n\n\n\n\n\n\n\n\n\n\n  ¬ß.¬ß.¬ß Constraint Clipping\n\nEliminating non binding constraints can speedup the computation even further. Table¬†<ref> shows the number of constraints for different scenarios with and without constraint clipping. Observe that the number of redundant constraints is higher in scenarios with a higher RES penetration. The reason is that a higher RES penetration requires more flexible gas generation with ramp rates shorter than the time resolution (one hour in our case). Note that the benefit of constraint clipping with a shorter time resolution will be smaller.\n\n\n\n\n\n ¬ß.¬ß MST Computation Time and Accuracy\n\nThe proposed MST outperforms the BUC and AGG in terms of the computational time by several orders of magnitude, as shown in Fig.¬†<ref> (bottom). The difference is more pronounced at higher RES penetration levels. For RES75, the MST is more than 500 times faster than the BUC. In terms of the accuracy, the MST results are almost indistinguishable from the BUC results, as evident from Fig.¬†<ref> that shows the number of online synchronous units for different RES penetration levels. Minor differences in the results stem from the nature of the optimization problem. Due to its mixed-integer structure, the problem is non-convex and has therefore several local optima. Given that the BUC and the MST are mathematically not equivalent, the respective solutions might not be exactly the same. The results are nevertheless very close, which confirms the validity of the approach for the purpose of scenario analysis. The loadability and inertia results presented later further support this conclusion.\n\n\n\n\n ¬ß.¬ß Stability Assessment\n\nTo showcase the applicability of the MST for stability assessment, we analyze system inertia and loadability that serve as a proxy to frequency and voltage stability, respectively. More detailed stability studies are covered in our previous work, including small-signal stability <cit.>, frequency stability <cit.>, and voltage stability <cit.>.\n\n\n\n  ¬ß.¬ß.¬ß System inertia\n\nFig.¬†<ref> (bottom) shows the system inertia for the BUC, AGG and the proposed MST, respectively, for RES0. Given that the inertia is the dominant factor in the frequency response of a system after a major disturbance, the minuscule difference between the BUC and the MST observed in Fig.¬†<ref> validates the suitability of the MST for frequency stability assessment. The inertia captured by the AGG, on the other hand, is either over or under estimated and so does not provide a reliable basis for frequency stability assessment.\n\n\n\n  ¬ß.¬ß.¬ß Loadability Analysis\n\nThe dispatch results from the MST are used to calculate power flows, which are then used in loadability analysis[The loadability analysis is performed by uniformly increasing the load in the system until the load flow fails to converge. The loadability margin is calculated as the difference between the base system load and the load in the last convergent load flow iteration.]. Fig.¬†<ref> (top) shows loadability margins for the RES0 scenario for different UC formulations. Observe that the BUC and the MST produce very similar results. The AGG formulation, on the other hand, gives significantly different results. From hours 95 to 150, in particular, the AGG results show that the system is unstable most of the time, which is in direct contradiction to the accurate BUC formulation.\nCompared to the inertia analysis, the differences between the formulations are much more pronounced.\nUnlike voltage, frequency is a system variable, which means that it is uniform across the system. In addition to that, inertia only depends on the number of online units but not on their dispatch levels.\nVoltage stability, on the other hand, is highly sensitive both to the number of online units and their dispatch levels, which affects the available reactive power support capability, as illustrated in Fig. <ref>.\nClose to the voltage stability limit, the system becomes highly nonlinear, so even small variations in dispatch results can significantly change the power flows and, consequently, voltage stability of the system. One can argue that in comparison to BUC  the proposed MST result in the more conservative loadability margin, although this is not always the case (around hour 85, the MST is less conservative).\n"
        },
        {
            "section_number": 6,
            "title": "CONCLUSION",
            "summary": "Discuss the effectiveness and implications of the proposed computationally efficient electricity market simulation tool for future grid scenario analysis, highlighting the impact of the techniques used on computational speedup and accuracy, as well as their suitability for long-term grid studies.",
            "target_length": 300,
            "origin_content": "This paper has proposed a computationally efficient electricity market simulation tool based on a UC problem suitable for future grid scenario analysis. The proposed UC formulation includes an explicit network representation and accounts for the uptake of emerging demand side technologies in a unified generic framework while allowing for a subsequent stability assessment. We have shown that unit aggregation, used in conventional planning-type UC formulations to achieve computational speedup, fails to properly capture the system inertia and reactive power support capability, which is crucial for stability assessment. To address this shortcoming, we have proposed a UC formulation that models the number of online generation units explicitly and is amenable to a computationally expensive time-series analysis required in future grid scenario analysis. To achieve further speedup, we use a rolling horizon approach and constraint clipping.\n\nThe effectiveness of the computational speedup techniques depends on the problem structure and the technologies involved so the results cannot be readily generalized. The computational speedup varies between 20 to more than 500 times, for a zero and 75% RES penetration, respectively, which can be explained by a more frequent cycling of the conventional thermal units in the high-RES case. The simulation results have shown that the computational speedup doesn't jeopardize the accuracy. Both the number of online units that serves as a proxy for the system inertia and the loadability results are in close agreement with more detailed UC formulations, which confirms the validity of the approach for long term future grid studies, where one is more interested in finding weak points in the system rather than in a detailed analysis of an individual operating condition.\n\n\n\n\n\n\nIEEEtran\n"
        }
    ],
    [],
    [],
    [
        {
            "section_number": 1,
            "title": "INTRODUCTION",
            "summary": "Discuss the importance of personalized instructor responses to student reflections in countering weed-out culture in physics education, and explore how the Guided Reflection Form (GRF) fosters supportive student-teacher relationships in an introductory lab course.",
            "target_length": 1000,
            "origin_content": "Reflection is an important skill in learning physics,<cit.> and is a key part of learning more generally.<cit.> Previously we have described how structured reflection activities can augment physics courses that focus on iterative improvement of models<cit.> and apparatuses.<cit.> We have also developed an online tool, the Guided Reflection Form (GRF), that facilitates student reflection and personalized instructor responses.<cit.>. The GRF was designed to support students in describing a past experience, setting a goal for improvement, and identifying specific steps for achieving that goal. In a study of the GRF, we focused on the structure of students' reflections in a physics course for future teachers; students in that study successfully used the GRF to narrate specific experiences upon which they wanted to improve and articulate goals and/or action plans for improvement.<cit.> In this article, we explore the GRF activity in a different context and from a different perspective. Here, we focus on how the GRF was implemented in an introductory lab course, and we characterize the types of feedback that the two instructors of that course provided in response to their students' reflections.\n\nOur analysis of instructors' responses to students' reflections is motivated by an overarching desire to cultivate a culture of support and inclusiveness in undergraduate physics courses. In particular, we aim to develop and implement research-based educational tools that may counter weed-out culture. We consider weed-out culture to be a set of traditional educational practices and beliefs aimed at sorting and selecting the students seen as most capable, while ‚Äúweeding out\" the rest (i.e. removing them from the system). In their landmark study of undergraduate student attrition from science, mathematics, and engineering majors, Seymour and Hewitt described the disproportionate impacts of this culture on marginalized groups:<cit.>\n\nThe most serious criticisms of the weed-out system, however, focused on its disproportionate impact on men of color and on all women. Even well-prepared, these two groups tend to enter basic classes feeling uncertain about whether they `belong.' The loss of regular contact with high school teachers who encouraged them to believe in their ability to do science exposes the frailty of their self-confidence. Faculty who teach weed-out classes discourage the kind of personal contact and support which was an important part of high school learning. It is, as some students describe, a `weaning away' process by which faculty transmit the message that it is time to grow up, cast aside dependence on personally-significant adults and take responsibility for their own learning. This attitude is perceived by students in the reluctance of teachers to answer questions, brusqueness in response to `trivial' inquiries, failure to offer praise or encouragement, disinclination to discuss academic difficulties in a personal manner, carelessness in keeping office hours, and a `no excuses' stance on test results. The difficulty of getting personal attention was troubling to many students, but it was especially troubling to those whose presence in [science, mathematics and engineering] classes was the result of considerable personal attention and encouragement by particular high school teachers. (p.¬†132)\n\nThe GRF was designed to provide avenues of communication through which instructors and students can engage in precisely those interactions that are discouraged by weed-out culture. As educators ourselves, the authors of the paper have used the GRF to this end in multiple contexts. In the current study, our goal was to understand the extent to which the GRF opens up such opportunities for other instructors, particularly those who were not involved in the iterative design process through which the GRF was developed. Indeed, as we will show, both instructors in our study perceived the GRF as valuable for developing personally-significant relationships with their students, and both used itused the GRF to provide their students with personal attention and encouragement.\n\nWhen imagining how instructors might ideally use the GRF to foster supportive student-teacher relationshipsinteractions, Brown's metaphor of ‚Äúsitting on the same side of the table\"<cit.> is helpful. Brown drew on this metaphor to create a checklist for feedback that includes items like sitting ‚Äúnext to you rather than across from you,\" putting ‚Äúthe problem in front of us rather than between us (or sliding it toward you),\" and modeling ‚Äúthe vulnerability and openness that I expect to see from you\"¬†(p.¬†204). After outlining her checklist, she asked,\n\nHow would education be different if students, teachers, and parents sat on the same side of the table? How would engagement change if leaders sat down next to folks and said, ‚ÄúThank you for your contributions. Here's how you're making a difference. This issue is getting in the way of your growth, and I think we can tackle it together. What ideas do you have about moving forward? What role do you think I'm playing in the problem? What can I do differently to support you?\" (pp.¬†204‚Äì205)\n\nThe image of two people sitting on the same side of the table inspires our vision for how the GRF could shape classroom practices in physics: instructors and students working side-by-side to tackle academic problems together, building meaningful student-teacher relationships along the way.\n\nWe present a qualitative exploration of two instructors' implementations of the GRF in a lab course for first-semester undergraduate students interested in majoring in physics. The instructors were physics graduate students, and the course was designed and offered as part of a student-led diversity initiative in the instructors' physics department.  We conducted hour-long post-semester interviews with both instructors, and we collected electronic copies of 134 student reflections and corresponding instructor responses that were generated via the GRF. Using these data, we construct a rich picture of each instructor's unique implementation.\n\nThis paper is organized as follows. In Sec.¬†<ref>, we describe the GRF activity and provide a brief overview of some of the literature on feedback. We describe the programmatic and course context for our study in Sec.¬†<ref>, outline our research methods in Sec.¬†<ref>, and present results from our analyses of instructors' interviews and GRF responses in Sec.¬†<ref>.  Finally, in Sec.¬†<ref>, we summarize our findings, discuss their implications, and identify potential future directions for research and development of the GRF.\n"
        },
        {
            "section_number": 2,
            "title": "BACKGROUND",
            "summary": "Write a section that explores the principles and practices of providing personalized instructor feedback through the Guided Reflection Form (GRF), emphasizing the impact of mindset on feedback effectiveness and the importance of fostering a supportive learning environment.",
            "target_length": 1200,
            "origin_content": "We begin our discussion by describing the GRF and summarizing relevant literature about instructor feedback practices. When describing the GRF, we focus on how it has typically been used in other courses we have taught and/or studied. The instructors in the present study deviated slightly from this typical usage, as discussed in Sec.¬†<ref>.\n\n\n\n\n\n\n ¬ß.¬ß Guided Reflection Form\n\nThe GRF has been described in detail elsewhere,<cit.> so we provide only a brief overview here. The GRF is an online tool, similar to a survey, that provides questions and other prompts to guide student reflections about issues of resilience, collaboration, and organization. Once per week, students are tasked with submitting a reflection via the GRF. Reflections may focus on any aspect of the students' learning experience, whether or not it is directly related to the course in which the GRF is being implemented. Instructors then read the reflections and provide individualized responses to each student based on the content of their (the students') reflection. This cycle of reflection and feedback repeats, ideally facilitating an ongoing written dialogue between each student and the instructor.\n\nStudent responses can be collected by having students complete an online survey or submit individual electronic documents. In the former case, instructors can export student reflections into a spreadsheet, write their responses in the spreadsheet, and then use a mail merge program to generate individual documents with student responses and corresponding instructor feedback. In the latter case, the instructor can write their feedback directly on the submitted document.  Based on our own experiences using the GRF, responding to reflections takes about 3 to 5 min per student. Instructors in this study reported spending about 10 to 15 min per student responding to reflections. In large classes, the time required for an instructor to respond to each student individually can be prohibitively large; hence, this activity is most suitable for classes with 10 to 20 students per instructor or, in larger courses, per teaching or learning assistant. The GRF has been implemented in a variety of contexts, including high school-level computer science and upper-division quantum mechanics.\n\nWhen using the GRF, students are presented with a prompt instructing them to recall a scenarioan experience from the previous week upon which they would like to improve. Such experiences could include, for example, procrastinating on a long-term project.<cit.> Next, they are asked to choose one of three focus areas for reflection: bouncing back from failure or other setbacks; building a network and developing collaboration skills; or becoming an organized, self-aware, and mindful person. For students who would prefer to write about a different topic, the GRF includes a fourth option for ‚Äúsomething different.\" After students choose a topic for their reflection, the GRF presents a short paragraph describing the importance of the skills related to the topic. Regardless of topic, students are asked to write short responses to two reflection prompts:\n\n\n  * Describe the specific experience from last week that you would like to improve upon.\n\n  * Describe an aspect of this experience that you can improve in the future. (Provide at least one concrete strategy that you will use to become more successful.)\n\nThe GRF prompts were designed with three aspects of reflection in mind: students should (i) revisit a salient experience from the previous week, (ii) set a future goal for improvement, and (iii) articulate specific steps for achieving that goal. In a study of undergraduate students using the GRF in a pedagogy course for future physics teachers, we found that all students successfully used the GRF to engage in multiple aspects reflection.<cit.> In this article, we explore for the first time the ways that instructors use the GRF to provide feedback to their students.\n\n\n\n\n\n\n ¬ß.¬ß Feedback\n\n\nProviding feedback to students has a significant impact on their learning, but not all feedback is equally useful. For instance, there are a number of characteristics that make feedback effective, including specificity and timeliness.<cit.> Process-level feedback is particularly effective for enhancing learning; such feedback focuses on students' ability to strategize about their learning and to seek help when needed.<cit.> When students receive feedback about their learning strategies, it draws attention to the ways in which they can adapt to become more effective learners.<cit.> In contrast, praise can have unpredictable impacts‚Äîand can even inhibit learning, especially if it is perceived as undeserved‚Äîbecause it draws students' attention to themselves rather than the task at hand.<cit.>\n\nA popular way of interpreting these findings is through the concept of mindset;<cit.> indeed, this concept informed the perspectives of one of the instructors in our study. Here, ‚Äúmindset\" refers to students' beliefs about the nature of intelligence. Mindset is commonly described using a fixed/growth dichotomy: in the extreme cases, people with a fixed mindset view intelligence as static and unchangeable beyond a predetermined level, whereas those with a growth mindset view intelligence as malleable and something that can be improved with effort.<cit.> Using the language of mindset, providing process-level feedback is consistent with a growth mindset.<cit.> In particular, feedback that emphasizes self-improvement can bolster students' beliefs in their own capability to succeed.<cit.> On the other hand, praising a student for being ‚Äúsmart\" may reinforce a fixed mindset,<cit.> and feedback that communicates a lack of faith in a student's capabilities can undermine their confidence, motivation, and willingness to attempt challenging tasks.<cit.>\n\n\nFrom this literature, we infer two principles that could support instructors' effective use of the GRF:\n\n\n  P1. Praise should should focus on students' efforts to improve, express confidence in their ability to improve, and be sincere.\n\n  P2. Process-level feedback should identify specific areas for improvement and suggest strategies that students can use to improve their learning.\n\nEach principle is also informed by a particular aspect of weed-out culture, as described by Seymour and Hewitt.¬†<cit.> In particular, they identified instructors' ‚Äúfailure to offer praise\" and ‚Äúdisinclination to discuss academic difficulties in a personal manner\" as factors contributing to weed-out culture. However, because not all forms of praise support student perseverance, P1 recommends a particular process for giving praise. Similarly, P2 can be thought of as a guideline for how instructors can discuss academic difficulties with students. Taken together, these two principles align with part of Brown's vision for students and teachers sitting on the same side of the table.¬†<cit.> For example, should a teacher say to a student, ‚ÄúThis issue is getting in the way of your growth, and I think we can tackle it together,\" they would be identifying an area for improvement (P2) and expressing confidence in the student's ability to improve (P1).\n\n\nImportantly, feedback must be understood in the context of the learning environment in which it is given and received. For instance, feedback is more effective when instructors create classroom communities that normalize failure and value criticism. Students in these settings are better situated to receive and use feedback.<cit.> Therefore, one way for instructors and students to sit on the ‚Äúsame side of the table\" is to be embedded in a culture where students are in the habit of receiving timely, sincere, and critical feedback focused on their strategies for self-improvement. In the sections that follow, we describe a course in which the instructors aspired to foster such a culture, in part by using the GRF.\n"
        },
        {
            "section_number": 3,
            "title": "CONTEXT",
            "summary": "Describe the detailed context and structure of the study involving two instructors' feedback practices in a physics course at the University of Colorado Boulder, focusing on the organizational background, course design, and implementation of the Guided Reflection Framework (GRF) activity.",
            "target_length": 1000,
            "origin_content": "Our study is an exploratory qualitative investigation of two instructors' feedback practices. As Eisenhart argues,<cit.> such qualitative studies are responsible for ‚Äúproviding sufficient detail about the researched context for a person with intimate knowledge of a second context to judge the likelihood of transferability.\"¬†(p. 56). Accordingly, we describe the context for our study at three grain sizes: organization, course, and activity.\n\n\n\n ¬ß.¬ß Organizational context\n\n\nThe two instructors in our study‚ÄîEmily and Taylor‚Äîwere both physics graduate students at the University of Colorado Boulder (CU), a predominantly white public R1 university with a large physics program. Emily was a white woman and Taylor was a white man. They co-taught a course called Foundations of Scientific Investigation (hereafter ‚ÄúFoundations\"). Foundations was designed as part of a student-led organization called CU-Prime. CU-Prime is a member of The Access Network (hereafter ‚ÄúAccess\").[The Access Network, <http://accessnetwork.org>] Access organizations‚Äîincluding The Berkeley Compass Project,<cit.> The Chi-Sci Scholars Program,<cit.> and several other organizations‚Äîare characterized by student leadership and a commitment to improving diversity in the physical sciences through community building. To achieve their goals, these organizations offer multiple services designed to support students from underrepresented groups and raise awareness about issues of marginalization in physics. Examples of services include summer programs,<cit.> diversity workshops,<cit.> mentorship programs,<cit.> and courses with multi-week final projects.<cit.> Many of the courses designed and run by Access organizations use the GRF or similar tools to facilitate cycles of student reflection and instructor feedback. In this work, we focus on the implementation of the GRF in Foundations.\n\n\n\n ¬ß.¬ß Course description\n\n\nFoundations was first designed and taught in 2014 and was subsequently refined and taught in 2015 and 2016. It is a 14-week, fall-semester course designed for first-year undergraduate students interested in majoring in physics. On average, 22 students enroll in Foundations each semester. Students from underrepresented and/or minority racial and gender groups are especially encouraged to participate in the course; a demographic breakdown of students who completed the course is provided in Table¬†<ref>. The overarching goals of Foundations are twofold: build community among students enrolled in the course, and introduce students to the practice of research. Two corresponding subgoals are for students to practice developing theoretical models of scientific phenomena, and to reflect on and refine their coursework in Foundations and other courses.\n\nEach semester, the Foundations class met twice weekly for 75 minutes per meeting, and the course consisted of 2 successive 7-week halves. Consistent with the subgoals of the course, each half included both experimental activities that focused on building models as well as activities that engaged students in the practice of reflection.  During the first half of the course, students worked in groups on a set of guided optics experiments. They also used the GRF to reflect on their collaboration, organization, and resilience. During the second half, students worked in groups on multi-week final projects under the guidance of graduate student mentors; a similar approach to final projects has been described elsewhere.<cit.> In this part of the course, students used a tool similar to the GRF to reflect on goals, challenges, and successes related to their final projects.\n\n\n\nSince its inception, Foundations has been divided into 2 parallel sections of about 10 students. Each section has been co-taught by 2 instructors, for a total of 4 instructors per semester. By design, each co-teaching pair has been mixed gender and has comprised one undergraduate student and one graduate student. Most instructors have only taught the course once, and former instructors meet with new instructors during the summer to discuss teaching strategies for the upcoming fall semester.  Emily and Taylor taught Foundations concurrently, but in different sections. Hence, each was a member of a co-teaching pair, but neither was the other's co-teacher.\n\n\n\n ¬ß.¬ß GRF activity\n\n\nWe introduced Emily, Taylor, and their co-teachers to the GRF during the summer before they started teaching the course. Based on discussions between the authors and the instructors, the instructors' implementation of the GRF differed from that described in Sec.¬†<ref> in two ways. First, the GRF was assigned only during the first half of the course. This choice was made because a different reflection tool was deemed more appropriate for the second half of the course. Second, GRF focus areas were assigned by the instructors. Reflections focused on collaboration during weeks 1 and 2, organization during weeks 3, 4, and 5, and resilience in weeks 6 and 7. This choice was informed in part by the anticipated progression of student-to-student relationships in the course. Students would still be getting to know their group members during the first couple weeks of the semester, and they might not feel comfortable sharing about their experiences of failure with their instructors until several weeks had passed. This choice was also informed by the fact that many introductory courses have multiple midterms, making it important to develop good time management practices as early as possible. Although students were not graded on the quality of their reflections, they were awarded a small amount of course credit for completing the GRF activity.\n\nAt the start of the fall semester, we provided Emily and Taylor with guidelines for giving feedback.<cit.> The guidelines were based on our experiences with the GRF<cit.> and a precursor to the GRF,<cit.> and they emphasized the importance of communicating the goal of the activity to students as well as providing feedback on both the structure and content of students' reflections. Based on the instructors' internal decisions about division of labor, Emily and Taylor were each solely responsible for responding to all the reflections written by students in their respective sections; their co-teachers did not provide any individualized written feedback to students via the GRF activity. In this paper, we explore the ways that Emily and Taylor incorporated the GRF into their teaching. In doing so, we aim to provide clear examples of instructor feedback, as facilitated by the GRF. These examples could inform future instructors' use of the GRF in other  contexts.\n"
        },
        {
            "section_number": 4,
            "title": "METHODS",
            "summary": "Describe the methods used to explore how two instructors, Emily and Taylor, implemented the Guided Reflection Framework (GRF) in a university Foundations course, including the process of conducting interviews, analyzing instructor responses, and developing a coding scheme to categorize feedback types.",
            "target_length": 1700,
            "origin_content": "ThisThere are multiple ways in which the goals of the GRF, the Foundations course, and the CU-Prime organization are theoretically aligned. One line of reasoning is as follows: Seymour and Hewitt noted that weed-out culture has a ‚Äúdisproportionate impact on men of color and all women;\"<cit.> these populations are better represented in Foundations than in the CU Physics Department as a whole (Table¬†<ref>); the GRF was designed to counter some aspects of weed-out culture; and, finally, the Foundations course was designed to support CU-Prime's commitment to improving diversity in physics. Thus, implementing the GRF in Foundations is in alignment with the diversity-oriented mission of CU-Prime. More narrowly, the GRF directly aligns with the course goal of engaging students in the practice of reflection. However, our present focus is not on student experiences or outcomes as they relate to improving diversity in physics. Rather, we are interested in teacher practices. Accordingly, this study is a qualitative exploration of the ways that Emily and Taylor implemented the GRF in the Foundations course.\n\nWe conducted post-semester interviews with both Emily and Taylor, focusing on their goals for, perspectives on, and engagement with the GRF activity. To corroborate the instructors' self-reported response practices, we also collected and analyzed all instructor responses that were generated via the GRF. Thus, our study enables us to describe how Emily and Taylor implemented the GRF using their own words and authentic examples of the responses they provided to students. Our goal is not to make generalizable statements about either the GRF or instructors who use it, but rather to provide insight into the various ways that instructors might take up the GRF for use in their classrooms. In this section, we describe our data sources and analysis methods.\n\n\n\n\n\n\n ¬ß.¬ß Post-semester interviews\n\n\nAt the end of the semester, we conducted semi-structured interviews with Emily and Taylor to gain insight into their perspectives on the GRF and other aspects of the course. Emily and Taylor were interviewed separately, each for about an hour.  Interviews focused in part on threetwo themes: the instructors' perceptions about the (i) goals and framing of the GRF activity, and (ii) characteristics of good or bad feedback, and (iii) impacts of the GRF on the nature of teacher-student relationships. We chose the first twothese themes because they give us insight into why and how the instructors were using the GRF. The third theme was chosen because it reflects a goal of the Foundations course that runs counter to weed-out culture: to foster supportive relationships among students and teachers.\n\nThe first author transcribed both interviews, and the transcripts are the data that we analyzed. We collaboratively identified all excerpts that addressed the three themes that comprised the foci of our interviews. For each theme, we selected several representative excerpts and constructed two vignettes about the implementation of the GRF, one each for Emily and Taylor. These vignettes are presented in Sec.¬†<ref>.\n\n\n\n\n\n\n ¬ß.¬ß GRF responses\n\n\nIn total, 22 students were enrolled in Foundations: 10 in Emily's section and 12 in Taylor's. Each student was required to complete 7 reflections using the GRF. Of 154 possible GRF-based reflections, 135 were submitted. This corresponds to a completion rate of 88%, which is consistent with the GRF completion rate observed in another study.<cit.> The majority of students completed all or most reflections: 12 students completed all 7 reflections, 8 completed 5 or 6, and 2 completed 3 or 4. This distribution was roughly the same in both sections, resulting in similar completion rates for Emily's section (90%) and Taylor's section (86%). Each instructor responded only to reflections completed by students enrolled in their section. Almost every submitted reflection received a personalized response from either Emily or Taylor; only 1 reflection received no instructor response.\n\nWe analyzed both instructors' GRF responses using an a priori coding scheme. This scheme was not directly informed by existing frameworks for effective feedback, such as those described in Sec.¬†<ref>. Rather, our goal was to explore these data through an analytic lens informed by the language associated with the tool itself. Hence our scheme was directly informed by the guidelines<cit.> we gave to Emily and Taylor at the start of the semester as well as a preliminary analysis of the instructors' feedback styles as self-reported during interviews. Based on our guidelines, we created code categories for normalizing statements, empathizing statements, resource suggestions, and feedback on the structure of the reflection. Based on our preliminary analysis of Emily's and Taylor's interviews, we created additional code categories for encouraging statements and strategy suggestions, respectively. Thus, our coding scheme included categories corresponding to 6 distinct types of response:\n\n\n  * Encouraging statements serve to motivate the student or validate their experiences and efforts. Examples include: ‚ÄúYou're doing great,\" ‚ÄúI believe in you,\" ‚ÄúYou can do this,\" and, ‚ÄúI'm glad you're using this strategy.\"\n\n  * Normalizing statements involve communicating to the student that what they are experiencing is normal, common, and/or unsurprising; this can be accomplished by relaying a personal anecdote or making an appeal to the general student experience. Examples include: ‚ÄúI experienced something similar,\" and ‚ÄúLots of students go through this.\"\n\n  * Empathizing statements involve empathizing with the student cognitively, in a parallel emotional capacity, or in a reactive emotional capacity. Examples include: ‚ÄúI understand where you're coming from,\" ‚ÄúYour story makes me feel upset, too,\" and ‚ÄúI'm excited that you are enjoying class.\"\n\n  * Strategy suggestions include both direct and indirect suggestions, the latter of which may take the form of anecdotes or questions. Examples include: ‚ÄúYou should use a day planner,\" ‚ÄúWhen I was in this situation, I used a day planner,\" and ‚ÄúHave you thought about using a day planner?\"\n\n  * Resource suggestions also include both direct and indirect suggestions. Examples include: ‚ÄúYou should go to office hours,\" ‚ÄúWhen I was in this situation, office hours were very helpful,\" and ‚ÄúHave you thought about going to office hours?\"\n\n  * Feedback on reflection structure focuses on the way the student wrote their reflection‚Äîsuch as whether the reflection provided enough detail or articulated a goal/strategy for improvement‚Äîand may be formulated as a comment or question. Examples include: ‚ÄúPlease write a longer reflection next week,\" and ‚ÄúHow can you achieve this goal?\"\n\nSome individual statements received two codes. For example, empathizing with a student by normalizing their feelings was a common strategy for Emily, and about half of her empathizing statements were also coded as normalizing statements.In terms of the principles for feedback outlined in Sec.¬†<ref>, categories 1 to 3 map onto principle P1, which suggests that praise focus on students' efforts and be sincere. While student data would be needed to determine the perceived sincerity of instructor feedback, normalizing and empathizing statements could contribute to such perceptions. Categories 4 to 6 map onto principle P2, which recommends that process-level feedback suggest strategies for improvement.\n\nWe coded all 134 GRF responses via the following process. The second author read through each instructor response and identified all statements that aligned with one or more categories in our coding scheme. Some individual statements received two codes. For example, empathizing with a student by normalizing their feelings was a common strategy for Emily, and about half of her empathizing statements were also coded as normalizing statements. Then, for each category, the first author read through all the coded statements to verify that they matched the category definition, making note of any statements that did not fit the category. In total, such discrepancies were identified in only 10 responses; each of these discrepancies was reconciled through discussion among both authors. While we did not analyze student reflections, we read each reflection in order to provide context for the corresponding instructor response.\n\nAn initial version of our coding scheme included categories for additional types of statements, including praise for a student's intellect, achievement, or effort, as well as instances where an instructor articulated their expectations for student behavior. However, for each of these additional categories, we found few or no corresponding statements among the GRF responses in our dataset. Hence, these categories were discarded from our analysis.\n\nMeanwhile, each of the 6 response categories in our final coding scheme appeared in at least 22% of the 134 distinct responses (see Table¬†<ref>). Moreover, each of the responses included at least 1 statement corresponding to our code categories, and most responses comprised multiple types of statement. Indeed, 62% of responses received at least 3 codes. This suggests that there was a good mapping between our a priori coding scheme and our dataset. Nevertheless, the scheme was not comprehensive. For example, it did not capture instances where instructors used the GRF to communicate with students about certain aspects of Foundations (e.g., clarifying when homework is due or responding to schedule conflicts between Foundations and campuswide events).\n\nOne limitation of this analysis is that, due to the small number of students in each section, it is not possible to make strong claims about an instructor's feedback style. Consider, for example, a scenario where one section has many students who engage in the GRF in a meaningful way on their own, but the other section has many students who instead engage in a only cursory way. In this scenario, the responses written by the instructor of the former section may include relatively few instances of structure feedback compared to those of the other. Hence, differences in the frequency of particular types of feedback may be due to differences in student populations, not differences in the two instructors' response styles. Therefore, when discussing results in Sec.¬†<ref>, we use  instructors' self-reported practices (i.e., interview data) to help interpret the results of our coding scheme. In addition, Emily and Taylor read a draft of this manuscript, and both instructors indicated that they felt their perspectives and practices were accurately portrayed.\n\nIn the following section, we report the results of our analyses of the interview data and the instructors' responses to the GRF.\n"
        },
        {
            "section_number": 5,
            "title": "RESULTS AND INTERPRETATION",
            "summary": "Analyze the implementation and impact of guided reflection feedback (GRF) activities by comparing two instructors' approaches, highlighting their goals, feedback styles, and the effects on student-teacher relationships.",
            "target_length": 4100,
            "origin_content": "A summary of our GRF response coding is provided in Table¬†<ref>. For both instructors, encouraging statements were present in most response whereas resource suggestions were relatively sparse. In comparison to Taylor's responses, Emily's GRF responses were characterized by higher rates of encouraging, normalizing, and empathizing statements. Taylor's responses yielded higher rates of strategy suggestions. With respect to the principles for sincere praise (P1) and process-level feedback (P2), Emily's feedback contained more statements that map onto P1, and Taylor's contained more that map onto P2.\n\nWe describe each instructor's implementation of the GRF activity separately. For each instructor, we draw on interview data to paint an overarching picture of their perceptions about threetwo dimensions of their implemenations: (i) goals and framing of the GRF activity, and (ii) characteristics of good or bad feedback, and (iii) impacts of the GRF on the nature of teacher-student relationships. Then, in order to characterize the instructors' responses, we discuss the results of our GRF response coding. We focus on Emily first and Taylor second.\n\n\n\n\n\n\n ¬ß.¬ß Emily\n\n\nDuring her interview, Emily described a desire to bolster students' confidence through praise, and to avoid criticizing students, and foster trusting and friendly relationships with her students. Coding of GRF responses (Table¬†<ref>) revealed that encouraging and normalizing statements were each present in most of her responses. Empathizing statements, strategy suggestions, and feedback on structure were each present in about half of her responses. Resource suggestions were the least common category among her responses.\n\n\n\n  ¬ß.¬ß.¬ß Vignette: Emily's implementation\n\n\n\nWhen asked about the purpose of the reflection activity, Emily said that her goal was simply ‚Äúgetting students to reflect.\" She said that it was important to give students an opportunity to reflect because reflection is ‚Äúactually pretty important, but sometimes it's hard to set aside time in your day\" to reflect.\nReflecting is something that you may just not do. ‚Ä¶ It's actually pretty important, but sometimes it's hard to set aside time in your day or in your life to step back and reflect on what you're doing. So I guess using [the GRF] in the class was a way to give students‚Äîlike, you have to reflect on your life‚Äîalmost forcing them to make time to reflect. Then maybe it can become a habit later.Emily\nEmily said she hoped students would develop a habit of reflection that would help them avoid ‚Äúrepeating things that [they] don't necessarily want to repeat\" and ‚Äúengaging in some behavior that's not actually productive or helpful.\" When asked what she hoped her students gained from the activity, Emily said,\nI guess the ability to reflect on the good things they do every week‚Äîand not necessarily the negatives‚Äîbecause I know [the negatives are] pretty hard to not focus on. ‚Ä¶ I hope that during those reflections, and them thinking about the good stuff that they did, helps with their confidence a little bit.Emily\nHence another of Emily's goalsEmily said that another of her goals for the reflection activity was to boost students' confidence by giving them opportunities to reflect on ‚Äúthe good things they do every week.\" Emily articulated a belief that building confidence is especially important for students from underrepresented groups studying physics:\nIt sucks, but you have to be fairly confident about your ability to do science if you want to succeed in science, especially as someone from an underrepresented group. I feel like those reflections are a way to potentially build confidence because you're reflecting on things you did well and where you need to improve upon, instead of just focusing on what you did poorly. In physics, it can be really easy to just think about what you did poorly. It's extra important to build the confidence of [students from underrepresented groups] because it's a lot easier to get your confidence crushed down, I think.Emily\n\nEmily's first goal‚Äîgetting students to reflect‚Äîinformed how she framed the activity to students: Emily said she told students the GRF was ‚Äúan opportunity for y'all to reflect on what you're doing.\" This message was communicated to the students verbally once at beginning of the semester and twice more over the duration of the course. Her second goal‚Äîboosting students' confidence‚Äîinformed the type of feedback she provided.\n\nWhen asked to comment on connections between criticism and support, Emily highlighted an important tension in her understanding of these two concepts. For her, criticism was related to pointing out areas for improvement, but she saw it in opposition to supportive feedback, which she defined as ‚Äúalways positive,\" ‚Äúconstructive,\" and requiring praise. In particular, Emily saw praise as connected to improving students' confidence:\nPraise, to me, is like a confidence booster type-thing. Giving praise can give someone confidence to keep trying, or keep working hard. That's mostly it. Praise is meant to encourage people to keep up their good work. ‚Ä¶ It makes it feel like you're doing something right, you're doing something okay, and you have the ability to keep doing it.Emily\n\nOn the other hand, Emily described bad feedback as ‚Äúgeneric,\" ‚Äúnot sincere or not personal,\" and/or ‚Äúnot necessarily positive or encouraging.\" She suggested that a lack of sincerity could potentially limit the positive impacts of praise.\nThere's probably a way that praise can also be not supportive. If it doesn't feel like it's genuine, that could be potentially not supportive praise. Usually, [praise] would be supportive, but I think it could potentially be not supportive.Emily\n\nEmily said she preferred encouragement to criticism because she perceived critical feedback as hurtful:\nI try to be encouraging even if they're doing something wrong. ‚Ä¶ [I am] never super critical. I try to be really not critical because I'm a really sensitive person, so I know that it hurts to receive critical feedback, so I avoid it all costs.Emily\nShe described the boundary between supportive and unsupportive critical feedback as ‚Äúa fairly thin line\" that she tries to ‚Äústay above, towards the supportive end.\" Nevertheless, she acknowledged that criticism and support ‚Äúinteract in very complex ways,‚Äù and that students' learning can be supported by critical feedback, or hindered by its omission.\n\nDespite seeing value in praise, Emily recognized that providing only praise may not always be the best strategy: ‚ÄúIf you're not critical and you constantly say, `Close! Good job!,' then they may not try to improve or learn as much.\" She  drew connections between lack of critical feedback, insincere praise, and the nature of student-teacher relationships:\nI feel like not being critical and being supportive can really enhance student-teacher relationships, but I also feel like it could potentially hurt the student-teacher relationship if you aren't being critical to the point that students start to not learn. If I'm being supportive and not critical, but then you start doing poorly in my class, you're not going to like me as much because it's like, `Why are you letting me do poorly in this class while you tell me I'm going a good job?' It's a very delicate area.Emily\nEmily's description of the balance between praise, criticism, and support as a ‚Äúdelicate area\" highlights the tension she perceived in trying to help students build confidence as learners , supportwhile supporting them to grow in their areas of weakness, and foster meaningful student-teacher relationships.\n\nConsistent with her desire to provide supportive, constructive, and positive feedback, Emily also described a desire to establish supportive, trusting, and friendly relationships with her students. For example, when asked to describe her ideal student-teacher relationship, she said,\nI feel like it would be that [students] can trust me, to come to me if they have any issues or complaints or need help with some emotional issue or something like that. That's really important to me.Emily\nMoreover, one of Emily's most memorable moments from teaching Foundations involved a friendly exchange between Emily and one of her students:\nOne of the students came up to me [outside of class] ‚Ä¶ and said that she really, really liked the feedback and appreciated what I wrote. She wrote a lot, and I also wrote a lot. I was like, `Yeah, I feel like I'm talking to one of my friends when I'm writing your feedback.' She'd share a lot, and then I'd share, too, and I feel like I got to know her really well because of those. That was really memorable for me.Emily\nEmily suggested that the GRF activity played ‚Äúa big role\" in helping establish similarly friendly student-teacher relationships with some other students as well. However, she also described an unanticipated barrier to the type of sharing and relationship-building she was trying to achieve:\nI didn't sign my feedback. I kind of assumed [the students] would know [I was writing the feedback], but they didn't necessarily. This is something I saw in someone's reflection. They were upset that they didn't know who was reading them, because they didn't know how much they could share. ‚Ä¶ I guess that should have probably been made more explicit. `Just me and [Taylor] are reading your reflections, and that's it.'Emily\nThis example highlights how small details‚Äîlike instructors signing their feedback‚Äîcan have significant impacts on students' engagement with the GRF.\n\n\n\n  ¬ß.¬ß.¬ß Coding results: Emily's responses\n\n\nAs can be seen in Table¬†<ref>, almost all of Emily's responses included encouraging statements. Such statements were short, and the vast majority were exclamatory. Some were motivational in nature (e.g., ‚ÄúWoo! Yeah! That's the spirit!\"), while others served to validate students' actions (e.g., ‚ÄúI'm so glad you're working on managing your time!\").\n\nThe majority of Emily's responses included normalizing statements. Emily sometimes normalized a student's experience by telling a personal anecdote from her own life that mirrored the student's experience. For example, in response to a reflection in which a student described being overwhelmed by an unexpectedly heavy workload for an Organic Chemistry course, Emily said,\nI had a similar experience last year. The first few weeks of my quantum mechanics class was going over such easssyyy stuff (in my opinion) ‚Ä¶ Then all of a sudden I got slapped in the face with new material I hadn't seen before and the pace of the class started speeding up; I had a horrible time trying to catch up. I eventually did though.Emily\nSimilarly, in response to a student who struggled with getting enough sleep and who slept through a Computer Science course, Emily said,\nI can totally relate! A few weeks ago I stayed up until 3am to finish an assignment and then slept through the class the assignment was for! I definitely needed the sleep though. Since then I've been trying to plan ahead a little better to avoid such late nights.Emily\nIn each of these case, Emily drew upon a recent example from her time in graduate school in order to normalize her students' experiences.\n\nFor Emily, normalizing and empathizing often happened at the same time. Moreover, just as in the case of normalizing statements, some of Emily's empathizing statements also incorporated personal anecdotes. For example, one student described a particularly difficult lab activity that required knowing advanced Calculus content, with which the student was unfamiliar. The student concluded their reflection by saying, ‚ÄúThere may have been panic and tears involved.\" Emily responded as follows:\nAhhh. I'm sorry for the panic and tears! I've definitely experienced the tears! That sounds like it would be very stressful. It sucks they didn't really prepare you for that lab.Emily\nEmily simultaneously normalized crying while also acknowledging that the situation described by her student was unfortunate and may have been stressful. In total, about half of Emily's responses included an empathizing statement.\n\nEmily suggested strategies in about half of her responses to students. Some of Emily's suggestions were indirect, in the form of a personal anecdote:\nI use a planner to write out my tasks for the day and use [an online] calendar to keep my schedule. I have the calendar synced with my phone, so I can look at it whenever I need to and it even has reminders if I want them!Emily\nIn other cases, Emily was more direct. For example, one student wrote that, when they can't solve a problem, they often put themselves down. The student said they wanted to improve by no longer allowing setbacks to define how they feel about themselves. To this end, Emily responded with the following suggestion:\nTry thinking of yourself as one of your friends. How would you react if someone was saying the putdowns you use on yourself to one of your friends? You should have that same reaction when you use those on yourself. `My friend isn't dumb. My friend is super awesome and can work hard to overcome this.'Emily\n\nEmily provided feedback about the structure of students' reflections in about half of her responses. Her feedback was often in the form of a question that, if answered, would result in a reflection that addressed the GRF responses in a more comprehensive way (e.g., ‚ÄúWas there a specific experience that made you want to be more organized?,\" and ‚ÄúWhat, specifically, could you do to improve your organizational skills?\"). In some cases, Emily's comments about structure were formulated as requests: ‚ÄúPlease answer all of the questions in the reflection. Completing each question is helpful not only for the instructors but also for you.\"\n\nCompared to other response types, resource suggestions were the least common for Emily. When suggesting resources, Emily typically recommended that students use on-campus tutoring services and study rooms as well as online resources. She also framed the Foundations teachers (including herself) as a resource. For example, when a student described struggling with a hard physics problem, Emily offered to help: ‚ÄúIf you aren't completely tired of thinking about it, I'd be happy to talk to you about the roller coaster problem and what specifically is tripping you up.\" Consistent with her framing of the GRF activity, Emily's primary focus was on supporting students through positive, personal connections.\n\n\n\n\n\n\n ¬ß.¬ß Taylor\n\n\nDuring his interview, Taylor said he wanted students to learn how to reflect on themselves from an objective perspective, and that he aspired to provide concrete suggestions to students about how to improve. Coding of GRF responses (Table¬†<ref>) revealed that encouraging statements and strategy statements were each present in most of his responses. About half of his responses included feedback on structure, about a third included normalizing statements, and about a quarter included resource suggestions. Empathizing statements were the least common category among his responses.\n\n\n\n  ¬ß.¬ß.¬ß Vignette: Taylor's implementation\n\n\nTaylor described three major goals for the GRF. One of Taylor's goals was for students to reflect on and improve their learning, organizational skills, and mindset: ‚ÄúI hope that ‚Ä¶ they get this growth mindset, and that they take away 1 to 2 learning strategies that we gave them.\" Throughout the interview, Taylor frequently related development of reflection skills to development of a growth mindset.  Another of his goals was for students to learn how to reflect‚Äîin particular, how to do so objectively:‚Äúfrom an objective perspective.\"\nIt's probably more important that they learn how to reflect than how good an individual reflection is. If they're able to constantly reevaluate or take a step back from themselves and look at [themselves] from an objective perspective ‚Ä¶ they remove the frustration and emotional component out of their success. They're like, `Okay, I can do that, but only if I keep a cool head or a clear mind.' That's one of the goals of the reflections.Taylor\nThe third goal described by Taylor was related to the creation of an avenue for communication between students and instructors:, through which students ‚Äúcan voice problems\" and instructors can know ‚Äúwhat's going on with the students.\"\nAnother [goal] is that the instructors know much better what's going on with the students. Also the students have some confidential space where they can voice problems that they see.Taylor\n\nTaylor's focus on students' ability to take an objective perspective on their own learning and his goal of creating confidential communication pathways between students and teachers informed how he framed the activity to his students:. He said that he told students that it is important be ‚Äúable to take an objective perspective on yourself\" and to communicate with instructors ‚Äúin a very private, confidential space that is not rushed or in somebody's office.\"\nWhat I basically tried to tell them is, `What this is important for is, you are able to take an objective perspective on yourself and also a perspective that makes you a better learner. Furthermore it allows you to communicate with us in a very private, confidential space that is not rushed or in somebody's office.'Taylor\nTaylor said he communicated this framing to his class verbally at the start of the semester, and that he reinforced this framing throughout the duration of the course in his written feedback to students and in one-on-one conversations with students.\n\nTaylor described good feedback as ‚Äúlogical,\" ‚Äúconcrete,\" and ‚Äúto the point,\" whereas bad feedback was described as ‚Äúconfusing,\" ‚Äúnegative,\" and not valuing the students' effort. Taylor expressed concern about praise that focused on students' inherited traits or that was insincere. He noted that, in addition to focusing on students' effort, praise should also be tailored to the circumstances of the particular student being praised:\nYou should praise definitely the effort, their attitude towards working, [rather than] the things they inherited from wherever. The other thing is, if you give a lot of praise ‚Ä¶ praise no longer becomes genuine. It just becomes some sort of mechanism. You should always try to have some personal note in there. ‚Ä¶ Praise should be individual, and it should be appropriate.Taylor\nTaylor also described providing feedback to help students develop specific study habits:\nI also gave them strategies how to change their learning schedule. There are studies that after 45 minutes it's essentially pointless to go on, you should have a short break where your brain can regenerate. I definitely wrote that on every single reflection about learning skills. A few students actually responded the following weeks that they started doing that and saw gains in their learning.Taylor\n\nHowever, heTaylor noted that it can be difficult to provide good feedback to students who write short reflections that lack specificity:\nIf you write something very general, then you can use very little words to describe a lot of situations. But the devil is in the details, and it's difficult to give the student appropriate feedback. ‚Ä¶ If you hit a certain low word count, you just cannot say a lot of things. Normally, low word count goes along with very general statements, and that's hard to give feedback on.Taylor\nAccording to Taylor, vague reflections were not conducive to concrete (i.e., good) feedback. When discussing student-teacher relationships, Taylor emphasized the difference between friend and teacher:\n[The students] were able to see me as an ally. Of course not friend, because I'm still their instructor or teacher. ‚Ä¶ I think this is just great, because you can have a personal relationship but still work with them as a teacher.Taylor\nConsistent with his interpretation of the GRF as a communication avenue between students and instructors, Taylor said that the activity gave him access to a type of working relationship with his students that he normally doesn't have access to:\nThe reflections allowed me to sometimes personally address problems with the students. ‚Ä¶ This was very helpful to establish a good working relationship with the students. This is something I normally don't have access to, but now for some students I had access to.Taylor\nHowever, Taylor was not able to use the GRF to establish this type of rapport with every student. When asked to describe something he found surprising about the course, Taylor recounted an experience with a student who wrote short reflections throughout the semester: ‚ÄúThere was one student where I could not achieve that the student wrote long reflections.\" Taylor said he tried to encourage this student to write longer reflections both in his written feedback on the GRF as well as verbally during class. These efforts did not work, which surprised Taylor:\nThat was a little bit surprising because normally students always have a lot of things to tell, and these are the things that normally nobody talks about with them. So it was somewhat surprising.Taylor\nFor Taylor, not only did short reflections make it difficult to write good feedback, they were also perceived as a barrier to connecting with studentsshort or vague reflections made it difficult to write good (i.e., concrete) feedback. Indeed, upon reading a draft of this manuscript, Taylor asked us to emphasize that short reflections were ‚Äúone of the worst obstacles\" to productive use of the GRF.\n\n\n\n  ¬ß.¬ß.¬ß Coding results: Taylor's responses\n\n\nAs can be seen in Table¬†<ref>, Taylor included encouraging statements in a majority of his responses. Many of these statements were one-word exclamations (e.g., ‚ÄúGreat!,\" and ‚ÄúNice!\"). Less often, Taylor also validated students' actions: ‚ÄúIt is very good that you acknowledge the importance of physical and psychological well-being by taking a break from work.\"\n\nA majority of Taylor's responses included strategy suggestions. Taylor's suggestions were often straightforward and direct. For example, one student described having difficulty during a group activity where some group members could not reach agreement about whether light is displaced or bent as is passes through a medium. The student said they wished they could communicate with their group. In response, Taylor recommended using an alternative mode of communication:\nHave you thought about different ways to communicate? Since it was an optical phenomenon, maybe drawings could help you to communicate your thoughts, to also solidify them for yourself.Taylor\nSometimes, Taylor used anecdotes to make indirect suggestions. In response to a student who described the balance between attending class, studying, and having time to unwind as stressful and strenuous, Taylor said,\nThink also about your physical and psychological well-being by giving yourself (short) breaks from studying. I myself go for a short walk every day just to clear my head and get some fresh air.Taylor\nHere, Taylor's description of his own strategy‚Äîgoing for short walks‚Äîserved as an indirect suggestion to the student.\n\nAbout half of Taylor's responses included feedback on the structure of the reflection itself. Sometimes this feedback was formulated as a question (e.g., ‚ÄúWhat is a concrete strategy you want to use?\"), but more often it was a direct request (e.g., ‚ÄúI still would like to encourage you to write more, so I can give you better feedback.\"). Taylor's structure feedback often focused on encouraging students to write longer and more specific reflections. Another common theme was reminding students that their reflections could focus on experiences outside of the context of the Foundations course. In the following example, Taylor provided all of these types of structure feedback:\nMaybe you can expand your responses a little bit and become more concrete in the answers, e.g., what exact strategy you want to employ, or what particular obstacle you faced during the class section. Also, this reflection is not just limited to your experience in class, but about all your classes!Taylor\nSometimes, Taylor was successful in getting a student to write more; in these cases, Taylor provided feedback acknowledging the improvement (e.g., ‚ÄúYour reflection has significantly improved.\").\n\nFewer than half of Taylor's responses included normalizing and/or empathizing statements. When normalizing students' experiences, Taylor typically framed those experiences as common or typical (e.g., ‚ÄúMany students feel that way,\" and ‚ÄúEverybody needs some outside help.\"). And when empathizing with students, Taylor often focused on acknowledging their feelings (e.g., ‚ÄúIt seems that you were overwhelmed by the plethora of tasks,\" and ‚ÄúThis is a pretty terrible experience you described above.\").\n\nResource suggestions were present in about a quarter of Taylor's responses. Like Emily, Taylor also recommended that students make use of on-campus tutoring services and study rooms, online resources, and the Foundations teachers (including himself). In addition, Taylor often recommended specific books where students could find additional practice problems:\nThere is a plethora of really good books with various difficulty levels of problems ‚Ä¶ Please ask me for more if you think that this would be useful for you!Taylor\n(Note that we have omitted from the quote the names of the particular books Taylor recommended.) In this example, Taylor not only recommended specific books as a resource, but also offered himself as a resource that the student could turn to for additional recommendations.\n"
        },
        {
            "section_number": 6,
            "title": "SUMMARY AND DISCUSSION",
            "summary": "Discuss the effectiveness of the Guided Reflection Framework (GRF) in fostering personal connections between instructors and students while addressing potential challenges and areas for improvement in its implementation within a physics learning environment.",
            "target_length": 1200,
            "origin_content": "Our overarching goal for the GRF is to provide avenues through which students can receive personal attention from instructors about a variety of challenges they may experience while learning physics‚Äîinteractions that are discouraged by weed-out culture.<cit.> Our vision for its use is informed by Brown's metaphor for feedback:<cit.> instructors and students ‚Äúsitting on the same side of the table\" while working together to improve students' learning experiences. As a step toward understanding whether and how the GRF is able to support these types of interactions, we performed an exploratory qualitative study of two graduate student instructors' implementations of the GRF in an introductory lab course whose learning goals and broader programmatic context emphasized developing students' reflection skillsand fostering supportive student-teacher relationships. This learning environment not only resonated with our vision for how the GRF might ideally be used by physics instructors, it also aligned with characteristics of environments in which students are well situated to receive and use feedback.<cit.>\n\nOur analysis drew on two sources of data: (i) post-semester interviews with Emily and Taylor and (ii) their written responses to 134 student reflections. We found that Emily and Taylor both perceived that the GRF played an important role in the formation of meaningful connections with their students, and they each used all six of the following response types: encouraging statements, normalizing statements, empathizing statements, strategy suggestions, resource suggestions, and feedback to the student on the structure of their reflection. In particular, strategy suggestions were present in about half of Emily's responses and in most of Taylor's; this type of process-level feedback is especially effective for improving students' learning.<cit.>\n\nWithin CU-Prime, building community among graduate and undergraduate students is an explicit goal of many programs‚Äîincluding the Foundations course. As such, there is an inherent tension between maintaining teacher-student boundaries and cultivating friendships in Foundations. Taylor and Emily each navigated this tension differently. Both Emily and Taylor said that the reflection activity enabled them to get to know their students well and facilitated the development of personal relationships with their students that extended beyond the course context. Emily said that GRF facilitated two-directional sharing, which in turn fostered a friendship-style relationship with one of her students. In her responses, she often shared personal anecdotes as a way to empathize with students and/or normalize their experiences. Taylor, on the other hand, described a desire to establish a good working relationship with his students. He formatted his responses as if he were writing letters to his students, and he focused on suggesting concrete strategies that students could use to improve their learning habits. Thus, through the GRF, each instructor was able to establish a distinct balance between teacher and friend with which they were satisfied.\n\nAccording to Seymour and Hewitt,<cit.> weed-out culture encourages students to ‚Äúcast aside dependence on personally-significant adults and take responsibility for their own learning\" (p.¬†132)..\" We argue that, counter to this culture, the GRF supported Emily and Taylor to simultaneously position themselves as people on whom students could depend and encourage students to take responsibility for their own learning. For example, by offering to help students solve a roller-coaster problem or suggesting books with useful practice problems, Emily and Taylor framed themselves as resources for students' coursework outside the context of Foundations. Meanwhile, the instructors aimed to promote self-regulation and confidence by suggesting strategies through which students could grow as learners, as well as providing feedback on how to engage in the act of reflection itself.\n\nInstructors' feedback on the structure of students' reflections focused on the specificity, completeness, and length of reflections. In some cases, the instructors were successful in getting students to improve the quality of their reflections along these metrics. In other cases, however, they were not. During their interviews, both instructors said that short reflections made it difficult to write good feedback and/or connect with the student. However, we note that not all students may need or want to engage in the type of student-teacher interaction facilitated by the GRF. While we did not see evidence that the instructors were imposing the GRF on any of the Foundations students, we caution that doing so would be counter to the spirit of students and teachers (voluntarily) ‚Äúsitting on the same side of the table\" to tackle hard problems together. It can be difficult to know which students will respond to structure feedback and which will ignore it. The tension between improving engagement with the GRF among some students while respecting that others may not want to engage at all is an important area for future investigation.\n\nOn a related note, some students may choose to engage with the GRF in only cursory ways (or not at all) because it erroneously assumes that they experience something upon which they would like to improve on a weekly basis. The prompts may also unintentionally situate challenging experiences as failures. For example, although we did not analyze student reflections in this work, we found one excerpt from a Foundations student particularly insightful. In week 7, the student modified the GRF prompts related to resilience before reflecting on a health issue they were experiencing. At the bottom of their reflection, the student explained why they modified the prompts:\nI removed all mention of the word `failure.'  ‚Ä¶ I NEVER would have written this story on the original form. Why? Because it is NOT a story of failure, or even `something that I would like to improve upon' (original prompt #1). Potentially having a [health issue] is NOT a failure on my part ‚Ä¶ It's just a challenging situation.C06-7\nThis suggests that engagement in the GRF could be improved by making changes to both the framing and language of the activity.\n\nWe hope this paper can be a resource to physics instructors who are using the GRF or similar activities in their classrooms, especially those who are part of CU-Prime or other organizations within The Access Network and may therefore have similar learning goals and environments to Foundations. Together with previous work on structure of student reflections, this work lays the foundation for future research about the ways that feedback and reflections can be mutually informative for one another, and how the GRF impacts  student-teacher interactions (short-term) and student retention (long-term). In particular, the impact of the GRF on persistence of physics students from marginalized populations is an important topic for future investigation. Such studies will become possible in the coming years, as the first cohorts of students who completed Foundations begin graduating from college. More generally, we hope that these findings inform the implementation of the GRF in courses with small student-to-teacher ratios, or in large courses with small sections led by teaching or learning assistants. The GRF could also be implemented in informal educational contexts, including academic advising or mentorship programs.\n\n\n\n\n\n\nThis material is based upon work supported by the NSF under Grant Nos. DUE-1323101 and PHY-1125844. Both authors contributed equally to this work.\n"
        }
    ],
    [
        {
            "section_number": 1,
            "title": "INTRODUCTION",
            "summary": "Explain the discontinuous behavior of free Dirac spinors with general spin orientation at the point where mass approaches zero, and discuss how this affects the calculation of neutrino cross sections.",
            "target_length": 800,
            "origin_content": "According to the Standard Model (SM) of particle physics the\nneutrinos couple minimally to other SM particles only through V-A\ntype vertex and hence the interaction project out the left chiral\ncomponent of the neutrino field. Consequently, all interacting\nneutrinos in the SM can be accepted to be left chiral which can be\nwritten mathematically as 1/2(1-Œ≥_5)u_ŒΩ(p)=u_ŒΩ(p)\nwhere u_ŒΩ(p) is the spinor for the neutrino [In this\npaper only Dirac neutrinos and their SM interactions have been\nconsidered.]. It is well known that massless fermions are completely\nlongitudinally polarized <cit.>. They are described by pure\nhelicity states which coincide with chirality eigenstates. If the\nmass of the fermion is zero then its positive and negative helicity\nstates coincide with right-handed and left-handed chirality\neigenstates respectively. Since all SM neutrinos are left chiral,\nmassless neutrinos must be described by 100% negative helicity\nstates. On the other hand, as we know from experimental results\nobtained in Super-Kamiokande and Sudbury Neutrino Observatory that\nneutrinos oscillate and they cannot be massless\n<cit.>. Although neutrinos are not\nmassless they possess very tiny masses and hence they are\nultrarelativistic at the energy scales of current experiments.\nConsequently, during cross section calculations it is generally\nassumed (except for some direct neutrino mass measurement\nexperiments) that neutrino masses can be neglected and the neutrinos\nare described by 100% negative helicity states. Ignoring neutrino\nmasses is an approximation which is believed to be valid with a high\ndegree of accuracy for energies much greater than the neutrino mass.\nOn the contrary, we will show in this paper that the approximation\nis not as accurate as expected even in the zero-mass limit.\n\nThe crucial point which is generally skipped in the literature is\nthat the solutions of the free Dirac equation describing a general\nspin orientation have a discontinuity at the point m=0. If we take\nthe zero-mass limit of the spinor u^(s)(p) describing a general\nspin orientation we do not get, in general, its value evaluated at\nm=0, i.e., lim_m‚Üí0u^(s)(p)‚â† u^(s)(p)|_m=0\n<cit.>. According to the seminal work of Wigner\n<cit.>, strictly massless fermions are longitudinally\npolarized and described solely by helicity eigenstates. However if\nthe fermion has a non-zero mass (no matter how small it is), then it\nis allowed to have an arbitrary spin orientation which is different\nfrom longitudinal direction. It is quite surprising that the\ntransverse polarization does not disappear in the zero-mass limit\nbut it vanishes instantly at the point m=0 <cit.>.\nThis behavior is the origin of the discontinuity of the free Dirac\nsolutions with general spin. If we restrict ourself to special type\nof Dirac solutions, namely helicity states we observe that the\nhelicity states converge to the chirality eigenstates in the\nzero-mass limit and we do not encounter any discontinuity at m=0.\nHowever, the zero-mass behavior observed from helicity states is not\nvalid in general. Although the helicity states converge to the\nchirality eigenstates in the zero-mass limit, a spinor with\narbitrary spin orientation does not necessarily result in a\nchirality eigenstate in that limit. For instance, the spinor with\ntransverse polarization (relative to the direction of momentum) is\nalways given by a mixed chirality eigenstate and hence does not\nconverge to one of the chirality eigenstates left-handed or\nright-handed even in the zero-mass limit [The explicit\nexpressions for Dirac spinors describing a general spin orientation\nand their behavior in the zero-mass limit can be found in\nRef.<cit.> in detail.]. The discontinuity of the free\nDirac spinors at m=0 induces a similar discontinuity in the cross\nsections. If we calculate the cross section for a neutrino with mass\nm_ŒΩ and then take its m_ŒΩ‚Üí0 limit what we get is different\nfrom the cross section in which the neutrino is initially assumed to\nbe massless, i.e., lim_m_ŒΩ‚Üí0œÉ(m_ŒΩ)‚â†œÉ(0).\nAs a result of this discontinuous behavior, neglecting neutrino\nmasses in the cross section is not a good approximation even though\nneutrino masses are extremely small compared to the energy scale of\nthe processes that we consider.\n\n\nThe organization of the paper is as follows. In section II we review\nthe free Dirac spinors describing a general spin orientation and\ntheir discontinuous behavior at m=0. In section III-A we present\ncross section calculations in some generic SM processes, assuming\nthat neutrinos are massless. In section III-B the cross section\ncalculations are performed for massive neutrinos but the mixing\nbetween different mass eigenstates is omitted for simplicity. In\nsection III-C, a more realistic situation is considered where both\nneutrino masses and mixing are taken into account. In the\nconclusions section (section IV) we summarize the results that we\nobtain and discuss briefly some of its implications.\n"
        },
        {
            "section_number": 2,
            "title": "ZERO-MASS DISCONTINUITY OF THE DIRAC SPINORS",
            "summary": "Discuss the implications and limitations of the zero-mass discontinuity of Dirac spinors, particularly focusing on the behavior of spin orientations and chirality in the context of massless fermions and their representation in the Standard Model.",
            "target_length": 700,
            "origin_content": "Let us review shortly the free Dirac spinors describing a general\nspin orientation. Assume that in the rest frame of the fermion, its\nspin is quantized along the direction defined by the unit vector\nn‚Éó. Then, in the rest frame we can write the following\neigenvalue equations\n\n    (n‚Éó¬∑S‚Éó)\n    u^(‚Üë)_RF=+1/2 u^(‚Üë)_RF,    (n‚Éó¬∑S‚Éó)\n    u^(‚Üì)_RF=-1/2u^(‚Üì)_RF;\n\nwhere S‚Éó=1/2(\n                              [ œÉ‚Éó  0;  0 œÉ‚Éó;    ])\nis the non-relativistic 4√ó4 spin matrix. The eigenvectors\n(rest spinors) which correspond to the eiegenvalues +1/2 and\n-1/2 are called spin-up (‚Üë) and spin-down (‚Üì)\nspinors respectively. The spinor for a moving fermion can be\nobtained by applying a Lorentz boost to the spinor at rest.  Suppose\nthat S' frame is moving along negative z-axis with relative\nspeed v with respect to the rest frame of the fermion S. Then\nthe observer in the S' frame sees a moving fermion with\nfour-momentum p^Œº=(E,p‚Éó)=(E,0,0,p_z) and four-spin\n<cit.>\n\n    s^Œº=L^Œº_ŒΩ(s^ŒΩ)_RF=(p‚Éó¬∑n‚Éó/m,n‚Éó+p‚Éó¬∑n‚Éó/m(E+m)p‚Éó)\n\nwhere L^Œº_ŒΩ is the Lorentz transformation tensor and\n(s^ŒΩ)_RF=(0,n‚Éó) is the spin vector defined in\nthe rest frame of the fermion. Without loss of generality, choose\nn‚Éó=sinŒ∏ xÃÇ+ cosŒ∏ ·∫ë, i.e., n‚Éó\nis in the z-x plane which makes an angle Œ∏ (polar angle)\nwith respect to the z-axis. Then according to an observer in S',\nthe spin-up (‚Üë) and spin-down (‚Üì) spinors\ndescribing a general spin orientation are given by\n<cit.>\n\n    u^(‚Üë)(p)=cos(Œ∏/2) u^(+)(p)+sin(Œ∏/2) u^(-)(p)\n\n    u^(‚Üì)(p)=cos(Œ∏/2) u^(-)(p)-sin(Œ∏/2) u^(+)(p)\n\nwhere u^(+)(p) and u^(-)(p) represent positive and negative\nhelicity spinors which correspond to the special spin orientation\n(special orientation of the spin quantization axis) n‚Éó=p‚Éó/|p‚Éó| or equivalently Œ∏=0. It is\nobvious from equations (<ref>) or\n(<ref>) and (<ref>) that the spin-up and spin-down\nspinors are interchanged under the transformation n‚Éó‚Üí -n‚Éó or equivalently Œ∏‚ÜíœÄ+Œ∏. Finally, let us stress\nthe simple but crucial point which is at the heart of the analysis\npresented in this paper. The angle Œ∏ that appears in\nequations (<ref>) and (<ref>) is not a dynamical\nvariable. It does not depend on the relative velocity between the\nframes S and S'. It is the angle measured in the frame in which\nthe particle is at rest. Hence, Œ∏ is not affected by\nrelativistic aberration. The angle Œ∏ resembles the term\n\"proper time\" which is a frame-independent quantity. Due to this\nresemblance, we will call it \"proper angle\". We should also remind\nthe fact that when we talk about the spin orientation of a moving\nfermion, we mean the orientation of the spin quantization axis n‚Éó in the rest frame of the particle. Therefore the spinors\n(<ref>) and (<ref>) for a general spin orientation,\ndescribe a fermion which in its rest frame its spin is quantized\nalong n‚Éó=sinŒ∏ xÃÇ+ cosŒ∏ ·∫ë.\n\nNow we are ready to discuss the discontinuous behavior of the Dirac\nspinors at m=0. Since the expressions (<ref>) and\n(<ref>) for spinors with general spin orientation are\nobtained by means of a Lorentz transformation from the rest frame of\nthe fermion S to a moving frame S', they remain valid for every\nvalue of the relative speed v that satisfies |v-c|<œµ\nwhere œµ is infinitesimal. Consequently, the zero-mass\n(m‚Üí0) or ultrarelativistic (v‚Üí c) limit of the spinors\nu^(‚Üë)(p) and u^(‚Üì)(p) exists and given by\n\n    lim_m‚Üí 0u^(‚Üë)(p)=cos(Œ∏/2) u^(R)(p)+sin(Œ∏/2) u^(L)(p)\n    lim_m‚Üí\n    0u^(‚Üì)(p)=cos(Œ∏/2) u^(L)(p)-sin(Œ∏/2) u^(R)(p)\n\nwhere u^(R)(p)=lim_m‚Üí 0u^(+)(p)=u^(+)(p)|_m=0 and\nu^(L)(p)=lim_m‚Üí 0u^(-)(p)=u^(-)(p)|_m=0 are the\nright-handed and left-handed chirality eigenstates. On the other\nhand, the Lorentz group is non-compact and the parameter space of\nthe Lorentz group does not contain the point v=c. Therefore, we\ncannot perform a Lorentz transformation to the rest frame of a\nmassless particle. In other words, massless particles do not have a\nrest frame. Consequently, the expressions (<ref>) and\n(<ref>) become invalid for strictly massless\nparticles. In the case of massless fermions, we should employ the\nlittle group analysis of Wigner <cit.>. According to Wigner\nmassless particles are described by E(2)-like little group and\nthat their spin orientations other than parallel or antiparallel to\nthe direction of momentum are not allowed. Hence, massless fermions\nmust be completely longitudinally polarized and described by pure\nhelicity states which coincide with chirality eigenstates. We\nobserve from equations (<ref>) and (<ref>)\nthat the zero-mass limit of the spinors for a general spin\norientation are not equal to a chirality eigenstate unless\nŒ∏=0 or œÄ. Therefore the spinors u^(‚Üë)(p) and\nu^(‚Üì)(p) have a discontinuity at m=0 that is\nlim_m‚Üí0u^(s)(p)‚â† u^(s)(p)|_m=0 for\nŒ∏‚â†0,œÄ where u^(s)(p)|_m=0 is either\nu^(R)(p) or u^(L)(p). In the case of SM neutrinos\nu^(s)(p)|_m=0=u^(L)(p).\n"
        },
        {
            "section_number": 3,
            "title": "NEUTRINO CROSS SECTION FOR GENERAL SPIN ORIENTATION",
            "summary": "Discuss the impact of neutrino masses on cross-section calculations in the context of the Standard Model, highlighting the differences between massless and massive neutrinos and the implications of spin orientation and mixing on the accuracy of theoretical predictions.",
            "target_length": 3900,
            "origin_content": "¬ß.¬ß Massless case\n\n\n In the SM of particle physics, neutrinos\ninteract through the weak interaction. Hence any SM process which\ncontains the neutrinos involve W or/and Z boson exchange. The\nformer generates charged current and the latter generates neutral\ncurrent neutrino interactions. In both of the cases, the interaction\nis proportional to the left chirality projection operator LÃÇ=1/2(1-Œ≥_5). Hence, the neutrinos must be left-handed\nchiral in interactions. This fact is always true in the SM,\nindependent to whether the neutrinos are massless or not. Assume\nthat neutrinos are strictly massless. In this case, the neutrinos\nmust also be described by a pure negative helicity state. This is\nevident since massless fermions are completely longitudinally\npolarized, and that their positive and negative helicity eigenstates\ncoincide with right-handed and left-handed chirality eigenstates.\nPossibly because of this reason, sometimes the terms \"left-handed\"\nand \"negative helicity\" are used interchangeably in the literature\nfor massless neutrinos, although there are some differences in their\nmeaning. However one should be very careful in the case of massive\nneutrinos and does not use these terms instead of each other even\nthough neutrino masses are extremely small.[Sometimes the\nterms \"left-handed\" and \"right-handed\" are used for the eigenstates\nof the helicity instead of chirality. This is a matter of convention\nbut the important thing is not to confuse the eigenstates of the\nhelicity and chirality. In this paper we use the terms \"left-handed\"\nand \"right-handed\" for the eigenstates of the chirality and\n\"negative helicity\" and \"positive helicity\" for the eigenstates of\nthe helicity.]\n\nLet us first assume that neutrinos are strictly massless and their\nflavor and mass eigenstates coincide. Consider single neutrino\nproduction and absorption processes ab‚ÜíŒΩ c and ŒΩ a'‚Üí\nb'c' where a,b,c,a',b',c' are charged fermions. The tree-level\namplitudes for these processes can be written in the form\n\n    M=g(J_C^Œ± J'_C_Œ±)|_m_ŒΩ=0\n\nwhere J_C^Œ± is the charged current that contains the\nneutrino field and J'_C^Œ± is the charged current for\ncharged fermions and g is some constant. In writing equation\n(<ref>) we assume that the W propagator\ncan be approximated as (g_ŒºŒΩ-q_Œº\nq_ŒΩ/m_w^2)/q^2-m_w^2‚âà-g_ŒºŒΩ/m_w^2. The\nexplicit form of the charged neutrino current is given by\n\n    J_C^Œ±      =[uÃÖ_ŒΩŒ≥^Œ±LÃÇ u_‚Ñì]    for the process  ab‚ÜíŒΩ c\n    J_C^Œ±      =[uÃÖ_‚Ñì 'Œ≥^Œ±LÃÇ u_ŒΩ]    for the\n    process  ŒΩ a'‚Üí b'c'\n\nwhere LÃÇ=1/2(1-Œ≥_5) is the left chirality\nprojection operator. The unpolarized cross section is proportional\nto the squared amplitude which is averaged over initial and summed\nover final spins. In the case of single neutrino production, the sum\nover final neutrino spin gives just one term with s_ŒΩ=-1 that\ncorresponds to negative helicity. Hence, for m_ŒΩ=0 the produced\nneutrinos are completely longitudinally polarized [\nThe statement \"completely longitudinally polarized\" is used in the\nmeaning that the only possible spin orientation is the one which is\nparallel or anti-parallel to the direction of momentum.] and\ndescribed by a state with 100% negative helicity. In the case of\nsingle neutrino absorption, we do not perform an average over\ninitial neutrino spins and omit the factor of 1/2 coming from spin\naverage of initial neutrinos. Omitting initial neutrino spin\naverage is based on the assumption that all neutrinos in the SM are\ndescribed by completely longitudinally polarized negative helicity\nstates. This assumption is obviously true for massless neutrinos.\nThe neutrinos which enter neutrino absorption processes should be\nproduced through some production processes. If the neutrinos are\nstrictly massless, then all produced neutrinos through a SM process\nare indeed completely longitudinally polarized and described by a\nstate with 100% negative helicity. Nevertheless, as we will see\nin the next subsection surprisingly, the assumption underestimates\nthe cross section for neutrinos with non-zero mass even though\nneutrino masses are very tiny.\n\nNow let us consider another simple process the neutrino scattering\nfrom a charged fermion, ŒΩ a‚ÜíŒΩ a. Depending on the type of\nthe charged fermion a, the process may contain only neutral or\nboth neutral and charged neutrino currents. If we consider the most\ngeneral case, the tree-level amplitude for the process can be\nwritten in the form\n\n    M=g(J_N^Œ±J'_N_Œ±+J_C^Œ± J_C_Œ±)|_m_ŒΩ=0\n\nwhere J_N^Œ± and J'_N^Œ± are the neutral currents\nfor the neutrino and charged fermion respectively. J_C^Œ± is\nthe charged neutrino current defined, similar to\n(<ref>) and\n(<ref>).  For completeness, let us write\nthe explicit form of the neutral neutrino current:\n\n    J_N^Œ±      =[uÃÖ_ŒΩ_fŒ≥^Œ±LÃÇ u_ŒΩ_i]\n\nHere, u_ŒΩ_i (u_ŒΩ_f) represents the spinor for initial\n(final) neutrino field. Similar to the single neutrino absorption,\nwe do not perform an average over initial neutrino spins and omit\nthe factor of 1/2 coming from spin average of initial neutrinos.\n\n\n\n ¬ß.¬ß Massive case without mixing\n\n\nNow assume that neutrino masses are not strictly zero although they\nare extremely small. We also assume that flavor and mass eigenstates\nof the neutrino coincide, i.e., we ignore the mixing. Then, the\npolarized cross section for a process where the neutrino has a spin\norientation defined by the proper angle Œ∏, can be obtained by\ninserting the spinors (<ref>) or (<ref>) into the\nrelevant squared amplitudes and performing the phase space\nintegration. We additionally assume that the energy scale of the\nprocess is much greater than the mass of the neutrino, E>>m_ŒΩ.\nThen, it is a very good approximation to use the expressions\nobtained in the m_ŒΩ‚Üí0 limit. Therefore, during calculations,\nthe zero-mass limit of the spinors (<ref>) and\n(<ref>) can be used instead of (<ref>) and\n(<ref>).\n\nIf we insert the spinors u^(‚Üë)(p) and\nu^(‚Üì)(p) describing a general spin orientation (spin\norientation defined by the proper angle Œ∏) into charged\nneutrino current and take the m_ŒΩ‚Üí0 limit, we obtain\n\n    lim_m_ŒΩ‚Üí\n    0J^(‚Üë)_C^Œ±      =sin(Œ∏/2)(J_C^Œ±|_m_ŒΩ=0)\n    lim_m_ŒΩ‚Üí\n    0J^(‚Üì)_C^Œ±      =cos(Œ∏/2)(J_C^Œ±|_m_ŒΩ=0)\n\nwhere J_C^Œ±|_m_ŒΩ=0 is the charged current for\nmassless neutrinos defined in (<ref>) or\n(<ref>). While calculating the spin-up and\nspin-down neutrino currents in the above equations, we make use of\nthe following identities: LÃÇ{lim_m_ŒΩ‚Üí\n0u^(+)(p)}=LÃÇ u^(R)(p)=0 and LÃÇ{lim_m_ŒΩ‚Üí 0u^(-)(p)}=LÃÇ\nu^(L)(p)=u^(L)(p). We also use the continuity of the helicity\nstates at m_ŒΩ=0: lim_m_ŒΩ‚Üí\n0u^(+,-)(p)=u^(+,-)(p)|_m_ŒΩ=0=u^(R,L)(p). The squared\namplitude for single neutrino production or absorption processes\nab‚ÜíŒΩ c or ŒΩ a'‚Üí b'c' discussed in the previous\nsubsection is then found to be\n\n    lim_m_ŒΩ‚Üí\n    0|M^(Œª)|^2=(1-ŒªcosŒ∏)/2(|M|^2|_m_ŒΩ=0)\n\nwhere |M|^2|_m_ŒΩ=0 is the squared amplitude for massless\nneutrinos and Œª=+1 corresponds to spin-up (‚Üë) and\nŒª=-1 corresponds to spin-down (‚Üì) polarization.\nWe observe from (<ref>) that the squared amplitude\nand consequently the cross section has a discontinuity at m_ŒΩ=0.\nFor instance, if we choose Œ∏=œÄ/2 (transverse polarization)\nm_ŒΩ‚Üí0 limit of the cross section gives half of the cross\nsection for massless neutrinos: lim_m_ŒΩ‚Üí\n0œÉ^(Œª)|_Œ∏=œÄ/2=1/2(œÉ|_m_ŒΩ=0). The cross section for\ntransverse polarization remains finite in the m_ŒΩ‚Üí0 limit but\nit vanishes instantly at the point m_ŒΩ=0. Let us examine the\nzero-mass behavior of the cross section when the neutrinos are\ndescribed by helicity states. The negative (positive) helicity\ncorresponds to the choice Œª=-1 and Œ∏=0 (Œª=+1\nand Œ∏=0). We see from (<ref>) that the\ncross section for positive helicity goes to zero and the cross\nsection for negative helicity goes to œÉ|_m_ŒΩ=0 as\nm_ŒΩ‚Üí0. Hence, if we restrict ourselves to special spin\norientations namely helicity states, we do not encounter any\ndiscontinuity at m_ŒΩ=0. However, the zero-mass continuity\nobserved from helicity states is misleading and does not hold true\nin general as has been clearly shown above.\n\nThe longitudinal polarization of the neutrino is usually defined as\nfollows\n\n    P_long=œÉ^(+)-œÉ^(-)/œÉ^(+)+œÉ^(-)\n\nwhere œÉ^(+) and œÉ^(-) are the cross sections for\npositive and negative helicity neutrinos. P_long was\ncalculated for various SM processes in the literature (for example,\nsee Ref. <cit.>). It was shown that\nP_long goes to -1 as the neutrino mass approaches zero.\nIndeed as we have discussed in the previous paragraph, according to\nthe squared amplitude (<ref>),\nlim_m_ŒΩ‚Üí0œÉ^(+)=0‚áílim_m_ŒΩ‚Üí0P_long=-1. However, it is not correct to\nconclude from this result that the neutrinos become completely\nlongitudinally polarized and described by 100% negative helicity\nstates in the m_ŒΩ‚Üí0 limit. This is evident since the helicity\nbasis is not the only basis that spans the Hilbert space of the spin\nstates. A transversely polarized state is given by the superposition\nof positive and negative helicity states and vanishing of the\npositive helicity does not require the transverse polarization to be\nzero. As we have discussed, although the cross section for positive\nhelicity goes to zero as m_ŒΩ‚Üí0, the cross section for\ntransverse polarization does not go to zero, instead it approaches\nhalf of the cross section for massless neutrinos in that limit.\nTherefore, the quantity P_long defined in\n(<ref>) is not the genuine measure of the\nlongitudinal polarization. It measures only the asymmetry between\npositive and negative helicity states. If we define the quantity\nwhich we call the degree of transverse polarization by\n\n    P_trans=œÉ^(T)/œÉ^(+)+œÉ^(-)\n\nwe deduce that lim_m_ŒΩ‚Üí0P_trans=1/2. Here,\nœÉ^(T) represents the cross section for either spin-up\n(Œª=+1 and Œ∏=œÄ/2) or spin-down (Œª=-1 and\nŒ∏=œÄ/2) state of the transverse polarization.\n\nThe polarized cross section for neutrino scattering process ŒΩ\na‚ÜíŒΩ a can be calculated in a similar manner. If we insert the\nspinors for a general spin orientation into neutral neutrino current\nand take the m_ŒΩ‚Üí0 limit, we obtain\n\n    lim_m_ŒΩ‚Üí\n    0J^(Œª_i,Œª_f)_N^Œ±      =[(1-Œª_icosŒ∏_i)/2]^1/2[(1-Œª_fcosŒ∏_f)/2]^1/2(J_N^Œ±|_m_ŒΩ=0)\n\nwhere Œª_i and Œ∏_i (Œª_f and Œ∏_f) belong\nto the initial state (final state) neutrino and\nJ_N^Œ±|_m_ŒΩ=0 is the neutral current for massless\nneutrinos defined in (<ref>). The squared\namplitude for neutrino scattering process ŒΩ a‚ÜíŒΩ a is then\nfound to be\n\n    lim_m_ŒΩ‚Üí\n    0|M^(Œª_i,Œª_f)|^2=(1-Œª_icosŒ∏_i/2)(1-Œª_fcosŒ∏_f/2)(|M|^2|_m_ŒΩ=0)\n\nwhere |M|^2|_m_ŒΩ=0 is the squared amplitude for massless\nneutrinos. The cross section of the neutrino-electron scattering for\npolarized initial state neutrinos with general spin orientation and\nunpolarized final state neutrinos, was calculated in\nRef.<cit.>. To obtain the cross section for unpolarized final\nstate neutrinos we should sum the squared amplitude over\nŒª_f, which gives:\n\n    lim_m_ŒΩ‚Üí\n    0|M^(Œª_i)|^2=‚àë_Œª_f=+1,-1{lim_m_ŒΩ‚Üí\n    0|M^(Œª_i,Œª_f)|^2}=(1-Œª_icosŒ∏_i/2)(|M|^2|_m_ŒΩ=0).\n\nThis squared amplitude coincides with the result of\nRef.<cit.> with only one difference that m_ŒΩ‚Üí 0 limit\nin the left-hand side of (<ref>) appears in our\ncalculations but it is absent in Ref.<cit.>. Instead,\nspin-dependent squared amplitude was evaluated at m_ŒΩ=0, i.e.,\naccording to <cit.>:\n|M^(Œª_i)|^2|_m_ŒΩ=0=(1-Œª_icosŒ∏_i/2)(|M|^2|_m_ŒΩ=0).\nIt seems the authors assumed that the spinors for a general spin\norientation have a continues behavior in the massless limit, i.e.,\nthey assumed lim_m‚Üí0u^(s)(p)= u^(s)(p)|_m=0. We also\nwould like to draw reader's attention to the following point. We see\nfrom equations (<ref>), (<ref>)\nand (<ref>) that the perpendicular component\n(relative to momentum direction) of the spin three-vector n‚Éó\ndoes not appear in the squared amplitudes. Recall that we choose\nn‚Éó=sinŒ∏ xÃÇ+ cosŒ∏ ·∫ë and p‚Éó=p·∫ë. Therefore n‚Éó=(n_‚ä•,0,n_) where\nn_‚ä•=sinŒ∏ and n_=cosŒ∏. Then\nequation (<ref>) can be written as lim_m_ŒΩ‚Üí\n0|M^(Œª_i)|^2=(1-Œª_in_/2)(|M|^2|_m_ŒΩ=0).\nHowever, the disappearance of n_‚ä• in the squared amplitude\ndoes not imply that the squared amplitude is independent from\nn_‚ä•. This is obvious because we have a condition between\nn_‚ä• and n_ obtained from the normalization of\nthe spin four-vector s^Œº s_Œº=-1‚áín‚Éó¬∑n‚Éó=n_‚ä•^2+n_^2=1. Therefore we have one independent\nparameter representing the orientation of the spin. One may decide\nto choose n_‚ä• or n_ as an independent\nparameter or for instance, the proper angle Œ∏ as we did in\nthis paper. Regardless of which parameter we choose, the cross\nsection for transverse polarization evaluated in the m_ŒΩ‚Üí0\nlimit gives half of the cross section for massless neutrinos:\nn_‚ä•=1‚áí n_=0‚áílim_m_ŒΩ‚Üí\n0œÉ=1/2(œÉ|_m_ŒΩ=0). Thus, the\nproduction, absorption and scattering probability of the neutrinos\nwith transverse polarization cannot be neglected.\n\n\nThe zero-mass discontinuity that we have discussed has important\nimplications on neutrino physics. It makes a significant distinction\nbetween the cases in which neutrinos are exactly massless and\nneutrinos have non-zero but very tiny masses. In the former case,\nall SM neutrinos are described by completely longitudinally\npolarized negative helicity states. Therefore, the factor 1/2 due\nto spin average of initial state neutrinos is omitted for processes\nwhere neutrinos take part in the initial state. However, in the\nlater case it is not possible anymore to assume that neutrinos are\ncompletely longitudinally polarized. This is obvious because, the\nproduction cross section and hence the production probability of the\nneutrinos with transverse spin orientation through SM processes\ncannot be neglected. Therefore some part of the neutrinos in the SM\nis transversely polarized. Consequently, the spin average of initial\nstate neutrinos in a process cannot be neglected and the cross\nsection is reduced due to this spin average. Our reasoning can be\npresented in detail as follows: Consider a process in which the\nneutrinos take part in the initial state. For example it might be\nthe neutrino absorption or scattering process. In order to calculate\nthe unpolarized total cross section we have to average over initial\nand sum over final state spins. Some of the initial state neutrinos\nare transversely polarized. Therefore for these neutrinos, spin\naverage is performed over spin-up and spin-down states of the\ntransverse polarization (FIG.<ref>). Then in the m_ŒΩ‚Üí0\nlimit, the unpolarized cross section gives\n\n    lim_m_ŒΩ‚Üí\n    0œÉ^(unpol)=1/2‚àë_Œª_i=+1,-1lim_m_ŒΩ‚Üí\n    0œÉ^(Œª_i)=1/2(œÉ|_m_ŒΩ=0)\n\nwhere we use lim_m_ŒΩ‚Üí\n0œÉ^(Œª_i=+1)=lim_m_ŒΩ‚Üí\n0œÉ^(Œª_i=-1)=1/2(œÉ|_m_ŒΩ=0)\nfor Œ∏=œÄ/2 (transverse polarization). We see from equation\n(<ref>) that the unpolarized cross section is\nreduced by a factor of 1/2 compared to the cross section for\nmassless neutrinos. Hence, for transversely polarized initial state\nneutrinos we obtain an average factor of 1/2. However, not all\ninitial state neutrinos are transversely polarized. Some others are\nlongitudinally polarized. Since the cross section for neutrinos with\npositive helicity is zero in the zero-mass limit, longitudinally\npolarized initial neutrino states consist of 100% negative\nhelicity states. In this case we do not perform an average over\ninitial neutrino spins and the unpolarized cross section is equal\nthe cross section for massless neutrinos:\n\n    lim_m_ŒΩ‚Üí\n    0œÉ^(unpol)=lim_m_ŒΩ‚Üí\n    0œÉ^(-)=(œÉ|_m_ŒΩ=0).\n\nWe have deduced from the above analysis that if we consider\ntransversely polarized part of the initial neutrinos, then 50% of\nthem are spin-up and other 50% are spin-down. We should then\nperform an average over initial spins which gives a factor of 1/2.\nOn the other hand, if we consider longitudinally polarized part of\nthe initial neutrinos, then 100% of them are negative helicity\nand none of them are positive helicity. Then we do not perform an\naverage and instead of 1/2 we get a factor of 1. Hence, an\nimportant question arises:  By which factor is the cross section\nreduced? In order to give an answer to this question, let us\nconsider the following gedankenexperiment. Assume that neutrinos are\ndetected in a particle detector via the absorption process ŒΩ\na'‚Üí b'c'. Without loss of generality, also assume that all the\ndetected neutrinos, are produced via the production processes ab‚ÜíŒΩ c. FIG.<ref> represents a schematic diagram for this\ngedankenexperiment.\n\nWe will use the subscript \"1\" to denote the production process\nab‚ÜíŒΩ c and subscript \"2\" to denote the absorption process\nŒΩ a'‚Üí b'c'. If the neutrinos are produced in a particle\naccelerator then the total number of produced neutrinos is given by\nN_1=œÉ_1^(unpol) L_1, where\nœÉ_1^(unpol) is the unpolarized total cross section\nand L_1 is the integrated luminosity. If we assume that all\nof the produced neutrinos have a fix spin orientation defined by the\nproper angle Œ∏, then the number of produced neutrinos with\nthis spin orientation is given by\n\n    N_1^(Œª)(Œ∏)=œÉ_1^(Œª)(Œ∏) L_1=(1-ŒªcosŒ∏)/2(œÉ_1|_m_ŒΩ=0) L_1\n\nwhere we take m_ŒΩ‚Üí0 limit and make use of equation\n(<ref>). We observe from (<ref>)\nthat the total number of produced neutrinos is independent from the\nproper angle Œ∏:\n\n    N_1=N_1^(Œª=+1)(Œ∏)+N_1^(Œª=-1)(Œ∏)=(œÉ_1|_m_ŒΩ=0) L_1.\n\nNow we consider a massive detector which is composed of a huge\nnumber of atoms. The produced neutrinos can interact with the\nelectrons and nucleons (or quarks) of the detector through the\nprocess ŒΩ a'‚Üí b'c' and the detection occurs. For simplicity we\nassume that all of the produced neutrinos are passing through the\ndetector. Then, the number of detected neutrinos with spin\norientation defined by the proper angle Œ∏ can be written as\n\n    N_2^(Œª)(Œ∏)=N_1^(Œª)(Œ∏)P^(Œª)(Œ∏)\n    =œÉ_1^(Œª)(Œ∏)œÉ_2^(Œª)(Œ∏) L_1L_2.\n\nHere P^(Œª)(Œ∏)=œÉ_2^(Œª)(Œ∏)L_2 is the\ndetection probability of a single polarized neutrino and L_2 is a\nconstant that depends on the parameters of the detector. For\ninstance, L_2 depends on the number of electrons or nucleons per\nunit volume, the fiducial mass of the detector, etc. Since the\ndetails of the detector are irrelevant to our analysis, we do not\nconsider its explicit form as a function of detector parameters and\nassume that it is just a constant. According to equation\n(<ref>) the zero-mass limit of the production and\nabsorption cross sections can be written as\nlim_m_ŒΩ‚Üí0œÉ_1,2^(Œª)(Œ∏)=(1-ŒªcosŒ∏)/2(œÉ_1,2|_m_ŒΩ=0).\nThe total number of detected neutrinos is then\n\n    N_2^(Œª=+1)(Œ∏)+N_2^(Œª=-1)(Œ∏)=[sin^4(Œ∏/2)\n    +cos^4(Œ∏/2)]N_2.\n\nwhere N_2=(œÉ_1|_m_ŒΩ=0)\n(œÉ_2|_m_ŒΩ=0) L_1L_2 is the total number of\ndetected neutrinos in case all produced neutrinos are massless. In\nthe left hand side of (<ref>), the limit\nm_ŒΩ‚Üí0 is implemented but not shown.\n\nIn the above analysis we assume that all the neutrinos are produced\nhaving the same spin orientation with respect to the direction of\nmomentum, i.e., with a same proper angle Œ∏. Specifically if\nwe assume that all produced neutrinos are transversely polarized\n(Œ∏=œÄ/2) then total number of detected neutrinos is N_2/2.\nOn the other hand, if all produced neutrinos are longitudinally\npolarized (Œ∏=0) then total number of detected neutrinos is\nN_2. However in a real situation, the produced beam is comprised\nfrom neutrinos with different spin orientations. Hence, we should\nconsider every possible spin orientations and an average over\ndifferent spin orientations has to be performed. It is easy to show\nthat the average of the trigonometric expressions in the square\nparentheses yields ‚ü®[sin^4(Œ∏/2)\n+cos^4(Œ∏/2)]‚ü©=2/3. Here we\nshould note that a statistical weight of sinŒ∏ is used during\nthe average. Therefore different from other standard model fermions,\nspin average of initial state neutrino in a SM process yields a\nfactor of 2/3 instead of 1/2. Hence the total cross section is\nreduced by this factor compared to the case in which neutrinos are\ndescribed by 100% negative helicity states. Here we should\nemphasize that the standard model fermions other than neutrinos\ncarry electric and/or color charge and they interact dominantly\nthrough vector type coupling. Since the vector coupling does not\nprovide a preferred spin orientation, all different orientations of\ntheir spin three-vector n‚Éó are equally probable unless they\nare intentionally produced polarized. Therefore, for initial state\nelectrons, quarks, etc. the average over proper angle Œ∏ is\nomitted. On the other hand, the average over spin-up and spin-down\nstates is performed and yields a factor of 1/2.\n\nLet's summarize what we have done so far: We have deduced that due\nto zero-mass discontinuity in the cross section the cases in which\nneutrinos are exactly massless and neutrinos have non-zero but very\ntiny masses, have completely different implications. Therefore,\ncontrary to the previously accepted opinion in the literature, it is\nnot a good approximation to neglect neutrino masses during cross\nsection calculations even though neutrino masses are very small and\nthe energy scale of the processes are much greater than the neutrino\nmass. We have deduced a surprising result that the total cross\nsection of the process where a neutrino takes part in the initial\nstate is reduced by a factor of 2/3 due to spin average. As far as\nwe know, this fact has been overlooked in the literature. In the\nprevious studies on this subject, the spin average of initial state\nneutrinos was omitted for processes where neutrinos take part in the\ninitial state.\n\nThe total neutrino (anti-neutrino) cross sections have been measured\nin plenty number of experiments since the famous experiments of\nCowan and Reines <cit.>. In all these\nexperiments the measured cross sections seem not to be reduced by\nthe factor 2/3. They confirm the fact that neutrino states are\nalmost 100% negative helicity. Possibly because of the\nexperimental verification of the neutrino helicity, theoretical\npredictions have not been examined in much detail by previous\nstudies. However, as we have deduced, a straightforward calculation\ntaking into account the existing zero-mass discontinuity of the free\nDirac spinors yields a discrepancy between quantum field theory\npredictions and the experimental results. One possible solution to\nthis problem might be provided by adding a new simple hypothesis to\nestablished axioms of quantum field theory <cit.>. The\nscope of this paper is limited; we do not aim to discuss possible\nsolutions to the discrepancy. Our purpose is just to reveal the\nsurprising consequences of the zero-mass discontinuity of the Dirac\nspinors on neutrino cross sections.\n\nIn closing to this subsection, we would like to draw reader's\nattention to another surprising consequence of the zero-mass\ndiscontinuity of the Dirac spinors. Throughout this paper, all\ncalculations have been carried out considering only Dirac neutrinos.\nIt is assumed that Dirac and Majorana neutrino cross sections\ncoincide in the m_ŒΩ‚Üí0 limit <cit.>.\nThis fact is based on the assumption that both Dirac and Majorana\nspinors become completely left-handed chiral in the m_ŒΩ‚Üí0\nlimit. However, as we have discussed in section II, a free Dirac\nspinor with arbitrary spin orientation does not necessarily result\nin a chirality eigenstate in the zero-mass limit. Therefore,\ncontrary to expectations, Dirac and Majorana cross sections can lead\nto different results even though the limit m_ŒΩ‚Üí0 is performed.\n\n\n\n\n ¬ß.¬ß Massive case with mixing\n\n\nWe have so far ignore the mixing between different mass eigenstates\nof the neutrino. However, in a realistic situation the neutrinos\ninteract through weak interaction in flavor eigenstates which are\ngiven by a superposition of the mass eigenstates. The mixing\nequation is given by ŒΩ_‚Ñì L=‚àë_i=1^3U_‚Ñì i ŒΩ_i\nL  where  U_‚Ñì i is the Pontecorvo-Maki-Nakagawa-Sakata\n(PMNS) matrix element <cit.>. Here we use the\nsubscript ‚Ñì to denote the flavor and subscript i to denote\nthe mass eigenstates. Therefore, the scattering process for\nŒΩ_‚Ñì consist of separate processes for mass eigenstates\nŒΩ_i, i=1,2,3. The cross section calculations are then\nperformed for neutrino mass eigenstates and the contributions coming\nfrom different mass eigenstates are added. According to the minimal\nextension of the SM with massive neutrinos, the scattering amplitude\nfor ŒΩ_i is almost same with the amplitude for a neutrino without\nmixing. The only difference is that the charged neutrino current\npicks up an extra factor U_‚Ñì i. It is obvious that the\nsurprising result that we encounter in the previous subsection is\nalso true when we consider the processes ab‚ÜíŒΩ_ic, ŒΩ_ia'‚Üí\nb'c' and ŒΩ_ia‚ÜíŒΩ_ia where the neutrinos are taken to be in\nthe mass eigenstate. The neutrino mixing does not solve the problem,\non the contrary, the problem becomes worse than it was before. Since\nvarious different spin orientations of the neutrino contribute to\nthe cross section, we can conceive the flavor eigenstate as a\nsuperposition of the mass eigenstates where each mass eigenstate may\nhave an arbitrary spin orientation. Then, the spin state of the\nflavor eigenstate becomes ambiguous. One may assume the flavor\nneutrino has a mixed spin state, in the sense that, each of its\nconstituent mass eigenstates has a different spin orientation. Let\nus consider the single neutrino production or absorbtion processes\ndiscussed in the previous subsections. If we sum the squared\namplitudes that belong to individual mass eigenstates we expect to\nobtain the squared amplitude for the flavor eigenstate:\n|M_‚Ñì|^2=‚àë_i|M_i|^2. According to equation\n(<ref>) the sum over mass eigenstates gives:\n\n    lim_m_ŒΩ‚Üí0‚àë_i|M^(Œª_i)_i|^2=‚àë_i[|U_‚Ñì\n    i|^2(1-Œª_icosŒ∏_i)/2](|M_‚Ñì|^2|_m_ŒΩ=0)\n\nwhere (|M_‚Ñì|^2|_m_ŒΩ=0) is the squared\namplitude for the flavor neutrino evaluated at m_ŒΩ=0. In case\nall spin orientations of the mass eigenstates are equal\n(Œª_1=Œª_2=Œª_3; Œ∏_1=Œ∏_2=Œ∏_3), we\nobtain the expected result:\n\n    lim_m_ŒΩ‚Üí0‚àë_i|M^(Œª_i)_i|^2=(1-ŒªcosŒ∏)/2(|M_‚Ñì|^2|_m_ŒΩ=0)=lim_m_ŒΩ‚Üí0|M^(Œª)_‚Ñì|^2\n\nwhere we use the unitarity of the PMNS matrix. However, we do not\nhave any reasonable explanation for the choice\nŒª_1=Œª_2=Œª_3; Œ∏_1=Œ∏_2=Œ∏_3. In\ngeneral, spin orientations of different mass eigenstates can be\ndifferent.\n"
        },
        {
            "section_number": 4,
            "title": "CONCLUSIONS",
            "summary": "Explore the implications and challenges of the zero-mass discontinuity in Dirac spinors on neutrino cross sections, highlighting the resulting neutrino helicity problem and its potential impact on theoretical and experimental discrepancies.",
            "target_length": 700,
            "origin_content": "The helicity states have a continuous behavior in the massless\nlimit. When we take m‚Üí0 limit, a helicity state converge to one\nof the chirality eigenstate and becomes completely left-handed or\nright-handed chiral. The zero-mass behavior observed from helicity\nstates can make one think that massless limit is always smooth.\nHowever, this behavior is specific to helicity states and is not\nvalid in general. Massless limit has some subtleties in the case of\nspinors with general spin orientations. The angle which defines the\nspin orientation of a fermion is an invariant quantity by\ndefinition. Hence, the spin orientation of a fermion does not\nnecessarily becomes parallel or anti-parallel to the momentum\ndirection and does not necessarily result in a chirality eigenstate\nin the zero-mass limit. This behavior makes free Dirac solutions\ndiscontinues at m=0. We explore the consequences of this zero-mass\ndiscontinuity of the Dirac spinors and show that it has surprising\nconsequences for neutrino cross sections.\n\nThe most challenging consequence of the zero-mass discontinuity is\nthat it yields a discrepancy between theoretical predictions and the\nexperimental results. We call this discrepancy the neutrino helicity\nproblem. The theoretical predictions of the cross section for\nmassive neutrinos with general spin orientation have been discussed\nfor decades. In this respect, many of the calculations presented in\nthis paper is not totally novel; the new idea of the paper, lies in\nthe reinterpretation of the dependence of the cross section on the\nspin three-vector n‚Éó. Although the resultant discrepancy is\nvery disturbing, we decide to present our results since we think\nthat they are concrete predictions of the theory. The neutrino\nhelicity problem points out that something is wrong in the\nassumptions used in the theory. The polarized cross section\ncalculation technique for a general spin orientation is a\nconventional method which is used successfully for other fermions.\nIndeed, top quark spin polarization has been measured for various\nspin orientations and it was found to be consistent with the\ntheoretical predictions <cit.>.\nTherefore, the problem should be associated with the neutrino\nnature.\n\n\n\n\n\nThe author thanks Prof. A. U. Yƒ±lmazer for helpful criticism of\nthe manuscript and valuable suggestions.\n\n\n\n99\n\nWigner E. P. Wigner, ‚ÄúOn Unitary Representations of the Inhomogeneous Lorentz Group,‚Äù Ann. Math. 40, 149 (1939).\n\nFukuda:1998mi\n  Y.¬†Fukuda et al. [Super-Kamiokande Collaboration],\n  ‚ÄúEvidence for oscillation of atmospheric neutrinos,‚Äù\n  Phys. Rev. Lett.  81, 1562 (1998)\n\n  [hep-ex/9807003].\n\nAhmad:2001an\n  Q.¬†R.¬†Ahmad et al. [SNO Collaboration],\n  ‚ÄúMeasurement of the rate of ŒΩ_e+d ‚Üí p+p+e^- interactions produced by ^8B solar neutrinos at the Sudbury Neutrino Observatory,‚Äù\n  Phys. Rev. Lett.  87, 071301 (2001)\n\n  [nucl-ex/0106015].\n\nSahin:2016bjs\n  I.¬†Sahin,\n  ‚ÄúZero-mass limit of a Dirac spinor with general spin\n  orientation,‚Äù  Eur. J. Phys. 37, 065404 (2016)\n\n  ;arXiv:1606.04116 [physics.gen-ph].\n\nGreinerRQM W. Greiner, Relativistic Quantum Mechanics,\n(Berlin: Springer, 1994).\n\nGreinerQED W. Greiner and J. Reinhardt, Quantum Electrodynamics,\n(Berlin: Springer, 1994).\n\nBarenboim:1996cu\n  G.¬†Barenboim, J.¬†Bernabeu and O.¬†Vives,\n  ‚ÄúLeft-handed neutrino disappearance probe of neutrino mass and character,‚Äù\n  Phys. Rev. Lett.  77, 3299 (1996)\n\n  [hep-ph/9606218].\n\nKayser B. Kayser and R.E. Shrock, ‚ÄúDistinguishing between Dirac and Majorana neutrinos in neutral-current reactions,‚Äù Phys. Lett. B 112, 137 (1982).\n\nReinescowan1 F. Reines and C. L. Cowan Jr., ‚ÄúDetection of The Free\nNeutrino,‚Äù Phys. Rev. 92, 830 (1953).\n\nReinescowan2 C.¬†L.¬†Cowan, F.¬†Reines, F.¬†B.¬†Harrison, H.¬†W.¬†Kruse and\nA.¬†D.¬†McGuire,\n  ‚ÄúDetection of the free neutrino: A Confirmation,‚Äù\n  Science 124, 103 (1956).\n\n\nSahin:2015ofl\n  I.¬†Sahin,\n  ‚ÄúA hypothesis on neutrino helicity,‚Äù\n  arXiv:1601.00627 [physics.gen-ph].\n\nBarranco:2014cda\n  J.¬†Barranco, D.¬†Delepine, V.¬†Gonzalez-Macias, C.¬†Lujan-Peschard and M.¬†Napsuciale,\n  ‚ÄúScattering processes could distinguish Majorana from Dirac neutrinos,‚Äù\n  Phys. Lett. B 739, 343 (2014)\n\n  [arXiv:1408.3219 [hep-ph]].\n\n  Bilenky S. Bilenky, Introduction to the Physics of Massive and Mixed\n  Neutrinos,\n(Berlin: Springer, 2010).\n\nKayserbook B. Kayser, F. Gibrat-Debu and F. Perrier, The Physics of Massive\nNeutrinos, (Singapore: World Scientific, 1989).\n\n  Abazov:2016tba\n  V.¬†M.¬†Abazov et al. [D0 Collaboration],\n  ‚ÄúMeasurement of top quark polarization in t t lepton+jets final states,‚Äù\n  Phys. Rev. D 95, 011101 (2017)\n\n  [arXiv:1607.07627 [hep-ex]].\n\n  Abazov:2015fna\n  V.¬†M.¬†Abazov et al. [D0 Collaboration],\n  ‚ÄúSimultaneous measurement of forward-backward asymmetry and top polarization in dilepton final states from ttÃÖ production at the Tevatron,‚Äù\n  Phys. Rev. D 92, 052007 (2015)\n\n  [arXiv:1507.05666 [hep-ex]].\n"
        }
    ],
    [
        {
            "section_number": 1,
            "title": "INTRODUCTION",
            "summary": "Explain the challenges of achieving accurate and high-resolution Quantitative Magnetic Resonance Imaging (QMRI) in clinical settings, discuss the advancements in Magnetic Resonance Fingerprinting (MRF) for overcoming these challenges, and introduce the innovative approach of Magnetic Resonance Fingerprinting with Low Rank constraint (FLOR) to improve reconstruction quality and reduce quantization error.",
            "target_length": 1600,
            "origin_content": "Quantitative Magnetic Resonance Imaging (QMRI) is widely used to measure tissue's intrinsic spin parameters such as the spin-lattice magnetic relaxation time (T1) and the spin-spin magnetic relaxation time (T2) <cit.>. Since tissue relaxation times vary\nin disease, QMRI enables the diagnosis of different pathologies, including multiple sclerosis (MS), Alzheimer, Parkinson, epilepsy and cancer <cit.>. In addition, the knowledge of tissue relaxation times allows generation of many clinical MR imaging contrasts (such as FLAIR and STIR) off-line, and saves a significant amount of scanning time.\n\n\n\nDespite the advantages of QMRI, clinical MRI today mainly consists of weighted images. Values in weighted MR imaging are given in arbitrary units, since the signal strength is influenced by both intrinsic parameters (such as relaxation times and concentration of hydrogen atoms) and non-intrinsic ones. Non-intrinsic parameters include transmit and receive coils sensitivities, patient position in the scanner, vendor based scanner specific parameters, and local temperature. Weighted MRI images therefore lack quantitative information and as a result, different materials may exhibit similar or identical gray level values. In addition, weighted MRI contrast values vary between different follow-up scans of the same patient. This fact may impair disease monitoring, if based solely on those images. To date, weighted MRI scans are  more common than QMRI in the clinic, due to the extremely long times often associated with QMRI using conventional techniques <cit.>.\n\n\nA plethora of methods have been proposed for QMRI. Earlier approaches are based on a series of spin echo (SE) or inversion recovery (IR) images with varying repetition times (TR) and echo times (TE) to evaluate each magnetic parameter (T1 or T2) separately. After acquisition, the curve of intensities for each pixel is matched to the expected magnetic signal, representing the appropriate magnetic tissue parameters <cit.>. Accelerated methods for QMRI consist of the popular driven equilibrium single pulse observation of T1 (DESPOT1) <cit.> or T2 (DESPOT2) <cit.> and the IR TrueFISP for simultaneous recovery of T1 and T2 quantitative maps <cit.>.\nBoth techniques do not require long waiting times between excitations to reach an equilibrium state, and therefore they are significantly faster. Later works shortened the acquisition time required by those methods by under-sampling the data in both spatial and temporal domains <cit.>.\nHowever, obtaining accurate and high resolution QMRI in a reasonable clinical scanning time is still very challenging.\n\nAn approach for QMRI called magnetic resonance fingerprinting (MRF) has drawn increased attention in the last few years <cit.>. MRF uses pseudo-randomized acquisitions to generate many different imaging contrasts, acquired at a high under-sampling ratio.\n\nIt exploits the different acquisition parameters over time to produce a temporal signature, a ‚Äúfingerprint\", for each material under investigation. By matching this unique signature to a pre-generated set of simulated patterns, the quantitative parameters can be extracted off-line. This approach saves valuable scan time compared to previous methods for accelerated QMRI, demonstrating promising efficient and reliable results.\n\n\n\n\nMRF utilizes the fact that each tissue responds differently to a given quasi-random pulse sequence. By varying the acquisition parameters (e.g. repetition time (TR), echo time (TE), and radio frequency flip angle (FA)),\nunique signals are generated from different tissues. After acquisition, a pattern recognition algorithm is used to match the acquired signal from each voxel to an entry from a dictionary of possible tissue candidates. The dictionary entries are created by simulating the tissue's response to the sequence for a range of T1 and T2 parameter values, using the Bloch equations. The resulting dictionary contains the temporal signatures of various simulated materials, given the pseudo-random pulse sequence. The quantitative parameters, such as the tissue's T1 and T2 relaxation times, can be retrieved from the data by matching the signature acquired to the most correlated entry in the dictionary.\n\nIn MRI, data is acquired in the Fourier domain of the spatial image (a.k.a. k-space). The acquisition time of a high resolution, single contrast 3D MRI lasts a substantial amount of time. Since MRF is based on rapid acquisition of hundreds of different contrasts, severe under-sampling is performed in k-space to obtain the temporal resolution required for MRF. Figure¬†<ref> demonstrates the effect of fully sampled versus under-sampled data, acquired with spiral trajectories and recovered using the inverse non uniform fast Fourier transform (NUFFT) <cit.>. It can be seen that the under-sampled data is blurred and introduces aliasing artifacts. Figure¬†<ref> illustrates the noise and under-sampling artifacts of a representative brain voxel intensity as function of time, where the data is acquired with an MRF sequence based on fast imaging with steady state precession (FISP) <cit.>. Clearly, under-sampling also introduces a substantial level of noise in the time domain. In addition, MRF uses a dictionary with discrete values, while QMRI values are continuous. This leads to quantization error, depending on the values represented in the dictionary.\n\nWhile in the original MRF paper <cit.> these imaging artifacts are not handled explicitly,\nrecent works have implemented advanced reconstruction techniques to overcome under-sampling artifacts.\n\nApproaches based on exploiting the sparsity of the signal in some transform domain in a compressed sensing (CS) <cit.> framework are examined by Davies et al. <cit.> and Wang et al. <cit.>. Zhao et al. <cit.> formulated MRF as a maximum likelihood (ML) problem, and developed an iterative reconstruction approach for each time point. While these techniques showed improved results compared to the original MRF method, they do not exploit the temporal similarity between adjacent time-points, which is intrinsic to the dynamic acquisition used in MRF.\n\nA common approach to exploit redundancy exists in dynamic MRI, based on modeling the acquired data as low-rank. This modelling was successfully applied for various dynamic MRI applications, such as cardiac imaging <cit.> and functional MRI <cit.>. In the context of MRF, early works use low-rank MRF to compress the dictionary for faster reconstruction <cit.>. This saves reconstruction time, but does not necessarily improve the quality of the reconstructed maps or the acquisition time. The first introduction of a low-rank constraint for improved reconstruction in MRF was proposed by Zhao et al. <cit.> followed by a sub-space constrained low-rank approach introduced by us <cit.>. Extensions of these ideas include adding a sparse term to the low-rank-based reconstruction <cit.> (a.k.a robust PCA <cit.>) and representing the data as low-rank in the k-space domain <cit.>. Recently, a few approaches that utilize prior knowledge of the dictionary together with a low-rank constraint have been published. Zhao et al. <cit.> presented an efficient algorithm that performs a singular value decomposition (SVD) on the dictionary and embeds the right singular vectors in the solution, to obtain better estimation of the temporal signatures. A similar approach was presented by Assl√§nder et al. <cit.>, who embed the left singular vectors in the solution. These methods show that exploiting the redundancy via a low-rank based solution improves the results compared to a sparsity approach. However, the obtained reconstructed maps still suffer from quantization error, due to the nature of a matched-filter based solution that matches a single dictionary atom to a single pixel. In addition, most of these methods are based on a fixed rank, set in advance, which may be difficult to determine in advance.\n\n\nIn this paper we extend our initial idea presented in our conference paper <cit.> and enforce a low-rank constraint in the image domain together with constraining the solution to the dictionary subspace. In particular, we exploit the low-rank property of the temporal MRF domain, via an iterative scheme that consists of a gradient step followed by a projection onto the subspace spanned by the dictionary elements in order to constrain the structure of the tissue behaviour simulated in the dictionary. The estimated images are then decomposed using SVD and the singular values are soft-thresholded to reduce the nuclear norm value in every step. Our approach, called magnetic resonance Fingerprinting with LOw Rank constraint (FLOR), incorporates three main advantages that were only partially introduced in previous work:\n\n\n  * FLOR formulates the problem as a convex problem. The solution is then rigorously developed based on the incremental subgradient proximal method <cit.>. This technique is known to convergence to the global minimum, regardless of the initial starting point.\n\n  * FLOR is based on a nuclear-norm solution, and does not require fixing the rank in advance. This leads to a solution that adapts the rank according to the nature of the specific dataset.\n\n  * The subspace constraint in FLOR is not limited to dictionary items, but rather allows a solution that is spanned by the dictionary. This enables better reconstruction of the temporal imaging contrasts. It also allows generation of quantitative parameters that do not necessarily exist in the simulated dictionary, thereby reducing the quantization error of the resulting maps.\n\nWhile there are previous publications that introduce one or two of the advantages pointed above (e.g. Zhao et al. <cit.> describes a subspace constraint that is not limited to the dictionary items), our work incorporates all of them together in a convenient optimization framework.\n\n\n\n Our reconstruction results are based on sampling with variable density spiral trajectories, using 5% and 9% sampling ratios, for retrospective and prospective experiments, respectively. We compare our results to the methods developed by Davies et al. <cit.> and Zhao <cit.>, and show that FLOR provides quantitative parameter maps with higher accuracy or correspondence to literature compared to those methods.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis paper is organized as follows. Section <ref> describes the MRF problem and provides a review of common reconstruction methods, followed by our low-rank based approach. Section <ref> compares our results to previous MRF algorithms, using retrospective and prospective under-sampled MRF data of a human subject. Sections <ref> and <ref> discuss experimental results using retrospective and prospective under-sampled MRF data, followed by conclusions.\n"
        },
        {
            "section_number": 2,
            "title": "METHOD",
            "summary": "Discuss the methodology used in Low Rank Magnetic Resonance Fingerprinting, emphasizing the problem formulation, previous methods, the proposed approach, and potential extensions for improving accuracy and reducing quantization errors.",
            "target_length": 1600,
            "origin_content": "¬ß.¬ß Problem formulation\n\n\nMRF data consists of multiple frames, acquired in the image's conjugate Fourier domain (a.k.a k-space), where each frame results from different acquisition parameters. We stack the measurements into a Q √ó L matrix ùêò, where L is the number of frames and Q is the number of k-space samples in each frame. Every column in ùêò is an under-sampled Fourier transform of an image frame, ùêó_:,i:\n\n    ùêò=[F_u{ùêó_:,1},...,F_u{ùêó_:,L}]+ùêá\n\nwhere F_u{¬∑} denotes an under-sampled 2D Fourier transform and ùêá denotes a zero mean complex Gaussian noise. The row ùêó_j,: represents the temporal signature of a single pixel (assumed to correspond to a single tissue). The signature depends on the tissue's relaxation times, T1 and T2, and its proton density  (PD), grouped as a row vector:\n\n    Œò_1^j=[T1^j,T2^j,PD^j],  1‚â§ j‚â§ N.\n\nEach column, ùêó_:,i represents a response image acquired at a single time point with different acquisition parameters, stacked as a column vector:\n\n    Œò_2^i=[TR^i,TE^i,FA^i]^T,  1‚â§ i‚â§ L\n\nwhere TR and TE are the repetition time and time to echo and FA represents\nthe flip angle of the RF pulse. Therefore, ùêó_j,:=f(Œò_1^j,Œò_2), where f{¬∑} represents the Bloch equations.\n\n\n\n\nNote that we omit the off resonance parameter (which appeared in Œò_1 in the original MRF paper <cit.>), since the sequence used in our retrospective experiments is derived from the FISP sequence, which is insensitive to off resonance effects <cit.>.\n\n\n\n\n\n\n\n\n\n\n\nThe goal in MRF is to recover, from the measurements ùêò, the imaging contrasts ùêó and the underlying quantitative parameters of each pixel defined in  (<ref>), under the assumptions that every pixel in the image contains a single type of tissue and that Œò_2 is known.\n\nRecovery is performed by defining a dictionary that consists of simulating the signal generated from M tissues using the Bloch equations (represented as M different combinations of T1 and T2 relaxation times), when the length-L acquisition sequence defined in (<ref>) is used.\nAs a result, we obtain a dictionary ùêÉ of dimensions M √ó L (M>L as the number of simulated tissues is greater than the sequence length).  The PD is not simulated in the dictionary, as it is the gain used to match the Bloch simulation performed on a single spin to the signal obtained from a pixel containing multiple spins. It can be easily determined after the T1 and T2 maps are known. After successful recovery of ùêó, each row in ùêó is matched to a single row in the dictionary, and T1 and T2 are estimated as those used to generate the matched dictionary row. Each dictionary signature has its own unique T1 and T2 values stored in a look up table (LUT), represented as the matrix ùêãùêîùêì of dimensions M√ó2.\n\n\n\n\n\n ¬ß.¬ß Previous Methods\n\n\n\n\n\nThe approach suggested in the original MRF paper <cit.> is described in Algorithm <ref>, and uses matched filtering to match dictionary\nitems to the acquired data. In the algorithm, F^H{¬∑} is the 2D inverse NUFFT operator.\nThe parameters k_j are the matching dictionary indices, j is a spatial index and i is the temporal index, representing the ith frame in the acquisition.\nThe parameter maps are extracted from ùêãùêîùêì, which holds the values of T1 and T2 for each k_j.\nThis approach does not incorporate sparse based reconstruction, which has been proven to be very successful in MRI applications based on under-sampled data <cit.>.\n\n\n\nDavies et al. <cit.> suggested a method incorporating sparsity of the data in the dictionary domain (i.e. each pixel is represented by at most one dictionary item), referred to as the BLoch response recovery via Iterative Projection (BLIP) algorithm. This approach is based on the Projected Landweber Algorithm (PLA) which is an extension of the popular iterative hard thresholding method.\nBLIP (described here as ) consists of iterating between two main steps: A gradient step that enforces consistency with the measurements, and a projection that matches each row of ùêó to a single dictionary atom.\n\n\n\n\n\n\n\n\nBLIP and a few other works that are based on it <cit.> do not incorporate the temporal similarity across time points, which is a fundamental characteristic of the MRF sequence. In addition, there is a high degree of similarity across signatures in ùêÉ. As a result, the imaging contrasts matrix ùêó is typically a low-rank matrix.\n\n\nLow-rank based modelling for dynamic MRI in general <cit.> and MRF in particular <cit.>-<cit.> has been proposed in the past.\nTo demonstrate the low-rank property of ùêó, we used T1, T2 and PD maps of size 128√ó128 (acquired using DESPOT <cit.>) as an input to a simulation of a FISP sequence <cit.>, using L=500 TRs. In addition, we used random TR and FA values that have been used in previous publications in the field of MRF <cit.>. Note that the general assumption of ùêó being a low-rank matrix holds as long as temporal similarity exist between time-frames in ùêó, and multiple voxels in the image belong to a single tissue, regardless of the specific acquisition parameters. Figure¬†<ref> shows the singular values of ùêó. It can be seen that ùêó is indeed low-rank, as most of the data is represented in the highest 15 singular values.\n\n\n\nThis low-rank property of ùêó can be exploited for improved reconstruction using the following optimization problem:\n\n    ùêó,ùêëminimize      1/2iŒ£‚Äñùêò_:,i-F_u{ùêó_:,i}‚Äñ _2^2\n       subject to      rank(ùêó)‚â§ r\n             ùêó=ùêë_1ùêÉ\n\n\nwhere ùêë_1 is a matrix that matches each pixel (ùêó_j,:) with the dictionary signatures. In many previous implementations of low-rank for MRF, a matching of a single dictionary atom to a single pixel is enforced, which means that the rows of ùêë_1 are one-sparse vectors. The parameter r is the rank of the matrix, and is usually defined as a fixed pre-chosen parameter. Typically r is not known in advance and determining it upfront arise difficulty and may add error to the reconstruction scheme.\n\n\n\n\n\n\n\n\nZhao et al. <cit.> suggested an approximation for problem (<ref>), using an ADMM formulation <cit.> as follows:\n\n    ùêó^n+1,ùêë_1^n+1,ùêô^n+1   =\n          ùêó,ùêë_1,ùêôarg min1/2iŒ£‚Äñùêò_:,i-F_u{ùêó_:,i}‚Äñ _2^2+Œªœà(ùêô)+Œ∑_1‚Äñùêê^n- ùêó+ùêë_1ùêÉ‚Äñ _F^2\n              +Œ∑_2‚Äñùêñ^n-ùêó+ùêô‚Äñ _F^2\n    ùêê^n+1   =\n          ùêê^n+Œ∑_1(ùêó^n+1-ùêë_1^n+1ùêÉ)\n    ùêñ^n+1   =\n          ùêñ^n+Œ∑_2(ùêó^n+1-ùêô^n+1)\n\n\n\n\nwhere the low rank constraint is applied via the function œà(ùêô), defined as the p norm (p<1) of the singular values of ùêô to the power of p.\nThe matrices ùêê and ùêñ are the Lagrange multipliers.\nThe algorithm, coined Model Based Iterative Reconstruction MRF (MBIR-MRF) <cit.> is described in .\n\n\n\n\n\n\n\n\n\n ¬ß.¬ß Proposed Method\n\n\n The constraint presented in previous approaches <cit.> on ùêë_1 to have one sparse rows that contain the corresponding PD values for each row of ùêó, is justified by the assumption that only a single dictionary item should match an acquired signature. However, in practice, we found that superior results (in terms of spatial resolution and correspondence to ground truth) are obtained by relaxing this constraint, and allowing ùêó to be comprised of multiple dictionary elements at each step of the optimization algorithm, where at the final stage each voxel is matched to a single tissue.\n This allows for non-simulated signatures to be described by a linear combination of simulated ones. In addition, the relaxation enables formulating the problem as a convex problem, and saves the pattern recognition search time during reconstruction. The matching between ùêó and the dictionary is done only at the final stage, after ùêó is fully recovered by using a matched filter (MF), in order to extract the parameter maps. For brevity we write the constraint ùêó=ùêëùêÉ as ùêó‚ààùîª where ùîª={X:ùí©(X)‚äáùí©(D)}\n , and we consider the next regularized form:\n\n    ùêó ‚ààùîªminimize      1/2iŒ£‚Äñùêò_:,i-F_u{ùêó_:,i}‚Äñ _2^2+Œªrank(ùêó)\n\n\nfor some fixed regularization parameter Œª.\n\nProblem (<ref>) is not convex due to the rank constraint. We therefore relax this constraint by replacing the rank of ùêó with the nuclear norm ‚Äñùêó‚Äñ _*, defined as the sum of the singular values of ùêó <cit.>. This results in the relaxed problem:\n\n    ùêó ‚ààùîªminimize      1/2iŒ£‚Äñùêò_:,i-F_u{ùêó_:,i}‚Äñ _2^2 +Œª‚Äñùêó‚Äñ _*.\n\n\n\nIn order to solve (<ref>) we use the incremental subgradient proximal method <cit.> as described in .\n\n\n\n\nDue to the convex modelling of the problem, we also introduce an improvement that significantly reduces convergence time. The improvement uses the acceleration approach suggested by Nesterov <cit.> for minimizing a smooth convex function, and its extension for non smooth composite functions of Beck and Teboulle  <cit.>. Our final algorithm is detailed in  and referred to as magnetic resonance Fingerprint with LOw Rank (FLOR), where the parameter Œª is chosen experimentally. Note that by setting Œª=0, enforcing ùêë to have one-sparse rows and eliminating the acceleration step, FLOR reduces to BLIP <cit.>.\n\n\n\n\n\n\nFigure¬†<ref> shows the reconstruction error of FLOR as the number of iterations varies with and without the acceleration step. Note that the CPU time of both algorithms is similar.\n\n\n\n\n\n\n\n\n\n\n\n\n ¬ß.¬ß Possible extension\n\n Conventional MRF algorithms use MF for the magnetic parameter extraction. MF introduces a quantization error since map values are continuous, as opposed to discrete dictionary values. A possible extension of FLOR is to add values to the dictionary by linear interpolation, in regions where a few candidates from the dictionary match a single signature from the data. We then select the dictionary signatures that exhibit a high correlation value (the ones above a certain threshold) and average their matching T1 and T2 values.\nThis improvement expands the possible solutions to include ones that do not exist in the dictionary, and therefore exhibits improved accuracy compared to the conventional matching. The major benefit from this extension is reduced quantization errors that arise from conventional MF used in MRF. This extension, coined FLOR II, is examined in the first part of our experimental results in the next section.\n"
        },
        {
            "section_number": 3,
            "title": "EXPERIMENTAL RESULTS",
            "summary": "Discuss the experimental results of two MRI experiments using brain scans of a healthy subject, focusing on the performance and error analysis of different reconstruction algorithms under retrospective and prospective sampling conditions.",
            "target_length": 1400,
            "origin_content": "This section describes two MRI experiments that were carried out using brain scans of a healthy subject. The first experiment is based on well known quantitative maps that were used, in a purely simulation environment to generate an MRF experiment with retrospectively sampled data. While this experiment is a simulation based on real quantitative maps, it allows accurate comparison of the results of the different algorithms using a well defined reference.\n\nIn the second experiment, we used prospective sampled real MRF data that was used to generate the results in Ma et al. <cit.>. While this experiment lacks a gold-standard for accurate error evaluation, it allows comparison between different algorithms in a realistic multi-coil acquisition. To compare between different algorithms, for prospective sampling, where no ground truth is available, we examined the performance of the various algorithms as a function of the total number of excitations, where correspondence to values provided in literature for various brain tissues is used for validation. In both experiments, variable density spiral trajectories were used for sampling.\n\nFor quantitative error analysis, we calculated the normalized MSE (NMSE) between each quantitative map estimation and the reference map, defined as:\n\n    NMSE_i= ||Œ∏_i-Œ∏ÃÇ_i||_F^2/||Œ∏_i-1/Nj‚àëŒ∏_i^j||_F^2\n\nwhere Œ∏_i, Œ∏ÃÇ_i represent a reference map (such as T1,T2 or PD) and its corresponding reconstructed map (respectively), N is the number of pixels in the map and j is a spatial index.\n\n\n\nIn the first experiment, forward and inverse non-uniform Fourier transforms were applied using SPURS, which is a fast approach published recently <cit.>. For the second experiment, we used the NUFFT package <cit.>, to adhere with the reconstruction results of the original MRF paper <cit.>.\n\n\n\n ¬ß.¬ß Experiment 1: Retrospective undersampling of real data\n\n\nThe data for this experiment was acquired with a GE Signa 3T HDXT scanner. The\nprocedures involving human subjects described in this experiment were approved by the Institutional Review Board of Tel-Aviv\nSourasky Medical Center, Israel. We generated our reference data by acquisition of Fast Imaging Employing Steady-state Acquisition (FIESTA) and Spoiled Gradient Recalled Acquisition in Steady State (SPGR) images, at 4 different flip angles (3^‚àò ,5^‚àò,12^‚àò and 20^‚àò), implementing the fast and well known DESPOT1 and DESPOT2 <cit.> algorithms, after improvements as described in Liberman et al. <cit.>, to generate T1,T2 and PD quantitative maps, each of size 128 √ó 128 pixels. While it is well known that the gold standard method for T1 measurement is the inversion recovery spin echo with varying TIs and for T2 measurement is the spin echo sequences with varying TEs, in this experiment DESPOT was used as a reference thanks to its availability and its relatively fast acquisition time. The FISP pulse sequence has been applied for simulating acquisition of the reference. It was simulated with constant TE of 2ms, random TR values in the range of 11.5-14.5 ms, and a sinusoidal variation of FA (RF pulses) in the range of 0-70 degrees <cit.>.\n\n\nTo simulate noisy undersampled MRF samples, we added complex Gaussian zero-mean noise to the k-space data to obtain an SNR of 67dB in the undersampled measurement domain. Data was then under-sampled to acquire only 876 k-space samples in each TR with spiral trajectories. In particular, we used 24 variable density spirals with inner region size of 20 and FOV of 24. In every time frame, each spiral is shifted by 15 degrees. Figure <ref> demonstrates the first spiral trajectory. We define the under-sampling ratio by the number of the acquired samples in the k-space domain divided by the number of pixels in the generated image. This leads to an undersampling ratio of Àú5% in this experiment. For comparison, the under-sampling ratio of the original MRF paper <cit.> is Àú9%, since for each single spiral 1450 data points were acquired.\n\n\n\nWe generated the dictionary using Bloch equations, simulating T1 values of [100:20:2000,\n2300:300:5000] ms and T2 values of [20:5:100,110:10:200,300:200:1900] ms. This range covers the relaxation time values that can be found in a healthy brain scan <cit.>. The tuning parameters were experimentally set as Œº=1 and Œª=5, after Œª was tested in the range between 0 and 30.\nData was fed as an input to BLIP, MBIR-MRF and the improved FLOR algorithm (described as Algorithms 2,3 above and Algorithm 4 with the additional extension of interpolating the parameter maps). In addition, we performed reconstruction using 100% of the data (without the addition of noise) via conventional MRF (), for comparison purposes and to evaluate the error caused by the effect of discretized dictionary. All the iterative algorithms were run until the difference between consecutive iterations was below the same threshold.\n\n\n\nThe MATLAB code for reproducing the experiment provided in this section can be be found at: http://webee.techni- on.ac.il/Sites/People/YoninaEldar/software_det18.php. In this code, spiral sampling trajectories design was based on Lee et al. <cit.>.\n\n\n\n\nFigure¬†<ref> shows the resulting maps for the recovery of T1, T2 and PD obtained with the various algorithms against the reference (left). The corresponding error maps of each method versus the reference are shown in Fig.¬†<ref>. To allow detailed view of the reconstruction results for the reader, Fig.¬†<ref> shows a zoomed region for each map.\n\nIt can be seen that both FLOR and MBIR-MRF outperform BLIP reconstruction results, when using 5% of sampled data by utilizing the low rank property. In addition, FLOR provides a lower error compared to MBIR-MRF. The details in the FLOR maps are comparable to those obtained by the original MRF algorithm using 100% of the noise-free data.\n\nDue to the very low sampling ratio in our experiments (measured as the number of samples divided by the number of pixels in the image), conventional MRF using 5% of the data did not provide valuable reconstruction results and is therefore omitted in this analysis.\n\n\n\nWe next implemented the MF improvement described in Section II.D. The results are shown in Fig.¬†<ref>, with corresponding error maps in Fig.¬†<ref>.  These figures compare the recovery maps of FLOR without (FLOR I) and with (FLOR II) the proposed improvement.\nIt can be seen that FLOR II improves the results of FLOR I and produces a smoother solution which better fits the reference maps.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n ¬ß.¬ß Experiment 2: In vivo prospective sampling experiment\n\nThe experiment in this section was carried out using the data of the original MRF paper <cit.>,\n\n\nwhich consisted of 48 spiral trajectories shifted by 7.5 degrees, where 1450 samples were acquired in each trajectory, leading to an underampling ratio of 9%. The data was acquired on a 1.5-T whole body scanner (Espree, SIEMENS Healthcare) using a 32-channel head receiver coil.\n\n\n\nDue to the lack of gold standard maps for this data, we are unable to provide quantitative error results (e.g. NMSE). Therefore, in this experiment we compare between the various algorithms by examining reconstruction results using 400 TRs (representing 40% of scanning time),\nto quantitative values of brain tissues from the literature. Since the results obtained in the original MRF experiment (using 1000 TRs) mostly correspond to quantitative values from the literature, the maps generated using 1000 TRs using the original MRF algorithm are provided in Fig.¬†<ref>, for reference.\n\n\n\n\nThe results of T1, T2 and PD maps for BLIP, MBIR-MRF and FLOR appear in Fig.¬†<ref>. Since IR-bSSFP sequence has been used in this experiment, off-resonance frequency has also been computed and shown.  We used 109 different values in the range between -250 and 240 Hz.\n\n\nIt can be seen that for T1, all iterative algorithms provide similar results, and T1 values of grey matter (GM), white matter (WM) and cerebrospinal fluid (CSF) regions correspond to similar values that appear in the literature (see Table 1 in Ma et al.<cit.>) and in Fig.¬†<ref>. While T2 results exhibit visible differences between the various methods, WM and GM values for all methods correspond to values that appear in the literature. However, both BLIP and MBIR MRF exhibit T2 values for CSF that are lower than those reported in the literature. This can be seen in Fig.¬†<ref>, where the color scale for T2 is adjusted to 500-2000ms (T2 values for CSF are around 2000ms). Shortened T2 values in CSF were also reported in the original MRF experiment with 1000 TRs (and were justified as out-of-plane flow in this 2D experiment). In our case, using the same acquired data, it can be seen in Fig.¬†<ref> that FLOR provides CSF values that better correspond to literature values, when compared to the other methods.\n"
        },
        {
            "section_number": 4,
            "title": "DISCUSSION",
            "summary": "Discuss the unique aspects and advantages of the proposed low-rank magnetic resonance fingerprinting solution, including its computational efficiency and comparison to existing methods.",
            "target_length": 300,
            "origin_content": "¬ß.¬ß Relation to previous works\n\nAlthough works that exploit the low rank structure of MRF sequences have been published in the past by others  and also by us <cit.>, our solution is unique mainly in the combination of convex modelling and the ability to enable a solution with quantitative values that do not exist in the dictionary. Our solution is based on soft-thresholding the singular values <cit.>, which is mathematically justified in .\n\n\n\n\nMoreover, we compare our algorithm to both CS-based and low-rank based methods for MRF and demonstrate superior results. While BLIP treats the original MRF problem as an ‚Ñì_0 optimization problem, FLOR first solves the relaxed problem of (<ref>) and only then uses MF to extract the magnetic parameters. It leads to some beneficial properties such as convergence guarantees, and the ability to use the acceleration step as described in , which is also novel in MRF reconstruction methods.\n\n\n\n\n\n\n\n\n ¬ß.¬ß Computational complexity\n FLOR is divided into two main components: The first recovers the imaging contrasts, and the second extracts the parameter maps from the recovered contrasts.\nThe computational burden of FLOR lies in the low-rank projection step, or specifically, in the SVD calculation. This step does not exist in BLIP nor the original MRF reconstruction. However, there are efficient fast techniques to calculate the SVD <cit.>, required by FLOR. Moreover, unlike BLIP, and other low rank based algorithms such as MBIR-MRF, FLOR does not require the pattern recognition calculation at every iteration.\n\nAnother time consuming step that exists in all algorithms is the non uniform Fourier transform. By using the acceleration step, FLOR reduces significantly the number of iterations required for convergence and therefore saves computational cost.\n\nIn addition, while previous implementations of CS-based reconstruction algorithms mainly use the inverse NUFFT (iNUFFT) algorithm, in our retrospective experiemtns we use SPURS <cit.>. Based on our observations, SPURS provides improved image reconstruction with the same computational complexity compared to iNUFFT.\n"
        },
        {
            "section_number": 5,
            "title": "CONCLUSIONS",
            "summary": "Discuss the effectiveness and advantages of the FLOR method in reconstructing high-quality quantitative MRI data from highly under-sampled data, highlighting its comparison with existing methods and potential directions for future research.",
            "target_length": 200,
            "origin_content": "We presented FLOR, a method for high quality reconstruction of quantitative MRI data using MRF, by utilizing the low-rank property of MRF data. Due to the fact that we exploit low-rank on top of the well known sparsity of MRF in the dictionary matching domain, we are able to obtain high quality reconstruction from highly under-sampled data. Our method is based on a convex minimization problem, leading to a solution in the dictionary subspace that overcomes its quantization error.\n\nWe provide results that are comparable to fully sampled MRF, using only 5% of the data in a simulation environment. In addition, comparison against CS-based and low-rank based methods for MRF shows the added value of our approach in generating quantitative maps with less artifacts. Our results also consist of real-data, in-vivo experiments that exhibit FLOR superiority also for realistic multi-coil data acquisition. Future work will examine more sophisticated patch wise recoveries.\n"
        },
        {
            "section_number": 6,
            "title": "ACKNOWLEDGEMENTS",
            "summary": "Draft an acknowledgements section for a research paper, highlighting the contributions and support received from various institutions, individuals, and funding bodies involved in the project, while also addressing any potential conflicts of interest.",
            "target_length": 100,
            "origin_content": "The authors wish to thank the Tel Aviv center for brain functions at Tel Aviv Sourasky Medical Center for providing the data required for experiment 1. We also wish to thank Dan Ma and Prof. Mark Griswold for providing the real data used in their experiments. This work was supported by the\nMinistry of Science, by the ISF I-CORE joint research center of the\nTechnion and the Weizmann Institute, and by the European Union‚Äôs\nHorizon 2020 research and innovation programme under grant agreement\nNo. 646804-ERC-COG-BNYQ, Assaf Tal acknowledges the support of the Monroy-Marks Career Development Fund, the Carolito Stiftung Fund, the Leona M. and Harry B. Helmsley Charitable Trust and the historic generosity of the Harold Perlman Family. The authors have no relevant conflicts of interest to disclose.\n"
        },
        {
            "section_number": 7,
            "title": "",
            "summary": "Explain the optimization problem and solution approach used in the basic implementation of FLOR for low-rank magnetic resonance fingerprinting, detailing the role of the incremental proximal method and singular value soft-thresholding in the process.",
            "target_length": 300,
            "origin_content": "The basic implementation of FLOR, as described in  in the paper, aims to solve the following optimization problem:\n\n\n\n\n\n\n\n    X‚ààùîªargmin1/2iŒ£‚Äñùêò_:,i-F_u{ùêó_:,i}‚Äñ _2^2+Œª||X||_*\n\n\nwhere F_u is the partial Fourier transform operator, X has dimensions N^2 √ó L and ùîª={X:ùí©(X)‚äáùí©(D)}.\n\nFLOR solves (<ref>) using the incremental proximal method <cit.>, which treats problems of the form:\n\n    X‚ààùîªargmin {Œ£_i^m F_i(X)}\n\nwhere F_i(X)=f_i(X)+h_i(X). The function f_i(X) is convex and non-differentiable, h_i(X) is a convex function and ùîª is a non-empty, closed, and convex subspace. The general step in solving (<ref>) is given by [27, (4.12)-(4.13)]:\n\n\n\n    Z^k=P_ùîª(X^k-Œº_k g_i_k)\n\n\n    X^k+1=X‚ààùîªargmin f_i_k(X)+1/2Œº_kX-Z^k_F^2\n\n\n\n\nwhere g_i_k‚àà‚àÇ h_i_k(X^k), Œº_k is a positive step size, and P_ùîª is the projection operator onto ùîª defined as\n\n\n    P_ùîª(X)   = Z‚ààùîªargminZ-X_F^2.\n\n\nThe optimization problem, defined in the update step of X^k+1, is referred to as the proximal gradient calculation of the non-differentiable f_i_k, under the constraint X‚ààùîª.\n\nOur problem in (<ref>) corresponds to m=1 in (<ref>) and\n\n    h(X)   =1/2iŒ£‚Äñùêò_:,i-F_u{ùêó_:,i}‚Äñ _2^2=1/2Y-F_u{X}_F^2\n\n    f(X)   =ŒªX_*.\n\nTherefore,\n\n    ‚àÇ h(X)   =F_u^H{Y-F_u{X}},\n\n\nand,\n\n    P_ùîª(X)   =XD^‚Ä†D=XP.\n\n\nThe solution of (<ref>) for f(X)=ŒªX_* without the constraint X‚ààùîª, is the singular value soft-thresholding operator (SVT) <cit.> defined as:\n\n    SVT_Œº_kŒª(Z^k)=U_r[Œ£_r-Œº_kŒªI]_+V_r^H.\n\nHere Œ£_r is a diagonal matrix with the non-zero singular values of Z^k on its diagonal, U_r and V_r are the r left and right singular vectors of the SVD of Z^k, associated with the r non-zero singular values, and [x]_+=max(0,x).\n\nIn our case, since Z^k‚ààùîª (as follows from (<ref>)) and the SVT calculation keeps the operand in the same subspace, the constraint X‚ààùîª can be omitted. Therefore, (<ref>) reduces to\n\n    X^k+1=U_r[Œ£_r-Œº_kŒªI]_+V_r^H.\n\n\n\n\nCombining (<ref>), (<ref>) and (<ref>), the incremental subgradient-proximal method for solving (<ref>) consists of two updates in each iteration:\n\n\n    Z^k=(X^k-Œº_kF_u^H{Y-F_u{X^k}})P\n\n\n    X^k+1=U_r[Œ£_r-Œº_kŒªI]_+V_r^H.\n\n\n\nThis constitutes the core of Algorithms 4. In our framework, the step sizes are set to constant, Œº_k=Œº, and Œª is chosen experimentally.\n"
        }
    ],
    [
        {
            "section_number": 1,
            "title": "INTRODUCTION",
            "summary": "Write the section that introduces the concepts of patches and moats, explains their significance, and provides bounds on the area of moats in the context of 3-connected cubic plane graphs with all faces of size at most 6.",
            "target_length": 500,
            "origin_content": "A set of edges intersecting every odd cycle in a graph is known as an\nodd cycle (edge) transversal, or odd cycle cover, and the\nminimum size of such a set is denoted by œÑ_. A set of edge-disjoint\nodd cycles in a graph is called a packing of odd cycles, and the maximum\nsize of such a family is denoted by ŒΩ_. Clearly, œÑ_‚â•ŒΩ_.\nDejter and Neumann-Lara¬†<cit.> and independently\nReed¬†<cit.> showed that in general, œÑ_ cannot be bounded\nby any function of ŒΩ_, i.e., they do not satisfy the\nErd≈ës‚ÄìP√≥sa property. However, for planar graphs, Kr√°l' and\nVoss¬†<cit.> proved the (tight) bound œÑ_‚â§ 2ŒΩ_.\n\nIn this paper we focus on packing and covering of odd cycles in 3-connected\ncubic plane graphs with all faces of size at most 6. Such graphs‚Äîand their\ndual triangulations‚Äîare a very natural class to consider, as they correspond\nto surfaces of genus 0 of non-negative curvature (see e.g.¬†<cit.>).\n\nA much-studied subclass of cubic plane graphs with all faces of size at most 6\nis the class of fullerene graphs, which only have faces of size 5 and 6.\nFaria, Klein and Stehl√≠k¬†<cit.> showed that any fullerene\ngraph on n vertices has an odd cycle transversal with no more than\n‚àö(12n/5) edges, and characterised the extremal graphs. Our main result\nis the following extension and sharpening of their result to all 3-connected cubic\nplane graphs with all faces of size at most 6.\n\n\n\n  Let G be a 3-connected cubic plane graph on n vertices with all faces of size at most\n  6, with p pentagonal and t triangular faces. Then\n\n    œÑ_(G) ‚â§‚àö((p+3t)n/5).\n\n  In particular, œÑ_(G) ‚â§‚àö(12n/5) always holds, with equality\n  if and only if all faces have size 5 and 6, n=60k^2 for some\n  k ‚àà, and (G) ‚âÖ I_h.\n\n\nIf G is a fullerene graph, then t=0 and Euler's formula implies that p=12, so\nTheorem¬†<ref> does indeed generalise the result of Faria, Klein and Stehl√≠k¬†<cit.>.\nWe also remark that the smallest 3-connected cubic plane graph with all faces of size at most 6\nachieving the bound œÑ_(G) = ‚àö(12n/5) in Theorem¬†<ref> is the ubiquitous\nbuckminsterfullerene graph (on 60 vertices).\n\nThe rest of the paper is organised as follows. In Section¬†<ref>,\nwe introduce the basic notation and terminology, as well as the key concepts from\ncombinatorial optimisation and topology. In Section¬†<ref>, we introduce\nthe notions of patches and moats, and prove bounds on the area of moats. Then, in\nSection¬†<ref>, we use these bounds to\nprove an upper bound on the maximum size of a packing of T-cuts in triangulations\nof the sphere with maximum degree at most 6. Using a theorem of Seymour¬†<cit.>,\nwe deduce, in Section¬†<ref>, an upper bound on the minimum\nsize of a T-join in triangulations of the sphere with maximum degree at most 6,\nand then dualise to complete the proof of Theorem¬†<ref>. In\nSection¬†<ref>, we deduce lower bounds on the size of a maximum cut and\na maximum independent set in 3-connected cubic plane graphs with no faces of size\nmore than 6. Finally, in Section¬†<ref>, we show why the condition\non the face size cannot be relaxed, and briefly discuss the special case when the graph\ncontains no pentagonal faces.\n"
        },
        {
            "section_number": 2,
            "title": "PRELIMINARIES",
            "summary": "Describe the fundamental concepts, terminologies, and mathematical principles related to graph theory, polygonal surfaces, and combinatorial optimization that are essential for understanding the analysis of cubic plane graphs and their duals in the context of packing and covering odd cycles.",
            "target_length": 900,
            "origin_content": "Most of our graph-theoretic terminology is standard and follows¬†<cit.>.\nAll graphs are finite and simple, i.e., have no loops and parallel edges.\nThe degree of a vertex u in a graph G is denoted by d_G(u).\nIf all vertices in G have degree 3, then G is a cubic graph.\nThe set of edges in G with exactly one end vertex in X is denoted by Œ¥_G(X).\nA set C of edges is a cut of G if C=Œ¥_G(X), for some X ‚äÜ V(G).\nWhen there is no risk of ambiguity, we may omit the subscripts in the above notation.\n\nThe set of all automorphisms of a graph G forms a group, known as the automorphism group\n(G). The full icosahedral group I_h ‚âÖ A_5 √ó C_2 is the group of\nall symmetries (including reflections) of the regular icosahedron. The full tetrahedral\ngroup T_d ‚âÖ S_4 is the group of all symmetries (including reflections) of the regular\ntetrahedron.\n\nA polygonal surface K is a simply connected 2-manifold, possibly with a boundary,\nwhich is obtained from a finite collection of disjoint simple polygons in ^2 by\nidentifying them along edges of equal length. We denote by |K| the union of all polygons in\nK, and remark that |K| is a surface.\n\nBased on this construction, K may be viewed as a graph embedded in the\nsurface |K|. Accordingly, we denote its set of vertices, edges, and faces\nby V(K), E(K), and F(K), respectively. If every face of K is incident to three edges,\nK is a triangulated surface, or a triangulation of |K|.\nIn this case, K can be viewed as a simplicial complex.\nIf K is a simplicial complex and X ‚äÜ V(K),\nthen K[X] is the subcomplex induced by X, and K‚àñ X is the subcomplex\nobtained by deleting X and all incident simplices. If L is a subcomplex of K,\nthen we simply write K ‚àñ L instead of K ‚àñ V(L).\n\nIf K is a graph embedded in a surface |K| without boundary, the dual graph\nK^* is the graph with vertex set F(K), such that fg ‚àà E(K^*) if and only if f and\ng share an edge in K. The size of a face f ‚àà F(K) is defined as the number\nof edges on its boundary walk, and is denoted by d_K(f). Note that d_K(f)=d_K^*(f^*).\n\nAny polygonal surface homeomorphic to a sphere corresponds to a plane\ngraph via the stereographic projection. Therefore, terms such as `plane triangulation'\nand `triangulation of the sphere' can be used interchangeably.\nWe shall make the convention to use the term `cubic plane graphs' because it is so\nwidespread, but refer to the dual graphs as `triangulations of the sphere' because\nit reflects better our geometric viewpoint.\n\nGiven a polygonal surface K, the boundary ‚àÇ K is the set of all\nedges in K which are not incident to two triangles; the number of edges in the\nboundary is denoted by |‚àÇ K|. With a slight abuse of notation, ‚àÇ K will also denote\nthe set of vertices incident to edges in ‚àÇ K. The set of interior vertices\nis defined as (K)=V(K)‚àñ‚àÇ K.\n\nGiven a triangulated surface K, we define K to be the number of faces in K,\nand the combinatorial curvature of K as ‚àë_u ‚àà(K)(6-d_K(u)).\nRecall that the Euler characteristic\nœá(K) of a polygonal surface K is equal to |V(K)|-|E(K)|+|F(K)|. It can be shown\nthat œá is a topological invariant: it only depends on the surface |K|, not on the\npolygonal decomposition of K. If X is any contractible space, then œá(X)=1, and\nif S^2 is the standard 2-dimensional sphere, then œá(S^2)=2. The following lemma\nis an easy consequence of Euler's formula and double counting, and we leave its verification\nto the reader.\n\n\n\n  Let K be a triangulated surface with (a possibly empty) boundary ‚àÇ K. Then\n\n    ‚àë_v ‚àà K(6-d(v))+‚àë_v ‚àà‚àÇ K(4-d(v))=6œá(K).\n\n\n\nWe remark that, if we multiply both sides of the equation by œÄ/3, we obtain a discrete\nversion of the Gauss‚ÄìBonnet theorem (see e.g.¬†<cit.>), where the curvature is concentrated at the vertices.\n\nIn order to prove Theorem¬†<ref>, it is more convenient to work with the dual\ngraphs, which are characterised by the following simple lemma. The proof is an easy\nexercise, which we leave to the reader.\n\n\n\n  If G is a 3-connected simple cubic plane graph with all faces of size at most 6, then the dual\n  graph G^* is a simple triangulation of the sphere with all vertices of degree at\n  least 3 and at most 6.\n\n\nWe will use the following\nimportant concept from combinatorial optimisation. Given a graph G=(V,E) with a distinguished\nset T of vertices of even cardinality, a T-join of G is a subset J ‚äÜ E\nsuch that T is equal to the set of odd-degree vertices in (V,J). The minimum size of a\nT-join of G is denoted by œÑ(G,T). When T is the set of odd-degree vertices of G,\na T-join is known as a postman set. A T-cut is an edge cut Œ¥(X) such\nthat |T‚à© X| is odd. A packing of T-cuts is a disjoint collection\nŒ¥(‚Ñ±)={Œ¥(X) | X ‚àà‚Ñ±} of T-cuts of G; the maximum\nsize of a packing of T-cuts is denoted by ŒΩ(G,T).\n\nA family of sets ‚Ñ± is said to be laminar if, for every pair\nX,Y ‚àà‚Ñ±, either X ‚äÜ Y, Y ‚äÜ X, or X ‚à© Y = ‚àÖ.\nA T-cut Œ¥(X) is inclusion-wise minimal if no T-cut is properly contained\nin Œ¥(X). For more information on T-joins\nand T-cuts, the reader is referred to¬†<cit.>.\n"
        },
        {
            "section_number": 3,
            "title": "PATCHES AND MOATS",
            "summary": "Explain the definitions and properties of patches and moats in triangulations of the sphere, and derive isoperimetric inequalities that relate the combinatorial curvature of patches to the geometry of their surrounding moats, emphasizing the conditions under which equality holds.",
            "target_length": 1000,
            "origin_content": "From now on assume that K is a triangulation of the sphere with all vertices of degree at most 6.\nWe define a subcomplex L ‚äÜ K to be a patch if in the dual complex K^*, the faces\ncorresponding to V(L) form a subcomplex homeomorphic to a disc. (Equivalently, one could say\nthat L ‚äÜ K is a patch if L is an induced, contractible subcomplex of K.)\nA patch L‚äÜ K such that c=‚àë_u ‚àà V(L)(6-d_K(u)) is called a c-patch.\nWe remark that a c-patch L has combinatorial curvature c if and only if all vertices in the\nboundary ‚àÇ L have degree 6 in K.\nIf u ‚àà V(K) has degree 6-c, and the set X of vertices at distance at most r from u\ncontains only vertices of degree 6, then the c-patch K[{u}‚à™ X] is denoted by D_r(c).\nThe subcomplex of the dual complex K^* formed by the faces in V(D_r(c)) is denoted by D^*_r(c);\nsee Figure¬†<ref>.\n\n\n\nThe following isoperimetric inequality follows from the work of\nJustus¬†<cit.>[Gunnar Brinkmann¬†<cit.>\nhas pointed out an error in the statement and proof of <cit.>\non which <cit.> is based, but has sketched a different way to prove\n<cit.>.].\n\n\n\n  Let K^* be a polygonal surface homeomorphic to a disc, with all internal vertices of\n  degree 3 and with n faces, all of size at most 6. Let c=‚àë_f ‚àà F(K^*)(6-d(f)),\n  and suppose that c ‚â§ 5. Then\n\n    |‚àÇ K^*| ‚â•‚àö(8(6-c)(n-1)+(6-c)^2).\n\n  Equality holds if K^* ‚âÖ D^*_r(c), for some integer r ‚â• 0, and only\n  if at most one face in K^* has size less than 6.\n\n\n\n  The minimum possible values of |‚àÇ K^*| are given in¬†<cit.>,\n  for all possible numbers of hexagonal, pentagonal, square, and triangular faces.\n  In each case, our bound is satisfied. Moreover, it can be checked that equality\n  holds only if at most one face in K^* has size less than 6. Finally, if\n  K^* ‚âÖ D^*_r(c), then it can be shown that |‚àÇ K^*|=(6-c)(2r+1) and\n  f-1=(6-c)r(r+1)/2. Hence, |‚àÇ K^*| = ‚àö(8(6-c)(f-1)+(6-c)^2).\n\n\nWe can use Lemma¬†<ref> to deduce the following isoperimetric inequality\nfor triangulations. Certain special cases of the inequality were already proved by\nJustus¬†<cit.>.\n\n\n\n  Let K be a triangulation of the sphere with all vertices of degree at most 6,\n  and let L ‚äÜ K be a patch of combinatorial curvature c ‚â§ 5. Then\n\n    |‚àÇ L| ‚â•‚àö((6-c)  L).\n\n  Equality holds if L ‚âÖ D_r(c), for some integer r ‚â• 0, and only\n  if at most one vertex in L has degree less than 6.\n\n\n\n  Put n=|V(K)|, and let L^* be the subcomplex of K^* formed by the faces\n  corresponding to V(L). By Lemma¬†<ref>,\n\n    |‚àÇ L^*| ‚â•‚àö(8(6-c)(n-1)+(6-c)^2).\n\n  Moreover, the following two equalities were shown by Justus¬†<cit.>\n\n    2(n-1)= L-|‚àÇ L|,\n\n\n    |‚àÇ L|^2 = 14|‚àÇ(L^*)|^2+(6-c)|‚àÇ L|-14(6-c)^2.\n\n  So, combining (<ref>), (<ref>) and (<ref>) gives\n\n    |‚àÇ L|^2 ‚â• (6-c)  L.\n\n\n  Equality holds in¬†(<ref>) if and only if equality holds in¬†(<ref>). The\n  latter is true only if at most one face in L^* has size less than 6, or equivalently,\n  only if at most one vertex in L has degree less than 6. For the final\n  part, it is enough to note that if L ‚âÖ D_r(c), then L^* ‚âÖ D^*_r(c), so\n  equality holds in¬†(<ref>) and therefore in¬†(<ref>).\n\n\nLet L ‚äÜ K be a patch. A moat of width 1 in K surrounding L\nis the set ^1(L) of all the faces in F(K)‚àñ F(L) with at\nleast one vertex in V(K). More generally, we can define a moat of width w in K surrounding\nL recursively as ^w(L)=^1(^w-1(L)‚à™ L). With a slight abuse of notation,\n^w(L) will also denote the subcomplex of K formed by the faces in ^w(L).\nIf L is a c-patch, then ^w(L) is a c-moat of width w surrounding L.\nSee Figure¬†<ref> for an example of a moat.\n\n\n\nUnder certain conditions, the area of a c-moat ^w(L) can be bounded\nin terms of c, w, and L.\n\n\n\n  Let K be a triangulation of the sphere with maximum degree at most 6,\n  and suppose L ‚äÜ K is a c-patch, for some 0<c<6.\n  If L‚à™^i(L) is a c-patch, for every 0‚â§ i ‚â§ w-1, then\n\n    ^w(L)‚â• (6-c)w^2+2w‚àö((6-c)  L).\n\n  Equality holds if L ‚âÖ D_r(c), for some integer r ‚â• 0, and only\n  if at most one vertex in L has degree less than 6.\n\n\n\n  As L is contractible, its Euler characteristic is œá(L)=1.\n  We have\n\n    c    = ‚àë_u ‚àà V(L)(6-d_K(u))\n       = ‚àë_u ‚àà L(6-d_L(u))+‚àë_u ‚àà‚àÇ L(6-d_L(u))-^1(L)\n       = ‚àë_u ‚àà L(6-d_L(u))+‚àë_u ‚àà‚àÇ L(4-d_L(u))+2|‚àÇ L|-^1(L).\n\n  Hence, by Lemma¬†<ref>,\n\n    2|‚àÇ L|+6-c = ^1(L).\n\n\n  The dual complex K^* is homeomorphic to the sphere and the subcomplex L^*\n  formed by the faces corresponding to V(L) is homeomorphic to a disc, so by the\n  Jordan‚ÄìSchoenflies theorem, the subcomplex formed by the faces corresponding\n  to V(K)‚àñ V(L) is also homeomorphic to a disc. Hence, K ‚àñ L is\n  also a patch. Moreover, K has Euler characteristic œá(K)=2, so by\n  Lemma¬†<ref>, ‚àë_u ‚àà V(K)(6-d(u))=12. Therefore,\n  ‚àë_u ‚àà V(K‚àñ L)(6-d_K(u))=12-c, i.e., K ‚àñ L is a\n  (12-c)-patch. Applying¬†(<ref>) to L and to\n  K‚àñ L,\n\n    2|‚àÇ L|+6-c    = ^1(L)\n       = ^1(K‚àñ L)\n       = 2|‚àÇ(K‚àñ L)|+6-(12-c).\n\n  Hence, |‚àÇ(L ‚à™^1(L))|=|‚àÇ(K‚àñ L)|=|‚àÇ L|+6-c, so by\n  induction, and the fact that L ‚à™^i(L) is a patch for all 0 ‚â§ i ‚â§ w-1,\n\n    |‚àÇ(L ‚à™^i(L))|=|‚àÇ L|+(6-c)i.\n\n  By¬†(<ref>) and¬†(<ref>),\n\n    ^1(L ‚à™^i(L))   = 2|‚àÇ(L ‚à™^i(L))|+6-c\n       = 2(|‚àÇ L|+(6-c)i)+6-c\n       = 2|‚àÇ L|+(6-c)(2i+1),\n\n  so the area of ^w(L) is\n\n    ^w(L)   = ‚àë_i=0^w-1^1(L ‚à™^i(L))\n       = ‚àë_i=0^w-1(2|‚àÇ L|+(6-c)(2i+1))\n       = 2w|‚àÇ L|+(6-c)w^2.\n\n  The combinatorial curvature of L is at most c, so by Lemma¬†<ref>,\n\n    |‚àÇ L| ‚â•‚àö((6-c)  L),\n\n  with equality if L ‚âÖ D_r(c), for some integer r ‚â• 0, and only\n  if at most one vertex in L has degree less than 6.\n"
        },
        {
            "section_number": 4,
            "title": "PACKING ODD CUTS IN TRIANGULATIONS OF THE SPHERE WITH MAXIMUM DEGREE AT MOST 6",
            "summary": "Discuss the relationship between packing odd cuts and moats in triangulations of the sphere with a maximum degree of 6, and derive an upper bound on the maximum size of such packings, emphasizing the mathematical techniques and inequalities used to establish these results.",
            "target_length": 1600,
            "origin_content": "We now relate certain special types of packings of T-cuts to packings of\n1-, 3- and 5-moats.\n\n\n\n  Let K be a triangulation of the sphere with all vertices of degree at most 6,\n  and let T be the set of odd-degree vertices in K. There exists a family\n  ‚Ñ± on V(K) and a vector w ‚àà^|‚Ñ±| with the following\n  properties.\n\n\n  *  ‚Ñ≥=‚ãÉ_X ‚àà‚Ñ±_K^w_X(X) is a packing of\n      moats in K;\n\n  *  The total width of ‚Ñ≥ is ‚àë_X ‚àà‚Ñ±w_X=ŒΩ(K,T);\n\n  *  For every X ‚àà‚Ñ±, the subcomplex K[X] is a patch;\n\n  *  Every ^w_X(X) ‚àà‚Ñ≥ is a 1-, 3-, or 5-moat in K;\n\n  *  If X is an inclusion-wise minimal element in ‚Ñ±, then |X|=1;\n\n  *  ‚Ñ± is laminar.\n\n\n\n\n  Consider a packing Œ¥(‚Ñ±') of inclusion-wise minimal T-cuts in K of size\n  of ŒΩ(K,T). Note that ‚àë_u ‚àà X(6-d_K(u)) is odd, for every X ‚àà‚Ñ±.\n  Since ‚àë_u ‚àà X(6-d_K(u))=12 and Œ¥(X)=Œ¥(V(K)‚àñ X), we can assume that\n  ‚àë_u ‚àà X(6-d_K(u))‚â§ 5; otherwise we could replace X by V(K)‚àñ X in\n  Œ¥(‚Ñ±'). Finally, we can also assume that,\n  subject to the above conditions, ‚Ñ±' minimises ‚àë_X ‚àà‚Ñ±' |X|.\n\n  We remark that ‚Ñ±' is a laminar family. Indeed, suppose that X,Y ‚àà‚Ñ±',\n  X ‚à© Y ‚â†‚àÖ, X ‚äàY and Y ‚äàX. Then\n  ^1(X)‚à©^1(Y)‚â†‚àÖ, so there is a face {u,v,w} of K in\n  ^1(X)‚à©^1(Y). Since\n\n    |Œ¥(X)‚à©{uv,uw,vw}|=|Œ¥(Y)‚à©{uv,uw,vw}| = 2,\n\n  it follows that Œ¥(X)‚à©Œ¥(Y)‚â†‚àÖ, contradicting the fact that\n  ‚Ñ±' is a packing of T-cuts. Hence, ‚Ñ±' is laminar.\n\n  We summarise the properties of the family ‚Ñ±' below.\n\n\n  *  Œ¥(‚Ñ±') is a packing of T-cuts;\n\n  *  |‚Ñ±'|=ŒΩ(K,T);\n\n  *  Œ¥(X) is an inclusion-wise minimal cut,\n      for every X ‚àà‚Ñ±';\n\n  *  ‚àë_u ‚àà X(6-d_K(u)) ‚àà{1,3,5} for all X ‚àà‚Ñ±';\n\n  *  Subject to <ref>‚Äì<ref>, ‚Ñ±'\n      minimises ‚àë_X ‚àà‚Ñ±' |X|;\n\n  *  ‚Ñ±' is laminar.\n\n\n  We let ‚Ñ± be the subfamily of ‚Ñ±' consisting of the\n  elements X ‚àà‚Ñ±' such that\n\n    ‚àë_u ‚àà Y(6-d_K(u))<‚àë_u ‚àà X(6-d_K(u)),\n\n  for every Y ‚àà‚Ñ± such that Y ‚äÜ X.\n  For each X ‚àà‚Ñ±, let\n\n    ‚Ñ±'_X={Y ‚àà‚Ñ±' : X ‚äÜ Y, ‚àë_u ‚àà Y(6-d_K(u))=‚àë_u ‚àà X(6-d_K(u))},\n\n  and let w_X=|F'_X|.\n\n  To prove¬†<ref>, we use an argument very similar to the one we used to\n  prove¬†<ref>.\n  Clearly, for every X ‚àà‚Ñ±, ^w_X(X)=‚ãÉ_Y ‚àà‚Ñ±'_X^1(Y)\n  is a moat around X of width w_X. Let X,Y ‚àà‚Ñ±, and suppose that\n  ^w_X(X) ‚à©^w_Y(Y) ‚â†‚àÖ. Then there exists a face\n  {u,v,w}‚àà F(K) and sets X',Y' ‚àà‚Ñ±' such that X ‚äÜ X',\n  Y ‚äÜ Y', and\n\n    |Œ¥(X')‚à©{uv,uw,vw}|=|Œ¥(Y')‚à©{uv,uw,vw}| = 2.\n\n  But then Œ¥(X') ‚à©Œ¥(Y') ‚â†‚àÖ, so by¬†<ref>,\n  X'=Y'. Hence, by the construction of ‚Ñ±, X=Y. This proves¬†<ref>.\n\n  To prove¬†<ref>, it suffices to note that ‚àë_X ‚àà‚Ñ±w_X=|‚Ñ±'|=ŒΩ(K,T)\n  by¬†<ref>.\n\n  The property¬†<ref> follows immediately from¬†<ref>;\n  indeed, since Œ¥(X) is\n  an inclusion-wise minimal cut, the dual edges form a cycle, so by the\n  Jordan‚ÄìSchoenflies theorem, the subcomplex of K^* formed by the faces in\n  X is homeomorphic to a disc, so K[X] is a patch.\n\n  Since ‚Ñ±‚äÜ‚Ñ±', <ref> follows immediately\n  from¬†<ref> and ¬†<ref> follows immediately from¬†<ref>.\n\n  To prove¬†<ref>, let X be an inclusion-wise minimal element\n  of ‚Ñ±. By the definition of ‚Ñ±, X is also an inclusion-wise\n  minimal element of ‚Ñ±'. Since ‚àë_u ‚àà Xd(u) is odd, at least one\n  vertex in X has odd degree. If |X|>1, let u be a vertex of odd degree in X,\n  and let ‚Ñ±‚Äù=(‚Ñ±'‚àñ X) ‚à™{u}. Then ‚Ñ±‚Äù satisfies\n  <ref>‚Äì<ref>, but ‚àë_X ‚àà‚Ñ±‚Äù |X|<‚àë_X ‚àà‚Ñ±' |X|,\n  contradicting¬†<ref>.\n\n\nLemmas¬†<ref> and¬†<ref> can be used to prove\nthe following upper bound on the maximum size of a packing of odd cuts in\nspherical triangulations with all vertices of degree at most 6,\nwhich may be of independent iterest. By taking the planar dual, we also get\nan upper bound on ŒΩ_ for the class of 3-connected cubic plane\ngraphs with all faces of size at most 6.\n\n\n  Let K be a triangulation of the sphere with maximum degree\n  at most 6. If T is the set of odd-degree vertices of K, then\n\n    ŒΩ(K,T) ‚â§‚àö( 15‚àë_u ‚àà T(6-d(u))  K).\n\n  In particular, ŒΩ(K,T) ‚â§‚àö(12  K/5) always holds,\n  with equality if and only if all vertices have degree 5 and 6, K=60k^2\n  for some k ‚àà, and (K) ‚âÖ I_h.\n\n\n\n  Let ‚Ñ≥=‚ãÉ_X ‚àà‚Ñ±_K^w_X(X) be a packing of 1-, 3- and\n  5-moats in K of total width ‚àë_X ‚àà‚Ñ±w_X=ŒΩ(K,T), as\n  guaranteed by Lemma¬†<ref>. Let m_c be the total area of\n  c-moats of ‚ãÉ_X ‚àà‚Ñ±_K^w_X(X), where\n  c‚àà{1,3,5}. Define the incidence vectors r, s, t ‚àà‚Ñù^|T|  as\n  follows: for every u ‚àà T, let r_u, s_u, t_u be the width of the 1-moat,\n  3-moat and 5-moat surrounding u, respectively.\n\n  Define the inner product ‚ü®¬∑,¬∑‚ü© on ^|T| by\n  ‚ü® x,y ‚ü© = ‚àë_u‚àà T(6-d(u)) x_uy_u and the norm\n  ¬∑ by x=‚ü® x,x ‚ü©. With this inner product,\n  the total width of 1-, 3- and 5-moats in\n  ‚ãÉ_X ‚àà‚Ñ±_K^w_X(X) can be expressed as\n  ‚ü® r,1‚ü©, 13 ‚ü® s,1‚ü©, and\n  15 ‚ü® t,1‚ü©, respectively. Therefore,\n\n    ŒΩ(K,T)=‚àë_X ‚àà‚Ñ±w_X=‚ü® r+13s+15t,1‚ü©.\n\n\n  To prove the inequality in Theorem¬†<ref>, we compute lower bounds on\n  m_1, m_3 and m_5 in terms of the vectors r, s and t, and then use\n  the fact that the moats are disjoint, so the sum m_1+m_3+m_5 cannot exceed f,\n  the number of faces of K. Simplifying the inequality gives the desired bound.\n\n  To bound m_1, recall that by property¬†<ref> of Lemma¬†<ref>,\n  every 1-moat in ‚Ñ≥ is of the form _K^r_u(u), where u is a\n  5-vertex in K. By Lemma¬†<ref>,\n\n    _K^r_u(u) = (6-(6-d(u)))r_u^2= 5r_u^2,\n\n  and summing over all 1-moats gives the equality\n\n    m_1 = 5 ‚àë_u‚àà T(6-d(u))r_u^2 = 5r^2.\n\n\n  To bound m_3, let _K^s_u(X) be a non-empty 3-moat in ‚Ñ≥, for\n  some u‚àà T ‚à© X. By the laminarity of ‚Ñ≥, the 3-patch K[X] contains\n  the (possibly empty) 1-moats _K^r_u(u), for all 5-vertices\n  u ‚àà T ‚à© X. All the moats are pairwise disjoint, so by¬†(<ref>)\n  and the Cauchy‚ÄìSchwarz inequality,\n\n    K[X]   ‚â•‚àë_u ‚àà T ‚à© X_K^r_u(u)\n       ‚â• 5 ‚àë_u‚àà T ‚à© X(6-d(u))r_u^2\n       ‚â•5(‚àë_u‚àà T ‚à© X(6-d(u))r_u)^2/‚àë_u ‚àà T ‚à© X (6-d(u))\n       ‚â•5/3(‚àë_u‚àà T ‚à© X(6-d(u))r_u)^2.\n\n  Hence, by Lemma¬†<ref>,\n\n    _K^s_u(X)   ‚â• 3s_u^2+2s_u‚àö(3 K[X])\n       ‚â•‚àë_u‚àà T  ‚à© X(6-d(u))s_u^2+2‚àö(5)‚àë_u ‚àà T\n            ‚à© X(6-d(u))r_us_u .\n\n  Summing over all 3-moats gives the inequality\n\n    m_3 ‚â•s^2+2‚àö(5)‚ü® r,s ‚ü©.\n\n\n  To bound m_5, let _K^t_u(Y) be a non-empty 5-moat in ‚Ñ≥, for\n  some u‚àà T‚à© Y. By the laminarity of ‚Ñ≥, the 5-patch K[Y] contains at most one\n  non-empty 3-moat _K^s_u(X) of ‚Ñ≥. All the moats are pairwise disjoint,\n  so by¬†(<ref>), (<ref>) and the Cauchy‚ÄìSchwarz\n  inequality,\n\n    K[Y]   ‚â•‚àë_u‚àà T ‚à© Y_K^r_u(u)+\n                ‚àë_u‚àà T ‚à© Y_K^s_u(X)\n       ‚â• 5 ‚àë_u‚àà T ‚à© Y(6-d(u))r_u^2+‚àë_u ‚àà T ‚à© Y\n                (6-d(u))(2‚àö(5)r_us_u+s_u^2)\n       =    5 ‚àë_u‚àà T ‚à© Y(6-d(u))(r_u+1‚àö(5)\n                s_u)^2\n       ‚â•5(‚àë_u ‚àà T ‚à© Y(6-d(u))(r_u+\n                 1‚àö(5)s_u) )^2/‚àë_u ‚àà T ‚à© Y (6-d(u))\n       =    (‚àë_u ‚àà T ‚à© Y(6-d(u))(r_u+1\n                ‚àö(5)s_u) )^2.\n\n  Using Lemma¬†<ref>,\n\n    _K^t_u(Y)   ‚â• t_u^2+2t_u‚àö(K[Y])\n       ‚â•15‚àë_u ‚àà T ‚à© Y(6-d(u))t_u^2+2t_u‚àë_u ‚àà T ‚à© Y(6-d(u))(r_u+1‚àö(5)s_u)\n       =‚àë_u ‚àà T ‚à© Y(6-d(u))(15t_u^2+2r_ut_u+\n            2‚àö(5)s_ut_u),\n\n  with equality only if t_u=0, because K is a simple triangulation of the sphere,\n  and as such has no vertex of degree 1. Summing over all 5-moats gives the inequality\n\n    m_5 ‚â•15t^2+2‚ü® r,t ‚ü©+2‚àö(5)‚ü® s,t ‚ü©,\n\n  with equality only if t=0.\n\n  The moats are disjoint, so by\n  inequalitites¬†(<ref>), (<ref>) and¬†(<ref>),\n\n    K    ‚â• m_1+m_3+m_5\n       ‚â• 5r^2 + s^2 + 15t^2 + 2‚àö(5)‚ü® r,s ‚ü© +\n                     2‚ü® r,t ‚ü© + 2‚àö(5)‚ü® s,t ‚ü©\n       =    ‚àö(5)r + s +  1‚àö(5)t^2.\n\n  Hence, by the Cauchy‚ÄìSchwarz inequality and¬†(<ref>),\n\n    ‚àö(15‚àë_u ‚àà T(6-d(u))  K)   ‚â•‚àö(‚àë_u ‚àà T(6-d(u)))r +  1‚àö(5)s +  15t\n       ‚â•‚ü® r +  1‚àö(5) s +  15 t,1‚ü©\n       ‚â•‚ü® r +  13 s +  15 t,1‚ü©\n        =    ŒΩ(K,T).\n\n  This completes the proof of the first part of Theorem¬†<ref>.\n\n  To prove the inequality ŒΩ(K,T)‚â§‚àö(12  K/5), it suffices\n  to observe that ‚àë_u‚àà T(6-d(u))‚â§ 12\n  by Lemma¬†<ref>. Now suppose that\n  ŒΩ(K,T)=‚àö(12  K/5). By Lemma¬†<ref>, there\n  exists a packing ‚Ñ≥=‚ãÉ_X ‚àà‚Ñ±_K^w_X(X)\n  of 1-, 3- and 5-moats in K of total width ‚àö(12  K/5).\n  Then ‚àë_u ‚àà T(6-d(u))=12, i.e., all\n  vertices of degree less than 6 have odd degree, namely, 3 or 5.\n  Equality holds in¬†(<ref>) and in¬†(<ref>), so t=s=0.\n  Furthermore, equality holds in¬†(<ref>), so there is a natural\n  number k ‚â• 1 such that r_u=k for every u ‚àà T. Therefore, every u ‚àà T has\n  degree 5, so |T|=12. By Lemma¬†<ref> each moat\n  _K^k(u) ‚àà‚Ñ≥ has area 5k^2, so K=12¬∑5 k^2=60k^2.\n  Hence, K is the union of twelve face-disjoint 1-moats ^k(u),\n  for u ‚àà T (see Figure¬†<ref>). Each ^k(u) can be identified\n  with a face of a regular dodecahedron, which shows that (K) contains\n  a subgroup isomorphic to I_h. On the other hand, the dual graph of K is\n  a fullerene graph, and it can be shown (see e.g.¬†<cit.>) that the largest\n  possible automorphism group of a fullerene graph is isomorphic to I_h. Hence,\n  (K) ‚âÖ I_h.\n\n  Conversely, suppose K is a triangulation of the sphere with K=60k^2,\n  all vertices of degree 5 and 6, and (K) ‚âÖ I_h. Then it can be\n  shown (see¬†<cit.>) that K can be constructed by pasting\n  triangular regions of the (infinite) 6-regular triangulation of the plane\n  into the faces of a regular icosahedron (this is sometimes known in the literature\n  as the Goldberg‚ÄìCoxeter construction). The construction is uniquely\n  determined by a 2-dimensional vector (i,j) ‚àà^2, known as the\n  Goldberg‚ÄìCoxeter vector (see Figure¬†<ref>).\n  Since (K)‚âÖ I_h, we must have j=0 or j=i.\n  The area of K is given by the formula K = 20(i^2 + ij + j^2).\n  The condition K=60k^2 implies that the Goldberg‚ÄìCoxeter vector of K is\n  (k,k), which means that the distance between\n  any pair of 5-vertices in K is at least 2k. Therefore,\n  ‚ãÉ_u ‚àà T^k(u) is a packing of 1-moats of total width\n  12k=12‚àö( K/60)=‚àö(12  K/5), so ŒΩ(K,T)‚â•‚àö(12  K/5).\n"
        },
        {
            "section_number": 5,
            "title": "PROOF OF THEOREM¬†<REF>",
            "summary": "Explain the proof of Theorem <REF> by demonstrating how the relationship between the triangulation of the sphere and its refinement leads to a tight upper bound on the minimum size of a postman set, and how this relates to the properties of cubic plane graphs and their duals.",
            "target_length": 500,
            "origin_content": "Given a triangulation K of the sphere, we construct the refinement KÃÇ\nas follows. First, we subdivide each edge of K, that is, we replace it by an\ninternally disjoint path of length 2, and then we add three new edges inside every face,\nincident to the three vertices of degree 2. (For an illustration, see Figure¬†<ref>.)\nTherefore, every face of K is divided into four faces of KÃÇ.\nObserve that all the vertices in V(KÃÇ)‚àñ V(K) have degree 6 in\nKÃÇ, so if T is the set of odd-degree vertices of K, then T\nis also the set of odd-degree vertices of KÃÇ.\n\n\n\nThe following lemma was proved in¬†<cit.> using a theorem of\nSeymour¬†<cit.>.\n\n\n  If K is a triangulation of the sphere and T ‚äÜ V(K) is a subset\n  of even cardinality, then œÑ(K,T)=12 ŒΩ(KÃÇ,T).\n\n\nTheorem¬†<ref> and Lemma¬†<ref> immediately\ngive the following tight upper bound on the minimum size of a postman set in a plane\ntriangulation with maximum degree 6.\n\n\n\n  Let K be a triangulation of the sphere with f faces and maximum degree at most 6.\n  If T is the set of odd-degree vertices of G, then\n\n    œÑ(K,T) ‚â§‚àö(15 ‚àë_u ‚àà T(6-d(u))  K).\n\n  In particular,\n  œÑ(K,T) ‚â§‚àö(12  K/5) always holds, with equality if and only if\n  all vertices have degree 5 and 6, K=60k^2 for some k ‚àà, and\n  (G) ‚âÖ I_h.\n\n\n\n  Let K be a triangulation of the sphere with maximum degree at most 6, and\n  let KÃÇ be its refinement; observe that KÃÇ=4  K. By\n  Lemma¬†<ref> and Theorem¬†<ref>,\n\n    œÑ(K,T)=12 ŒΩ(KÃÇ,T)‚â§‚àö(15‚àë_u‚àà T(6-d(u))  K)‚â§‚àö(12  K/5),\n\n  as required.\n\n  If œÑ(K,T)=‚àö(12  K/5), then ŒΩ(KÃÇ,T) = ‚àö(12¬∑ 4  K/5),\n  so by the second part of Theorem¬†<ref>, all vertices in KÃÇ\n  have degree 5 and 6, and this must clearly hold in K. Furthermore,\n  4  K=60kÃÇ^2, for some kÃÇ‚àà, so K=15kÃÇ^2.\n  Since K is even, kÃÇ=2k, for some k ‚àà, so K=60k^2.\n  We also have (K)‚âÖ(KÃÇ) ‚âÖ I_h.\n\n  Conversely, suppose K is a triangulation of the sphere with K=60k^2,\n  all vertices of degree 5 and 6, and (K)‚âÖ I_h. By\n  Theorem¬†<ref> ŒΩ(K,T)=‚àö(12  K/5), so\n  œÑ(K,T)=‚àö(12  K/5).\n\n\nTheorem¬†<ref> follows from Theorem¬†<ref> by taking the planar\ndual.\n\n\n  Let G be a 3-connected cubic plane graph on n vertices with all faces of\n  size at most 6, with p pentagonal and t triangular faces.\n  By Lemma¬†<ref>, the dual graph G^* is a plane triangulation\n  with G^*=n and all vertices of degree at most 6, having exactly p vertices\n  of degree 5 and t vertices of degree 3. Let T be the set of vertices\n  of odd degree, J^* a minimum T-join of G^*, and J the set of edges of G\n  which correspond to J^*. Since G^*‚àñ J^* has no odd-degree vertices,\n  G‚àñ J=(G^*‚àñ J^*)^* has no odd faces, so is bipartite. By Theorem¬†<ref>,\n\n    |J|=|J^*| ‚â§‚àö(15‚àë_u‚àà T(6-d(u))n) = ‚àö(15(p+3t)n).\n\n  In particular, |J|‚â§‚àö(12n/5), with equality if and only if all faces\n  have size 5 and 6, n=60k^2 for some k ‚àà, and (G) ‚âÖ I_h.\n"
        },
        {
            "section_number": 6,
            "title": "CONSEQUENCES FOR MAX-CUT AND INDEPENDENCE NUMBER",
            "summary": "Discuss the implications of improved bounds on edge-cuts and independence numbers for 3-connected cubic plane graphs with faces of size at most 6, highlighting conditions for achieving equality and the role of odd cycle transversals and T-joins in these optimizations.",
            "target_length": 500,
            "origin_content": "A classic problem in combinatorial optimisation, known as max-cut,\nasks for the maximum size of an edge-cut in a given graph. This problem is\nknown to be NP-hard, even when restricted to triangle-free cubic graphs¬†<cit.>.\nHowever, for the class of planar graphs, the problem\ncan be solved in polynomial time using standard tools from combinatorial\noptimisation (namely T-joins), as observed by Hadlock¬†<cit.>.\nCui and Wang¬†<cit.> proved that every planar, cubic graph on\nn vertices has a cut of size at least 39n/32-9/16, improving an earlier\nbound of Thomassen¬†<cit.>. However, when the face size is bounded by\n6, we get the following improved bound.\n\n\n\n  If G is a 3-connected cubic plane graph on n vertices with all faces of size at\n  most 6, with p pentagonal and t triangular faces, then G has a\n  cut of size at least\n\n    3n/2-‚àö((p+3t)n/5).\n\n  In particular, G has a cut of size at least 3n/2-‚àö(12n/5), with\n  equality if and only if all faces have size 5 and 6, n=60k^2 for some\n  k ‚àà, and (G) ‚âÖ I_h.\n\n\n\n  Let G be a 3-connected cubic plane graph on n vertices with all faces\n  of size at most 6. Let J ‚äÜ E(G) be an odd cycle transversal, and\n  let X be a colour class of G‚àñ J. Then\n  |Œ¥_G(X)| = 3n/2-|J|. By Theorem¬†<ref>, we can always find J\n  such that |J|‚â§‚àö(12n/5), with equality if and only if all faces have\n  size 5 and 6, n=60k^2 for some k ‚àà, and (G) ‚âÖ I_h.\n\n\nA set of vertices in a graph is independent if there is no edge between\nany of its vertices, and the maximum size of an independent set in G is the\nindependence number Œ±(G). Heckman and Thomas¬†<cit.> showed\nthat every triangle-free, cubic, planar graph has an independent set of size at\nleast 3n/8, and this bound is tight. Again, forbidding faces of size greater\nthan 6 gives a much better bound.\n\n\n\n  If G is a 3-connected cubic plane graph on n vertices with all faces of size at\n  most 6, with p pentagonal and t triangular faces, then\n\n    Œ±(G) ‚â• n/2-‚àö((p+3t)n/20).\n\n  In particular, Œ±(G) ‚â• n/2-‚àö(3n/5), with equality\n  if and only if all faces have size 5 and 6, n=60k^2 for some\n  k ‚àà, and (G) ‚âÖ I_h.\n\n\n\n  Every graph G contains an odd cycle vertex transversal U such that\n  |U| ‚â§œÑ_(G), so\n  Œ±(G) ‚â•Œ±(G‚àñ U) ‚â• n/2-œÑ_(G)/2. Therefore, by\n  Theorem¬†<ref>, Œ±(G) ‚â• n/2-‚àö(3n/5), for every 3-connected\n  cubic graph G with all faces of size at most 6. When J^* is\n  a minimum T-join of G^*, every face of G^* is incident to at most one edge\n  of J^*. This means that the set J ‚äÇ E(G) corresponding to J^* is a\n  matching of G. Therefore, by Theorem¬†<ref>, equality holds if and only\n  if all faces have size 5 and 6, n=60k^2 for some k ‚àà, and\n  (G) ‚âÖ I_h.\n"
        },
        {
            "section_number": 7,
            "title": "CONCLUDING REMARKS",
            "summary": "Discuss the implications and limitations of the results on packing and covering odd cycles in cubic plane graphs with small faces, highlighting the conditions under which these results hold and any potential for improvement or generalization.",
            "target_length": 300,
            "origin_content": "Clearly, a necessary condition for œÑ_=O(‚àö(n)) is that\nŒΩ_=O(‚àö(n)). In the case of planar graphs, the theorem of\nKr√°l' and Voss¬†<cit.> mentioned\nin the introduction guarantees that it is also a sufficient condition.\nIt can be shown that ŒΩ_=O(‚àö(n)) is also a\nnecessary and sufficient condition for having a max-cut of size at least\n3n/2-O(‚àö(n)), and for having an independent set of size at least n/2-O(‚àö(n)).\n\nIt is not hard to construct an infinite\nfamily of 3-connected cubic plane graphs with all faces of size at most 7\nsuch that œÑ_‚â•Œµ n, for a constant Œµ > 0.\nThis shows that the condition on the size of faces in Theorem¬†<ref> and\nCorollaries¬†<ref> and¬†<ref> cannot be relaxed.\n\nTo construct such a family, consider the graphs C and R in\nFigure¬†<ref>. Note that C is embedded in a disc, and R is embedded\nin a cylinder. There are ten vertices on the boundary of C and also on each boundary\nof R, with the degree alternating between 2 and 3. We can paste k copies of\nR along their boundaries, and then paste a copy of C on each boundary of the\nresulting cylinder. Assuming k>0, this gives a 3-connected cubic plane graph G on\nn=15+40k vertices with all faces of size 5 and 7, such that\nŒΩ_(G) ‚â• 4+5k>18n.\n\n\n\nFinally, we remark that bounding œÑ_ is much simpler if the graph contains no\npentagonal faces. In this case, the bound in Theorem¬†<ref> can be improved to\nœÑ_(G) ‚â§‚àö(tn/3), where t is the number of triangular\nfaces. In particular, œÑ_(G) ‚â§‚àö(4n/3), with equality if and only if\nall faces have size 3 and 6, n=12k^2 for some k ‚àà, and\n(G) ‚âÖ T_d. Corollaries¬†<ref> and¬†<ref>\ncan be strengthened in the same way.\n\nplain\n"
        }
    ],
    [
        {
            "section_number": 1,
            "title": "INTRODUCTION",
            "summary": "Discuss the theoretical motivation behind using synchrotron intensity gradients as a tool for studying magnetic fields, grounded in the modern theory of magnetohydrodynamic (MHD) turbulence.",
            "target_length": 400,
            "origin_content": "This paper provides a description of a new technique for studying magnetic fields using gradients of synchrotron intensity. Gradients of synchrotron polarization have been successfully used before (see ). However, in this Letter we explore theoretically and numerically a more simple measure, namely, synchrotron intensity gradients (SIGs) and evaluate its utility for observational study of magnetic fields and accounting for the foreground contamination induced by the interstellar media within the CMB polarization studies.\n\nGalactic and Extragalactic synchrotron emission arises from relativistic electrons moving in astrophysical magnetic field (see ). In terms of CMB and high redshift HI studies, the most important is galactic synchrotron emission. However, diffuse synchrotron emission is also a major emission arising from the interstellar medium (ISM), the intracluster medium (ICM), as well as in the lobes of radio galaxies (e.g.  ). In fact, synchrotron emission provides the largest range of scales for studying magnetic fields.\n\nAstrophysical magnetic fields are turbulent as observations testify that turbulence is ubiquitous in astrophysics\n<cit.>. As relativistic electrons are present in most cases, the turbulence results in synchrotron fluctuations, which may provide detailed information about magnetic fields at different scales, but, at the same time, interfere with the measurements of CMB and high redshift HI. The latter has recently become a topic of intensive discussion (see ).\n\nThe statistics of synchrotron intensity has been studied recently in  (, hereafter LP12), where it was shown how fluctuations of synchrotron intensity can be related to the fluctuations of magnetic field for an arbitrary index of cosmic rays spectrum. There it was shown that the turbulence imprints its anisotropy on synchrotron intensity and this provides a way of determining the direction of the mean magnetic field using synchrotron intensities only. The current paper explores whether, on the basis of our present-day understanding of the nature of MHD turbulence, synchrotron intensities can provide more detailed information about magnetic fields.\n\nIn what follows <ref> we discuss the theoretical motivation of this work routed in the modern theory of the  of MHD turbulence,\nthe properties of synchrotron intensity gradients (SIGs), their calculation as well as the influence of noise and sonic Mach number are discussed in <ref>. We illustrate our method on PLANCK synchrotron data at <ref> The comparison of the SIGs technique with the technique based on the anisotropy of the correlation functions of intensity is presented in <ref>, the synergy with other techniques of magnetic field studies is outlined in <ref>. We present our summary in <ref>.\n"
        },
        {
            "section_number": 2,
            "title": "THEORETICAL CONSIDERATIONS",
            "summary": "Discuss the theoretical framework and key concepts of MHD turbulence, highlighting the role of synchrotron intensity gradients as tracers of magnetic fields, and address the implications of different turbulence modes on magnetic field alignment and gradient measurement.",
            "target_length": 3000,
            "origin_content": "¬ß.¬ß MHD turbulence and magnetic field gradients\n\n\nDealing with synchrotron emitting media, we deal with the non-relativistic thermal magnetized plasma and relativistic electrons. The turbulence in magnetized relativistic and non-relativistic fluids are different (see ). However, following the accepted approach, we consider turbulence in magnetized fluid separately from the fluid of cosmic rays. In other words, we consider that relativistic electrons just illuminate the structure of magnetic field that is created by non-relativistic MHD turbulence. This approach has its limitations (see ) but for our further discussion this is not critically important.\n\n\nWhile the original studies of Alfvenic turbulence done by <cit.> and <cit.> were based a hypothetical model of isotropic MHD turbulence, the\nlater studies (see ) uncovered the anisotropic nature of the MHD cascade.The modern theory of MHD turbulence arises from the prophetic work by , henceforth GS95).  Further theoretical and numerical studies (, henceforth LV99, , see  for a a review) extended the theory and augmented it with new concepts. Our theoretical motivation for the present work is based on the modern understanding of the nature of MHD turbulence that we briefly summarize below.\n\nThe GS95 theory treats the Alfvenic incompressible turbulence. The numerical simulations in <cit.> testify that for non-relativistic MHD turbulence the energy exchange between different types of fundamental modes is the effect that can be frequently neglected.[This is in contrast with the relativistic MHD turbulence where the coupling between fast and Alfvenic fundamental modes were shown to be significant <cit.>.] Therefore, in non-relativistic compressible astrophysical media one can consider three distinct cascades, namely, the cascade of Alfven, slow and fast modes.[We use the word \"modes\" rather than \"waves\", as the properties of the magnetic perturbations can be very different from those of waves. For instance, Alfven modes in GS95 turbulence are not oscillatory and after one period undergo cascading.] Therefore the GS95 treatment is applicable to describing Alfvenic modes also in compressible fluids.\n\nAlfven modes initially evolve by increasing the perpendicular wavenumber in the subAlfvenic regime, i.e. for the injection velocity v_L being less than the Alfven velocity V_A,  while the parallel wavenumber stays the same. This is the regime of weak turbulence with the spectrum E(k)‚àº k^-2 (see LV99, ). This is not yet the regime of GS95 turbulence, but, nevertheless, the increase of the perpendicular wave number means the modes get more and more perpendicular to the magnetic field. In Alfvenic turbulence, the magnetic field and velocity are symmetric and therefore the aforementioned situation means that both the gradients of magnetic field and velocity is getting aligned perpendicular to the direction of the magnetic field.\n\nWeak Alfvenic turbulence can be viewed as the interaction of wave packets with a fraction of the energy of cascading as a result of such an interaction. As the perpendicular wavenumber increases, this fraction gets larger and eventually becomes ‚àº 1 (see ). This is the maximal fraction of energy that can be transferred during the wavepacket interaction. However, the equations dictate the necessity of further increase of perpendicular wavenumber as the result of the interaction of oppositely moving wavepackets. This can only be accomplished through the simultaneous increase of the parallel wavenumber. This happens at the transition scale l_trans‚âà L M_A^2, where L is the turbulence injection scale and M_A=v_L/V_A is the Alfven Mach number (see LV99, ). This is the stage of the transfer of the strong or GS95 regime of turbulence. At this stage, the so-called critical balance condition should be satisfied, which states that the time of the interaction of the oppositely moving wavepackets\nl_/V_A, where l_ is the parallel to magnetic field scale of the wavepacket is equal to the perpendicular shearing time of the wavepacket l_/v_l, where l_ is the perpendicular scale of the wavepacket and v_l is the turbulent velocity associated with this scale. For the subAlfvenic turbulence this is how the cascade proceeds in the strong regime with the wavepackets getting more and more elongated according to (see LV99):\n\n    l_‚âà L (l_/L)^2/3 M_A^-4/3,\n\nwhich testifies that for l_‚â™ L the parallel scale of the wavepackets gets much larger than the perpendicular scale. This means that\nthe wavepackets/eddies get more and more elongated as the perpendicular scale l_ decreases.  As a result, both the velocity and magnetic field gradients get more and more aligned perpendicular to the magnetic field direction as l_ decreases. In fact, the increase of the disparity of the parallel and perpendicular scales continues until the energy reaches the dissipation scale.\n\nThe magnetic field direction is changing in the turbulent flow. Therefore the important question that arises is what the direction of the magnetic field should be used in the arguments above. In other words, it is important to understand how the parallel and perpendicular directions to measure  and  are defined.\nMost of the earlier MHD turbulence work assumed the perturbative approach and thus the mean field direction was used. This was also an implicit assumption in GS95 study. However, in the studies that followed the groundbreaking GS95 paper (namely, LV99, ) it was shown that it is not correct to measure the directions in respect to the mean magnetic field. Instead, one should use the local magnetic field that surrounds the wavepacket  [l_, l_].\n\nThe importance of using of local system of reference is the most evident if arguments related to the fast turbulent reconnection are employed (LV99). Indeed, there it was shown in LV99 that the magnetic reconnection happens within a turnover time of an eddy and therefore the motions of fluid perpendicular to the magnetic field lines are similar to hydrodynamic eddies. As magnetic field lines reconnect fast, the mixing motion of perpendicular to the local direction of magnetic field does not create magnetic tension. As a result, the formation of such eddies provides the path of least resistance compared to any other motions involving magnetic field line bending. Naturally, the turbulent energy is channeled along this path of the least resistance. The hydrodynamic-type cascade of energy associated of these eddies is ‚àº v_l^2/t_cas=const, with the cascading time given by the eddy turnover time l_/v_l. From what we said above, it is evident that l_ has to be measured perpendicular to the magnetic field direction at the location of the eddy, rather than to the direction of the mean magnetic field. Incidentally, this hydrodynamic-type cascading that we describe provides the Kolmogorov scaling for the perpendicular turbulent motions, i.e. from v_‚àº l_^1/3, that is the GS95 prediction. As the eddies rotate around the local magnetic field direction they flop sending the Alfven waves along the magnetic field. The corresponding Alfven wave period is equal to the eddy turnover time, i.e. l_/V_A‚âà l_/v_l. The latter coincides with the \"critical balance\" condition in GS95. Combining this with the Kolmogorov scaling of the perpendicular motions, one can get the l_≈Ç‚àº l_^2/3 (see Eq. (<ref>). We would like to stress that this derivation dictates that l_ is aligned with the magnetic field of the eddy and l_ is the size of the eddy perpendicular to the local magnetic field. The corresponding numerical studies () show that the aforementioned relations between l_ and l_ are correct only in the local system of reference given by local magnetic field that the eddy interacts with.[The GS95 relation between l_ and l_ isnnot valid in the system of reference related to the mean magnetic field. Observations in most cases sample turbulence along the line of sight over distances much larger than the scale of the sampled eddy. In this situation the measurements take place in respect to the mean magnetic field (see ) and this prevents the observational testing the GS95 anisotropy.]\n\nThe anisotropy of turbulence given by the aspect ratio of the eddies (see Eq. (<ref>)) is increasing with the decrease of the scale. Therefore the smaller the eddy the better it traces the local direction of the magnetic field. At the same time, one can estimate the velocity gradients that scale as v_l/l_‚àº l_^-2/3. The latter relation means that the largest gradients correspond to the smallest eddies. Thus 3D gradients in Alfvenic turbulence should be dominated by the gradients of the smallest eddies and therefore the measured gradients should be perpendicular to the local direction of the magnetic field as it is traced by the smallest resolved eddies. Magnetic field and velocity enter in a symmetric way in Alfvenic turbulence and therefore the gradients of turbulent magnetic field should have the same property as the gradients of velocity. As gradients are linear operation then if we have a quantity that is an integral of magnetic fluctuations along the line of sight, as this is the case of synchrotron fluctuations, the gradient and integral operation can be interchanged and thus the observed 2D measure can be presented as an integral of magnetic field gradients. This shows that the observed quantities, which could be the integrated along the line of sight components of fluctuating velocities as in our papers on tracing magnetic field with velocity gradients <cit.>. In our present paper that suggests the way of magnetic field tracing with synchrotron, the gradients are dominated by the smallest eddies, that are most aligned with magnetic field.\n\nNaturally, Eq. (<ref>) provides only the most probable relation between the parallel and perpendicular scales. The distribution function relating l_ and l_ was obtained in <cit.> on the basis of numerical simulations. Its analysis, however, shows that the uncertainty in the gradient direction is of the order of l_/l_‚àº (l_/L)^1/3 indicating that the smaller the resolved eddies, the better the gradients trace magnetic fields. In other words, the most probable directions of the Alfven wavevectors are limited by the GS95 cone given by Eq. (<ref>), while the probability of the vectors to be beyond this cone is exponentially suppressed.[<cit.> argued that the actual distribution can be best represented by the Castaing function <cit.> which is smooth near zero but looks like an exponential over a broad range.]\n\n\nWe note that all the arguments above are relevant to subAlfvenic turbulence. They are suggestive that the gradients of the velocities and magnetic fields are aligned with the local magnetic field and therefore sample the local direction of the magnetic field flux at the largest of the two scales, one is being the turbulence dissipation scale, the other is the telescope resolution scale.\nThis point is very important for the technique that we are going to propose. In this paper we are claiming that by measuring the magnetic field gradients one can trace the turbulent magnetic-field in the volume under study.\n\n\n\n\n\n\n\nThe discussion above was focused on the Alfvenic turbulence. In incompressible conducting fluid in 3D, apart of Alfven modes, the pseudo-Alfven modes exist (see GS95). The latter is the limiting case of slow modes in the incompressible limit. Pseudo-Alfven modes and, in general, the slow modes are slaved by Alfvenic modes, that shear them both in the case of magnetically dominated (low-Œ≤) and gas-pressure dominated (high-Œ≤)\nplasmas (GS95, ). Thus we expect that the slow modes will also show the properties of the magnetic gradients similar to the Alfven waves.\n\nThe third fundamental MHD turbulent mode is the fast mode. The fast modes are different from both Alfven and slow modes. The fast modes create an accustic-type cascade <cit.> which marginally cares about magnetic-field direction. In terms of our attempts to use gradients to trace magnetic fields, fast modes are distort the alignment. Therefore, it is important that numerical simulations indicate that the fast modes\nare subdominant even for supersonic driving <cit.>. Therefore having a natural admixture of Alfven and slow modes, which is augmented by fast modes and shocks, we expect to see alignment of magnetic gradient perpendicular to the local magnetic-field direction. This is the theoretical conclusion that motivates our study below.\n\nWe may add that for the weakly compressible flows the density associated with slow waves will mimic the GS95 scalings <cit.>. However, for supersonic flows the production of shocks significantly disturbs the statistics of density. As a result, for subsonic flows density gradients are also expected to be aligned perpendicular to the magnetic field which explains the results in empirical results in <cit.> as well\nas our numerical experiments with density gradients in  (, henceafter GL17) and  (, henceforth YL17). In terms of magnetic field tracing the density gradients are expected to be inferior to velocity and magnetic field gradients,\nwhich is clearly shown in <cit.> where the GALFA HI intensity gradients are compared to both and velocity centroid gradients and magnetic fields as revealed by Planck data. At the same time, the density gradients can also be very important. For instance, the misalignment of density gradients and magnetic field directions can be informative in terms of shocked gas and supersonic flows.\n\nA note about observational availability of magnetic field/velocity gradients is due. The observations probe the properties of diffuse media along the line of sight, rather than at a point in 3D space. Therefore one can wonder about the contributions from different scales that affect observationally available gradients. The magnetic gradients are can be estimated as the ratio |b(r_1)-b(r_2)|/|r_1-r_2|, where b(r) is the magnetic field at the point r. The structure function d(r)=‚ü® (b(r_1)-b(r_2))^2‚ü© can give us some indirect insight into the process of the summation along the line of sight. As we discuss in the next section (see Eq. (<ref>)) , the observed intensities are proportional to ‚à´_0^D dz H_^2, where the integration is performed along the line of sight through the diffuse volume of thickness D. Structure functions of synchrotron intensities for the general case of anisotropic turbulence were studied in detail in <cit.>. This function, i.e. S(l)=‚ü® (I(e_1)-I(e_2))^2 ‚ü©, where l is the distance between the lines of sight, is roughly proportional to\n\n    ‚à´ [d((l^2+z^2)^1/2)-d(z)] dz,\n\nwhere the integration is performed along the line of sight. For the Kolmogorov-type turbulence it is possible to show that the major contribution to the integral is coming from the scales close to l.\n\nMagnetic and velocity perturbations are symmetric within Alfvenic turbulence. However, the differences are obvious in compressible flows. For instance, shocks distort the velocity structure creating velocity gradients parallel to the local direction of magnetic field. This effect is not present for magnetic field, which gradients are more robust to compressible turbulence. Similarly, the velocity gradients for the flows affected by gravitational collapse tend to be parallel to the ambient magnetic field <cit.> This is not expected for magnetic field gradients making them a more robust measure of the line of sight integrated magnetic field.\n\n\n\n ¬ß.¬ß Synchrotron gradient properties\n\n\nSynchrotron emission arises from relativistic electrons spiraling about magnetic fields (see   references therein). A quantitative study of the synchrotron emission (see ) revealed that the emission is non-linear in the magnetic field H with the origin of nonlinearity arising from relativistic effects. For the power law distribution of electrons N(E) dE‚àº E^Œ± dE, the synchrotron emissivity is\n\n    I_synch(x, y) ‚àù‚à´ dz H_^Œ≥ (x, y, z),\n\nwhere H_=‚àö(H_x^2+H_y^2) corresponds to the magnetic field component perpendicular to the line of sight, the latter given by the z-axis. The fractional power of the index Œ≥= (Œ± +1)/2\nwas a impediment for quantatitive synchrotron statistical studies. However, the problem of the magnetic field dependence on the fractional power was dealt with in <cit.>, where it was shown that the correlation functions and spectra of H_^Œ≥ can be expressed as a product of a known function of Œ≥ times the statistics of H_^2, i.e. the synchrotron intensity obtained for Œ±=3. Although we do not use the correlation function approach explicitly, our approach is based on the statistical properties turbulence and we expect that similar to the case considered in <cit.> the gradients calculated with Œ±=3 will correctly represent the results for other Œ≥. Thus the fractional power of magnetic field in Eq. (<ref>) will not be considered as an issue within the present study aimed at determining magnetic field gradients.\n\nIn Eq. (<ref>) we disregard the dependence on the relativistic cosmic electron density. This is justified as we are interested by the gradients at the small scales at which the distribution of relativistic electrons is smooth in most parts of the diffuse media. In other words, on the basis of what we know about cosmic ray propagation (see e.g. Lazarian & Yan 2014 and ref. therein) we expect that the gradients arising from the inhomogeneities of the relativistic electrons distribution to be subdominant to the gradients arising from turbulent magnetic fields.\n\nAlfven modes do not change the strength of magnetic field. Therefore if the line of sight is directed along the z-axis, while the\nthe Alfven mode is polarized in the x-y plane, the magnetic field fluctuations are perpendicular to the line of sight and therefore the observed synchrotron intensity does not change with the amplitude of the Alfven mode. However, if all 3 components of the Alfven mode are present, then the fluctuations in the z-direction result in the decrease of the observed synchrotron intensities (see LP12). Therefore while the magnetic field gradients are still in the direction perpendicular to the local magnetic field, the synchrotron intensity fluctuations are parallel to the local magnetic field direction. The statistical similarity of the Alfven and slow modes (see ) is suggestive that the slow modes behave the same way. At the same time, fast modes are expected to play a disruptive role for the magnetic field tracing. For instance, fast modes in magnetically dominated plasma correspond to the compressions of magnetic field. These compressions happen perpendicular to magnetic field and therefore the fluctuations of synchrotron intensity induced by fast modes are expected to be perpendicular the magnetic field directions. For the pressure dominated media, the so-called high Œ≤ media, where Œ≤ is the ratio of the gas to magnetic pressure, the fast modes are essentially sound waves and they only marginally compress magnetic field (see GS95, Cho & Lazarian 2003). This mitigates the effect of fast modes for the gradient technique in that we introduce in this paper.\n"
        },
        {
            "section_number": 3,
            "title": "NUMERICAL DATA",
            "summary": "Explain how numerical simulations from different MHD codes are used to test the synchrotron intensity gradient technique for tracing magnetic fields across various physical settings.",
            "target_length": 200,
            "origin_content": "We test our theory using numerical simulations obtained from three different codes, in particular, from a 3D MHD compressible code described in ), an imcompressible code described in  <cit.>, as well as the data sets used in YL17 and its subsequent studies from another 3D MHD gravity-supported compressible code family ZEUS-MP. The use of numerical results obtained with different codes is advantageous and this allows us to test better the gradient technique for various physical settings. For instance, the 3D MHD compressible code from <cit.> is a third-order accurate hybrid, that employs essentially non-oscillatory (ENO) scheme on solving the ideal isothermal MHD equations in a periodic box. For our case, we choose M_s=0.5,3.0,10.0 and M_A=0.1 for our purpose. The code from <cit.>, on the other hand, solves the periodic incompressible MHD equations using the pseudo-special code. The resultant data corresponds to the extreme case plasma Œ≤ = 2M_A^2/M_s^2 = ‚àû. In our case, we used an incompressible cube with M_A=0.80. The respective parameters are listed in Table <ref>. We then follow <cit.> to produce both the maps of synchrotron polarization and synchrotron intensity.\n"
        },
        {
            "section_number": 4,
            "title": "PROPERTIES OF SYNCHROTRON INTENSITY GRADIENTS (SIGS)",
            "summary": "Discuss the impact of varying block sizes on the alignment measure of Synchrotron Intensity Gradients (SIGs) with respect to the projected magnetic field, highlighting the optimal block size for analysis and the influence of numerical resolution on the accuracy of SIGs in tracing magnetic fields.",
            "target_length": 1800,
            "origin_content": "¬ß.¬ß Calculation of SIGs\n\n\nTo calculate Synchrotron Intensity Gradients (SIGs), we use the procedure for gradient calculation that we introduced in YL17. The procedure consists of three steps. We first pre-process our synchrotron intensity maps with an appropriate noise-removal Gaussian filter. We then interpolate the map to ten times its original level, and determine the gradient field by computing the maximum gradient direction in the interpolated synchrotron intensity maps. By probing the peak in gradient orientation distributions in the sub-blocks of the gradient map, we gain an estimate of the sub-block averaged gradient vector as in YL17. That allows us to compare our magnetic field predictions to those revealed by the generally accepted technique of tracing polarization. As discussed in YL17, the sub-block averaging approach provided a way of estimating how good the vector is being predicted  in a block: The gradient angle distribution peaks tells the predicted value, while the shape of the distribution tells how good the prediction is. The deviation from the Gaussian function provides an error estimate for us to judge whether our method is accurate within a block.\n\n\n\n ¬ß.¬ß SIGs from Alfven, Slow and Fast modes\n\n\n\n\nTo illustrate the applicability of our theoretical considerations related to synchrotron intensity gradients by providing the comparison of the SIG, we perform the mode decomposition that similar to that in <cit.>.  The corresponding equations determining the basis for the decomposition into modes are:\n\n\n    Œ∂ÃÇ_f    ‚àù (1+Œ≤+‚àö(D)) (k_‚ä•kÃÇ_‚ä•) +(-1+Œ≤+‚àö(D)) k_||kÃÇ_||\n    Œ∂ÃÇ_s    ‚àù (1+Œ≤-‚àö(D)) (k_‚ä•kÃÇ_‚ä•) +\n    (-1+Œ≤-‚àö(D)) k_||kÃÇ_||\n    Œ∂ÃÇ_f    ‚àù -kÃÇ_‚ä•√ókÃÇ_||\n\nwhere D=(1+Œ≤/2)^2-2Œ≤cosŒ∏, Œ≤=PÃÖ_g/PÃÖ_B=2M_A/M_s, and cosŒ∏= kÃÇ_||¬∑BÃÇ.\nWe would only use the LOS component of the decomposed velocities for magnetic field calculations.That is to say, the three velocity modes can then be acquired by\n\n    b_(f,s,a),z= [‚Ñ±^-1(‚Ñ±(b)¬∑Œ∂ÃÇ_f,s,a)](Œ∂ÃÇ_f,s,a¬∑Œ∂ÃÇ_LOS)\n\nwhere ‚Ñ± is the Fourier transform operator.\n\n\nFigure <ref> exhibits synthetic observations produced with the separated MHD modes from one of the cube in the ZEUS family simulation. It shows that, as we expected, that the SIGs are aligned parallel to magnetic field for the case of Alfven and slow modes. At the same time, also as expected, for the case of magnetically dominated media, the SIGs are perpendicular to the plane-of-sky projected component of the magnetic field. In our simulations the ratio of the Alfven, slow and fast modes is 1:0.7:0.3. Therefore, indeed, the effect of the fast modes is subdominant and we expect that for the actual simulations without any decomposition the SIGs will trace magnetic field. This is what we test below.\n\n\n\n ¬ß.¬ß SIGs: Effect of Block size\n\n\nFigure <ref> demonstrates that out approach can deliver SIGs in a robust way with the magnetic-field directions obtained with SIGs providing an adequate representation of the projected magnetic field. To demonstrate the latter point in Figure <ref> we also show the magnetic field directions as traced by the synchrotron polarization in the synthetic observations.\n\n\n\nTo quantify how well the SIGs are tracing the synchrotron polarization that represents the projected magnetic field we introduce the alignment measure:\n\n    AM=2‚ü®cos^2Œ∏-1 ‚ü©,\n\nwhere Œ∏ is the angle between the SIG direction and magnetic field direction derived from Planck synchrotron polarization measurements, which AM ‚àà [-1,1].  When AM=1, that indicates a perfect alignment between SIGs to magnetic field. When it becomes zero, there are no relation between SIGs and magnetic field. When AM=-1, SIGs tend to be perpendicular to magnetic field.\n\nThe alignment between the SIGs and the magnetic field increases with the block size, but we observe a relatively small increase starting with a particular block size. This effect is demonstrated by the the left-hand-side  panel of Figure <ref> that shows that starting with the block size ‚àº 64 pixels the increase of the AM with the block size get very slow . Observationally this size provides the optimal block size for the analysis that maximizes the informational output of the SIG technique. Note, that the rapid decrease of the alignment measure as the block size decreases is strongly affected by the numerical resolution. Our analysis of the spectral slope of the turbulence on the right of Figure <ref> indicates that starting with scales k ‚àº 40, which is about r = 512/40 = 12.8 pixels,  the structures that we see are dominated by the numerical effects. For the part of the turbulent cascade that is dominated by numerical effects we do not expect to observe the GS95 or weak turbulence scalings of the turbulent magnetic field. Therefore it is not surprising that the SIG technique fails. In fact, this is in a good agreement with the fact that for block size less and ‚àº 16 we do not see good alignment, as shown in the left of Figure <ref>. At the same time, this is suggestive that for the actual low-noise astronomical observations the size of the optimal block may be smaller than 64 pixels that we find in our numerical simulations. Indeed, unlike numerical simulations, the astrophysical turbulence exhibits an extensive inertial range with the dissipation scale too small to be resolved by observations (see Chepurnov & Lazarian 2009).\n\n\n\n\n\n\n ¬ß.¬ß SiGs: effect of the sonic and Alfven Mach numbersr\n\n\n\n\nFor most of the environments of the spiral galaxies the areas dominating the synchrotron emission may correspond to the hot gas with low sonic Mach numbers M_s. However,  it is interesting to explore to what extend the effects of compressibility can affect the SIG technique. Therefore test how the SIGs trace magnetic field in systems with different M_s.The upper panels of Figure <ref> show the relative alignment of polarization and SIG. We observe the alignment  decreases with the increase of M_s which is also supported by the lower panels of Figure <ref> where the distribution of the SIGs about the magnetic field direction is shown. We note that there exist different ways of measuring the turbulence sonic Mach number and the studies like those illustrated in Figure <ref> allow to evaluate the accuracy of magnetic field tracing using the SIGs.\n\n\n\n\nWe also test the effect of Alfvenic Mach number to the alignment of SIGs on magnetic field in Figure <ref>. Even with high Alfvenic Mach number (M_A=3.2) our method is still very good on tracing magnetic field, with AM‚àº0.71. Not to mention, the sub-Alfven case has extremely good alignment. Notice that the alignment of SIGs in incompressible cases are significantly higher than that of the compressible cases. The possible reasons for this are e.g. creation of misaligned fast modes (See Figure <ref>) or shocks formed due to compression of fluids.\n\n\n\n ¬ß.¬ß SIGs: effects of Gaussian noise\n\n\n\n\nReal observational data is affected by noise. To gauge the effect, we test to what extend the alignment persists in the presence of noise. We calculate the SIGs by adding white noise to our synthetic maps,\nThe noise is included in the data in the following way. We generate white noise such that the noise amplitude is Gaussian with mean value zero. The noise level is defined as the standard deviation of the noise distribution. The resultant noise is added to the original map. The noise level is selected to be the multiple of 0.1 of the mean synchrotron intensity, extended to a maximum equals to the mean synchrotron intensity.\n\nWe treat the synthetic data as it if it were the real observational data. For this purpose, we analyze our noisy data using pre-processing Gaussian filters <cit.>, which is a procedure frequently used as a noise reduction tool in observations. The smoothing effect from the Gaussian filter enables us to compute per-pixel gradient information more accurately. The strength of the filter is controlled by the width œÉ, which characterizes how many pixels are averaged to give the information of one pixel in the filtered map. A larger œÉ will suppress the noise and produce a smoother map at the expense of losing the structure of magnetic field at small scales. To see the effect of the filter on the alignment, we perform tests with several œÉ with the maps having different noise levels, and measure the AM of the resulting maps.\n\nThe alignment measures for various noise levels and several Gaussian filters are shown in Figure <ref>. Without the Gaussian filter pre-process, the alignment is strongly reduced, in agreement with our expectations. However, by applying Gaussian filters we can significantly improve the alignment. While for small œÉ the alignment decreases rapidly with the increase of the noise, a filter with larger width improves the alignment even in a strong-noise environment. This experiment demonstrates that SIGs present a robust tool that can trace magnetic fields using observational data in the presence of noise.\n\n\n\n ¬ß.¬ß SIGs: effect of missing spatial frequencies\n\n\nTo increase the resolution of available data interferometers can be used. In fact, the detailed maps of galactic synchrotron radiation as well as synchrotron emission of nearby galaxies can be obtained with interferometers. Interferometers measure the spatial Fourier components of the image and changing the baseline of the interferometer one gets different spatial frequencies. For interferometric observations, the single dish measurements deliver low spatial frequencies. The single dish observations frequencies are not always available. Then it is important to understand how this can affect the accuracy of our SIG technique.\n\nWe note that the synchrotron polarization gradients were used in <cit.> and one of the motivations for their use was the possibility of using gradients with the interferometric data obtained without single dish observations. Below we test how the accuracy of the SIGs in tracing magnetic fields depends on the missing spacial frequencies.\n\nIn Figure <ref> we show the alignment measure given by Eq. (<ref>) using the same data as in Figure <ref> but gradually removing spatial frequencies starting with the lowest spatial frequencies from the inertial range of our data. We observe a gradual decrease of the AM. We show that by increasing the block size increases we can mitigate the effect of the absence of the lower spacial frequencies in our synthetic data.\n\n\n\n\n\n ¬ß.¬ß SIGs:effect of the amplitudes of the gradients\n\n\nIn the present paper, similar to our earlier papers dealing with gradients (GL17, YL17, LY17), we have used the gradients to trace the magnetic field and did not account for the gradient amplitudes.\nThe gradient amplitudereflects how spacial rate of the change. For example, in shock-dominated regions, we expect to see a sharp change on the magnitude across the shock boundary. On the other hand, in self-gravitated regions the gradient amplitude should increase significantly due to rapid infalling gas motions. Such events are not related to MHD turbulence and therefore one may expect that the magnetic gradients from such events are not being aligned perpendicular to the local magnetic field. At the same time, our current numerical study is limited to diffuse media, for which such a sharp changes of gradient magnitude are not common. Figure <ref> shows how the AM changes with the gradient amplitude. With the parameters we use, we do not see a clear tendency.  The corresponding study will be done elsewhere.\n"
        },
        {
            "section_number": 5,
            "title": "COMPARISON WITH THE MAGNETIC FIELD TRACING IN LP12",
            "summary": "Discuss the comparative effectiveness of synchrotron intensity gradients (SIGs) and correlation function anisotropies (CFAs) in tracing magnetic fields, highlighting their advantages, limitations, and complementary roles in magnetic field analysis.",
            "target_length": 400,
            "origin_content": "SIGs are not the only way to trace the magnetic field with synchrotron intensity maps. For instance, anisotropic MHD turbulence also results in synchrotron anisotropies that are quantified in LP12. There the quadruple moment of the synchrotron intensity correlation functions was shown to be aligned with the magnetic field. Therefore by measuring the longer direction of the contours of the magnetic field isocorrelation (see LP12) one can approximate the magnetic-field direction over the sky.\n\nThe calculations of the correlation functions, require averaging, which in the astrophysical situations means the volume averaging. Therefore one may expect that compared to the SIGs, the LP12-type quadrupole and higher multipole anisotropies are a significantly more coarse-graded measures.\nTo test this statement we provide in Figure <ref> the AM for the SIGs and the similarly-defined alignment measure of the correlation function anisotropies (CFAs) that reveal the dominant quadrupole anisotropy induced by magnetic field.  The directions of the CFAs longer axes of anisotropy are rotated 90 degrees to be compared with the directions of the SIGs and the magnetic field traced by synchrotron polarizations.\n\nWe compare sub-block averaged SIGs with the CFAs obtained in the same blocks. Figure <ref> clearly shows that the SIGs have a great advantage over the CFAs on tracing the detailed strucuture of magnetic field. In fact, in terms of the alignment measure, the CFAs can trace magnetic field only in a for a sufficiently coarse block size. Comparatively, the SIGs can work on smaller scales without losing much of the alignment. The ability of CFAs for the same purpose is highly limited. The limitations of the CFAs compared to the SIGs is expected as the SIGs are defined for an individual eddy, while the CFAs get defined after correlation/structure functions are calculated. The latter requires the averaging over many eddies.\n\n\n\nWe, however, believe that the SIGs and the CFAs are complementary measures in a number of ways. The correspondence between coarse-graded magnetic field directions measured by the two techniques makes the tracing of magnetic field more trustworthy. Their correspondence also indicates that the performed averaging may be sufficient to use studies of the CFA anisotropies for the purpose of separating the contribution from fundamental MHD modes, i.e. Alfven, fast and slow, as it is described in LP12.\n"
        },
        {
            "section_number": 6,
            "title": "ILLUSTRATION OF THE SIGS TECHNIQUE USING PLANCK SYNCHROTRON DATA",
            "summary": "Discuss how the Synchrotron Intensity Gradients (SIG) technique is applied to PLANCK synchrotron data to trace magnetic fields, highlighting the effectiveness of SIGs in revealing magnetic field directions at high galactic latitudes and addressing the limitations and challenges encountered near the galactic plane.",
            "target_length": 400,
            "origin_content": "The encouraging results above stimulated us to apply the SIG technique to the PLANCK synchrotron data. For our test we picked the PLANCK foreground synchrotron intensity map <cit.> and compared the magnetic-field directions that we obtained with SIGs with the magnetic-field directions as determined by the PLANCK synchrotron polarization.\n\n\nWe use the full-sky map to illustrate how the SIG can trace magnetic field. We use the synchrotron intensity to compute gradients, and synchrotron polarization to infer the magnetic field direction. We projected the data into the Cartesian frame, and follow the procedures described in the earlier sections and tested with the synthetic data to produce the sub-block averaged gradient map. As shown in section <ref> that œÉ=4 can already preserve the alignment in strong-noise environment, we reduced the noise using a œÉ=4 Gaussian pre-filter.\n\nFigure <ref> shows the full-sky SIG overplotted with Planck synchrotron data. We panels in the Figure demonstrate the patches of the sky with AM>0.5. It can be seen readily that the high latitude have the best alignment, while near the galactic plane alignment is reduced.  This reduction with the existence of the poorly resolved synchrotron structures not directly associated with turbulence. To such structures our technique is not applicable. However, we expect that with higher resolution when these structures are well resolved, the underlying small scale turbulence should again induce the alignment of the SIGs and the projected magnetic field.[Another potential complication related to the use of SIGs for studying magnetic field in the galactic disk plane is that distant regular structure, e.g. supernova shells, can interfere with the calculation of the SIGs that make use the resolved turbulence associated to the nearby objects. We do not discuss this effect in this paper.] At the same time, the fact that the SIGs are not influenced by the complex pattern of the Faraday rotation within the galactic disk should motivate further studies of the SIG ability to reveal magnetic fields in the galactic disk.\n\n\nOur test calculations shows that the SIGs are applicable to the synchrotron intensity observations and can reveal the direction of galactic magnetic field at least at high galactic latitudes. Note, that the turbulence at such latitudes corresponds to low M_A.  Naturally, more tests of the SIGs in the presence of complex magnetic-field morphology are needed. Therefore moving from our demonstration here to studies of magnetic fields in the galactic disk requires a more detailed study and will be performed elsewhere.\n"
        },
        {
            "section_number": 7,
            "title": "SYNERGY WITH OTHER TECHNIQUES OF MAGNETIC-FIELD STUDY",
            "summary": "Discuss the synergistic potential of combining synchrotron intensity gradients (SIGs) with other techniques, such as synchrotron polarization, velocity gradients, and dust polarimetry, to enhance our understanding of magnetic fields across different interstellar medium phases and their implications for astrophysical and cosmological studies.",
            "target_length": 2300,
            "origin_content": "The paper above introduces a new way to trace magnetic field. It is always good to have yet another way of studying astrophysical magnetic fields. However, the advantages of the SIGs are not limited by this.\n\nSynchrotron polarization is a generally accepted way of studying magnetic fields in our galaxy, external galaxies and galaxy clusters. One of the difficulties of using synchrotron polarization is that the polarized radiation is subject to the Faraday rotation effect. To account for this effect, multifrequency observations are performed and the Faraday rotation is compensated. This is a significant complication. Potentially going to very high frequencies makes the Faraday effect negligible. However, at high frequencies the energy loses of relativistic electrons are not negligible and their spacial distribution may be different from the low energy relativistic electrons. This complicates the analysis and may be the source of an error. Moreover, recent analytical studies in <cit.>  have demonstrated that the separation of the effects of the Faraday rotation in the presence of turbulent magnetic fields is far from trivial (see also ). In this situation, the possibility of obtaining magnetic field direction using SIGs is very advantageous.\n\nCombining the SIGs and the polarization measurements can be very synergetic. By measuring the actual direction of magnetic field using the SIGs and comparing it with the direction of polarization one can get the measure of the Faraday rotation of the media between us and the synchrotron-emitting region. In the presence of Faraday depolarization the combination of SIGs and polarized radiation presents additional advantages. For instance, the SIGs of the unpolarized synchrotron can trace magnetic fields in the distant regions subject to the Faraday depolarization, while the polarization and the SIGs measured for polarized intensities can trace the magnetic field in the regions close to the observer. As the Faraday depolarization is the function of frequency, by changing the frequency one can provide the 3D tomographic studies of the magnetic field structure. The corresponding procedures will be elaborated elsewhere. In particular, we are preparing a study revealing how the polarized intensity gradients trace magnetic fields.\n\nThe SIG technique is similar to the Velocity Centroid Gradient (VCG) technique that was introduced in GL17 and the Velocity Channel Gradient (VChG) technique introduced in LY17. Within the VCG technique, the calculation of gradients is performed using the 2D maps of velocity centroids gradients, while for the VChG technique the gradients are calculated by the intensities within the channel maps. Both measures are aimed at getting the velocity information. Indeed, the velocity centroids (see ) are known to be good measures of velocity, in particular, for subsonic turbulence. Intensities in thin velocity channels are mostly dominated by velocity caustics and therefore are also most sensitive to velocities <cit.>.[Naturally, this is the case when the turbulent broadening of the spectral lines is larger than the thermal broadening. Otherwise, the intensity variations arising from the velocity crowding induced by turbulence are exponentially suppressed <cit.> and the channel maps reflect the total intensities.] Supersonic velocity turbulence can be studied for both HI and heavier species using velocity channel maps, while for heavier species both subsonic and supersonic velocity turbulence can be studied. Both VCGs and VChGs are readily available from the Doppler-shifted spectroscopic data.\n\nCompared to the VCGs and VChGs, the calculation of the SIGs is simpler, as it requires only synchrotron intensities, rather than full spectroscopic data. In this sense, the SIG technique is similar to tracing magnetic fields using intensity gradients (IGs) that are discussed as ways of tracing magnetic field and the ISM processes in GL17, YL17ab and LY17. The alignment of intensity gradients and densities was first discussed by <cit.> on the basis of empirical numerical studies, while the relation of this alignment with the properties of MHD turbulence was revealed in the aforementioned papers. We note,  however,  that from both theoretical considerations and numerical simulations of turbulence we expect the properties of MHD turbulence to be better represented by fluctuations of magnetic fields and velocities rather than fluctuations of density (see Brandenburg & Lazarian 2013 for a review). In particular, we expect the IGs to be more affected by shocks and be less reliable traces of magnetic field for supersonic turbulence. At the same time, the disadvantages of the IGs in tracing magnetic field present advantages in tracing other ISM processes, e.g. shocks. Thus it is really advantageous to search the synergy of different techniques, including the IGs. An apparent advantage of the IGs is that they can be used for the data sets where no spectral information is available, but only intensities. Therefore the IGs can be used e.g. with dust emission intensities. The VChGs smoothly transfer to the IG technique when the Doppler shift of the lines get subsonic or, for the sake of reducing the noise, the channels are made thicker.\n\nIt is clear that, in general, SIGs, VCGs, VChGs and IGs are complimentary techniques that trace magnetic field in different interstellar environments. For instance, cold and warm diffuse HI, line emission, e.g. CO emission, from molecular clouds present the natural environments for studies using the VCG and VChG techniques. Combining that with the IGs, one can study shocks and self-gravitating regions (YL17, ) and measuring the relative alignment of the directions defined by the VCGs and VChGs with those defined by the IGs one can characterize the sonic Mach number of the media (LY17).  At the same time, synchrotron radiation in the Milky Way mostly originate at the large expanses of the galactic halo and to the data from these regions the SIG technique is intended to be applied. Obtaining magnetic field properties in different parts of the interstellar media is important not only for understanding the importance of the magnetic field these phase, but also for our understanding whether the same magnetic field connects different interstellar phases.\n In fact, while VCGs and VChGs are useful for studying magnetic fields in Cold and Warm phases, the SIGs can study magnetic fields in Warm and Hot ISM phases (see Draine 2011 for the list of the ISM phases). The advantage of the VCGs, the VChGs and the IGs is that it is possible to combine different molecular species that are present at different densities, it is possible to study the magnetic fields and the gravitational collapse within molecular clouds. In addition, using the galactic rotation curve, it is possible to approximately map the 3D distribution of magnetic field. The 3D mapping of magnetic field is also possible combining the SIGs and gradients of  polarized intensities measured at different frequencies. The latter technique requires further research, however.\n\nThe alignment of interstellar dust is a well-accepted way of tracing magnetic field. Both theoretical considerations and the observational testing (see  and ref. therein) indicate that\nthe alignment of dust is very efficient in the diffuse media where radiative torques <cit.> are strong. The alignment can trace magnetic fields in the self-gravitating regions, but it may fail in starless molecular cloud cores. The polarization arising from grain alignment is complementary to the VCGs as it is discussed in YL17 and to the VChGs, as discussed in LY17. The dust polarimetry provides the direction of the magnetic field which through the comparison with the velocity gradients reveals the regions of the gravitational collapse. Therefore, combining the polarimetry and velocity gradients it is possible to identify the regions of molecular clouds that are subject to the gravitational infall, i.e. revealing the initial stages of star formation. At the same time, compared to dust submillimeter polarimetry, velocity gradients can provide better information where the measured magnetic fields are spatially located along the line of sight. The latter is especially valuable for studying the magnetic field in the plane of the galaxy. For instance, while the polarized dust emission present in the disk plane presents the cumulative result of emission from many clouds along the line of sight, the studies with the VChGs allow mapping magnetic fields of individual clouds. In addition, the dust disk is significantly thinner that the synchrotron halo. Therefore by comparing the results obtained  FIR polarimetry with the magnetic fields revealed by synchrotron, e.g. by the SIGs, can help understanding the distribution of magnetic field with the height. Note, that in YL17 the VCGs were shown to reveal well the structure of magnetic field in the HI disk.Combining SIGs, VCGs, VChGs and the dust polarimetry one can study how magnetic fields connect Hot, Warm and Cold ISM phases with molecular clouds.\n\nIn addition, we shall mention the empirical technique of tracing magnetic field using filaments observed in HI velocity channel maps <cit.>. The relation of the observed filaments to the MHD turbulence theory requires further studies, but here we can provide some preliminary considerations. For instance, as we discussed earlier, the structures in channel maps are mostly induced by velocities and therefore we believe that the filament technique is related to velocity gradients, in particular to the VChGs.  The filaments are expected to be created perpendicular to the velocity gradients, i.e. therefore the filaments are expected to be aligned along magnetic field, which corresponds to observations. The comparison of the magnetic field tracing using the VCGs, VChGs and the filaments will be provided elsewhere.\n\nAs it is clear from the discussion above, combining different velocity and synchrotron gradients, one can investigate the relative distribution of magnetic fields in different ISM phases along the line of sight. Such studies are essential for understanding of the complex dynamics of magnetized multiphase ISM. At the same time, for some regions, however, e.g. for the supernovae shocks, it seems possible and very advantageous to apply all these techniques at once.\n\n One also should note that the tracing of magnetic field directions using velocity and magnetic field gradients is different in the regions dominated by self-gravity. It was noted in <cit.> that the velocity gradients in such regions get parallel to magnetic field, as the matter falls into gravitational wells. On the contrary, we may expect the magnetic field gradients to stay perpendicular to the magnetic field even in those situations.\n\n  In addition, it is clear from the discussion in <ref> that the most reliable magnetic-field tracing is expected in nearly incompressible turbulence in the absence of self-gravity. These are the conditions for the Warm and Hot phases of the ISM (see  for the list of the idealized ISM phases). These are exactly the media that are responsible for the bulk of  synchrotron radiation <cit.>.\n In fact, earlier studies (e.g. ) indicated that the sonic Mach number of the synchrotron emitting Warm media is around unity. It is expected to be much less than unity for the hot coronal gas of the galactic halo. Therefore we expect that the SIGs can trace magnetic fields well and be less affected by the distortion that arises from compressibility effects. Compared to the VCGs the SIGs can be also more robust, as the VCGs are influenced by the density distribution of the emitting gas (see ) and the density is not a robust tracer of MHD turbulence statistics. VChGs when thin slices are used are marginally influenced by the turbulent densities for subsonic turbulence,[For subsonic turbulence one should use the heavier species, e.g. metals or complex molecules, that are moved by main hydrogen dominated subsonic flow. E.g. CO molecules can be used as such a tracer.] but still are affected by density for supersonic turbulence (LP00). At the same time, the synchrotron intensity fluctuations are produced by uniformly distributed electrons and thus are expected to better reflect the magnetic-field statistics.\n\nWe can add that the ways of studying VCGs, VChGs and SIGs are similar. For instance, within our present study we successfully used the way of calculating gradients first suggested in YL17. In addition, our present study also shows that SIGs similar to VCGs and VChGs can be obtained using interferometric data with missing low spatial frequencies, e.g. the interferometric data obtained without the corresponding single dish observations. This opens prospects of using these techniques for studying extragalactic magnetic fields.\n\n\n\n\n\n\n\n\n\n\n\n\nFaraday rotation is an important way of studying the magnetic field component parallel to the line-of-sight (see ). The observationally attainable rotation measure (RM) is proportional to the integral of the product of the parallel to the line-of-sight component of magnetic field and thermal electron density, if the original magnetic-field direction at the source is known. The SIGs can be used to define this direction, which has advantages over the currently-used Faraday-rotation measurements that employ multifrequency polarization measurements. Moreover, SIGs can help to distinguish the Faraday rotation that arises from the source of polarized radiation and the media intervening between the source and the observer. Indeed, at the source the SIGs are measuring the actual magnetic-field direction.\n\n\n\n\nA promising possibility is presented with tracing of magnetic field using aligned atoms or ions ( and ref. therein). This alignment happens for atoms/ions with fine or hyperfine structure and is induced by radiation. The Larmor precession realigns atoms/ions and thus the resulting polarization becomes dependent on the magnetic field direction. This type of alignment can potentially trace extremely weak fields in the diffuse rarefied media and we expect that this can be complementary to the SIG technique. For instance, the resulting polarization of HI arising from the atomic alignment can reveal magnetic fields. The domain of the atomic alignment are the regions of low matter density but high radiation intensity. The anisotropic radiations pumps and aligns atoms/ions, while collisions randomize spin directions.\n\nWhile our discussion above has focused on the astrophysical prospects of the SIGs, the possibility of magnetic field tracing has important consequences for the CMB work. Indeed, separating of polarized foregrounds and the CMB polarization is absolutely essential for detecting and studying the enigmatic cosmological B-modes. Obtaining the actual direction of the magnetic field using the SIG technique looks very advantageous in this context, as well as combining the SIG, the VCG and the VChG measurements to weed out the polarized foreground contributions from different interstellar medium components.\n"
        },
        {
            "section_number": 8,
            "title": "SUMMARY",
            "summary": "Discuss how synchrotron intensity gradients can be utilized as tracers of magnetic fields in magnetized flows, highlighting their advantages over traditional methods and their robustness in various observational conditions.",
            "target_length": 1300,
            "origin_content": "Using the theory of MHD turbulence we predicted that in magnetized flows the synchrotron intensity gradients (SIGs) are expected to reveal the magnetic field.\nWe successfully tested this prediction using synthetic synchrotron maps obtained with the 3D MHD compressible and incompressible simulations\nas well as PLANCK synchrotron intensity and polarization data.\nThe new technique is complementary to the\nother ways of tracing magnetic field, which includes the traditional techniques of using synchrotron and dust polarization as well new techniques that employ velocity centroid gradients (VCGs) and velocity channel gradients (VChGs). The SIGs are giving the true direction of the magnetic field in the synchrotron-emitting volume that is not distorted by the Faraday rotation effect. Therefore,\ncombining the SIGs with synchrotron polarimetry measurements one can determine the Faraday rotation measure. This is useful for studying line-of-sight component of magnetic field. We have demonstrated that the SIGs are a robust measure in the presence of Gaussian noise and can be obtained with interferometeric data that is obtained without single-dish telescope observations.\n\nAcknowledgements.   AL acknowledges the support of the NSF grant AST 1212096, NASA grant NNX14AJ53G as well as a distinguished visitor PVE/CAPES appointment at the Physics Graduate Program of the Federal University of Rio Grande do Norte, the INCT INEspao and Physics Graduate Program/UFRN. The stay of KHY at UW-Madison is supported by the Fulbright-Lee Fellowship. HL is supported by the research fellowship at Department of Physics, Chugnam University, Korea.\n\n\n\n\n\n\n[Andersson et al.(2015)]2015ARA   A..53..501A Andersson, B.-G., Lazarian, A., & Vaillancourt, J.¬†E. 2015, , 53, 501\n[Armstrong et¬†al.(1995)Armstrong, Rickett, &\n  Spangler]Armstrong1995ElectronMedium\nArmstrong, J.¬†W., Rickett, B.¬†J., & Spangler, S.¬†R. 1995,\n  http://dx.doi.org/10.1086/175515The Astrophysical\n  Journal, 443, 209\n\n[Beresnyak et¬†al.(2005)Beresnyak, Lazarian, &\n  Cho]Beresnyak2005DensityTurbulence\nBeresnyak, A., Lazarian, A., & Cho, J. 2005,\n  http://dx.doi.org/10.1086/430702The Astrophysical\n  Journal, 624, L93\n[Beck(2015)]Beck15 Beck, R. 2015, Magnetic Fields in Diffuse Media, 407, 507\n[Brandenburg &\n  Lazarian(2013)]Brandenburg2013AstrophysicalTurbulence\nBrandenburg, A., & Lazarian, A. 2013,\n  http://dx.doi.org/10.1007/s11214-013-0009-3Space\n  Science Reviews, Volume 178, Issue 2-4, pp. 163-200, 178, 163\n\n[Burkhart et¬†al.(2012)Burkhart, Lazarian, &\n  Gaensler]Burkhart2012PropertiesMaps\nBurkhart, B., Lazarian, A., & Gaensler, B.¬†M. 2012,\n  http://dx.doi.org/10.1088/0004-637X/749/2/145The\n  Astrophysical Journal, Volume 749, Issue 2, article id. 145, 16 pp. (2012).,\n  749\n[Castaing et al.(1990)]1990PhyD...46..177C Castaing, B., Gagne, Y., & Hopfinger, E.¬†J. 1990, Physica D Nonlinear Phenomena, 46, 177\n[Chepurnov & Lazarian(2010)]Chepurnov2010ExtendingData\nChepurnov, A., & Lazarian, A. 2010,\n  http://dx.doi.org/10.1088/0004-637X/710/1/853The\n  Astrophysical Journal, Volume 710, Issue 1, pp. 853-858 (2010)., 710, 853\n\n[Cho & Lazarian(2002)]Cho2002CompressiblePlasmasb\nCho, J., & Lazarian, A. 2002,\n  http://dx.doi.org/10.1103/PhysRevLett.88.245001Physical\n  Review Letters, vol. 88, Issue 24, id. 245001, 88\n\n[Cho & Lazarian(2003)]Cho2003CompressibleImplicationsb\n‚Äî. 2003,\n  http://dx.doi.org/10.1046/j.1365-8711.2003.06941.xMonthly\n  Notices of the Royal Astronomical Society, Volume 345, Issue 12, pp.\n  325-339., 345, 325\n\n[Cho et¬†al.(2001)Cho, Lazarian, &\n  Vishniac]Cho2001SimulationsMedium\nCho, J., Lazarian, A., & Vishniac, E. 2001,\n  http://dx.doi.org/10.1086/324186The Astrophysical\n  Journal, Volume 564, Issue 1, pp. 291-301., 564, 291\n\n[Cho & Vishniac(2000)]Cho2000TheTurbulence\nCho, J., & Vishniac, E.¬†T. 2000,\n  http://dx.doi.org/10.1086/309213The Astrophysical\n  Journal, Volume 539, Issue 1, pp. 273-282., 539, 273\n\n[Clark et al.(2015)]2015PhRvL.115x1302C Clark, S.¬†E., Hill, J.¬†C., Peek, J.¬†E.¬†G., Putman, M.¬†E., & Babler, B.¬†L. 2015, Physical Review Letters, 115, 241302\n\n[Clarke & Ensslin(2006)]2006AJ....131.2900C\nClarke, T.¬†E., & Ensslin, T.¬†A. 2006,\n  http://dx.doi.org/10.1086/504076, 131, 2900\n\n[Dolginov & Mitrofanov(1976)]1976Ap   SS..43..291D\nDolginov, A.¬†Z., & Mitrofanov, I.¬†G. 1976,\n  http://dx.doi.org/10.1007/BF00640010, 43, 291\n\n[Draine(2011)]Draine2011PhysicsMedium\nDraine, B.¬†T. 2011, Physics of the interstellar and intergalactic medium\n  (Princeton University Press), 540\n\n[Draine & Weingartner(1996)]1996ApJ...470..551D\nDraine, B.¬†T., & Weingartner, J.¬†C. 1996,\n  http://dx.doi.org/10.1086/177887, 470, 551\n\n[Esquivel & Lazarian(2005)]EL05\nEsquivel, A., & Lazarian, A. 2005,\n  http://dx.doi.org/10.1086/432458, 631, 320\n[Fernandez et al.(2014)]2014MNRAS.440..298F Fernandez, E.¬†R., Zaroubi, S., Iliev, I.¬†T., Mellema, G., & Jeliƒá, V. 2014, , 440, 298\n[Gaensler et¬†al.(2011)Gaensler, Haverkorn, Burkhart, Newton-McGee,\n  Ekers, Lazarian, McClure-Griffiths, Robishaw, Dickey, &\n  Green]Gaensler2011Low-Mach-numberGradients\nGaensler, B.¬†M., Haverkorn, M., Burkhart, B., et¬†al. 2011,\n  http://dx.doi.org/10.1038/nature10446Nature, Volume\n  478, Issue 7368, pp. 214-217 (2011)., 478, 214\n[Galtier et al.(2005)]Gal2005 Galtier, S., Pouquet, A., & Mangeney, A. 2005, Physics of Plasmas, 12, 092310\n\n[Ginzburg(1981)]1981MoIzNRG\nGinzburg, V.¬†L. 1981, Moscow Izdatel Nauka\n\n[Goldreich(1995)]GoldreichP.Sridhar1995GS95IITurbulence\nGoldreich, P.¬†;Sridhar, S. 1995,\n  http://dx.doi.org/10.1086/174600The Astronomical\n  Journal, 438, 763\n\n[Gonz√°lez-Casanova & Lazarian(2017)]GL17 Gonz√°lez-Casanova, D.¬†F., & Lazarian, A. 2017, , 835, 41\n\n[Haverkorn et¬†al.(2006)Haverkorn, Gaensler,\n  McClure-Griffiths, Dickey, & Green]2006ApJS..167..230H\nHaverkorn, M., Gaensler, B.¬†M., McClure-Griffiths, N.¬†M., Dickey,\n  J.¬†M., & Green, A.¬†J. 2006,\n  http://dx.doi.org/10.1086/508467, 167, 230\n\n[Herron et¬†al.(2016)Herron, Burkhart, Lazarian, Gaensler,\n  & McClure-Griffiths]2016ApJ...822...13H\nHerron, C.¬†A., Burkhart, B., Lazarian, A., Gaensler, B.¬†M., &\n  McClure-Griffiths, N.¬†M. 2016,\n  http://dx.doi.org/10.3847/0004-637X/822/1/13, 822,\n  13\n\n[Higdon(1984)]1984ApJ...285..109H\nHigdon, J.¬†C. 1984,\n  http://dx.doi.org/10.1086/162481, 285, 109\n\n[Hill et¬†al.(2008)Hill, Benjamin, Kowal, Reynolds,\n  Haffner, & Lazarian]2008ApJ...686..363H\nHill, A.¬†S., Benjamin, R.¬†A., Kowal, G., et¬†al. 2008,\n  http://dx.doi.org/10.1086/590543, 686, 363\n\n[Iroshnikov(1964)]I64\nIroshnikov, P.¬†S. 1964, , 7, 566\n\n[Kandel et al.(2017)]K17 Kandel, D., Lazarian, A., & Pogosyan, D. 2017, , 464, 3617\n\n[Kowal & Lazarian(2010)]Kowal2010VelocityScalingsb\nKowal, G., & Lazarian, A. 2010,\n  http://dx.doi.org/10.1088/0004-637X/720/1/742The\n  Astrophysical Journal, Volume 720, Issue 1, pp. 742-756 (2010)., 720, 742\n\n[Kraichnan(1965)]K65\nKraichnan, R.¬†H. 1965,\n  http://dx.doi.org/10.1063/1.1761412Physics of Fluids,\n  8, 1385\n\n[Laing et¬†al.(2008)Laing, Bridle, Parma, &\n  Murgia]2008MNRAS.391..521L\nLaing, R.¬†A., Bridle, A.¬†H., Parma, P., & Murgia, M. 2008,\n  http://dx.doi.org/10.1111/j.1365-2966.2008.13895.x,\n  391, 521\n\n[Lazarian(2006)]Lazarian2006\nLazarian, a. http://dx.doi.org/10.1086/5057962006, 4\n\n[Lazarian(2007)]2007JQSRT.106..225L\nLazarian, A. 2007,\n  http://dx.doi.org/10.1016/j.jqsrt.2007.01.038,\n  106, 225\n\n[Lazarian(2009)]2009SSRv..143..357L\n‚Äî. 2009,\n  http://dx.doi.org/10.1007/s11214-008-9460-y, 143,\n  357\n\n[Lazarian(2016)]L16\n‚Äî. 2016,\n  http://dx.doi.org/10.3847/1538-4357/833/2/131,\n  833, 131\n\n[Lazarian & Beresnyak(2006)]LB06 Lazarian, A., & Beresnyak, A. 2006, , 373, 1195\n[Lazarian & Esquivel(2003)]LE03 Lazarian, A., & Esquivel, A. 2003, , 592, L37\n\n[Lazarian & Pogosyan(2000)]LP00 Lazarian, A., & Pogosyan, D. 2000, , 537, 720\n[Lazarian & Pogosyan(2004)]LP04 Lazarian, A., & Pogosyan, D. 2004, , 616, 943\n\n[Lazarian & Pogosyan(2012)]LP12\nLazarian, A., & Pogosyan, D. 2012,\n  http://dx.doi.org/10.1088/0004-637X/747/1/5, 747,\n  5\n\n[Lazarian & Pogosyan(2016)]LP16\n‚Äî. 2016,\n  http://dx.doi.org/10.3847/0004-637X/818/2/178,\n  818, 178\n\n[Lazarian & Vishniac(1999)]Lazarian1999ReconnectionField\nLazarian, A., & Vishniac, E.¬†T. 1999,\n  http://dx.doi.org/10.1086/307233The Astrophysical\n  Journal, Volume 517, Issue 2, pp. 700-718., 517, 700\n [Lazarian & Yuen(2017)]LY17 Lazarian, A., & Yuen, K.¬†H. 2017, arXiv:1703.03119\n\n[Lee et al.(2016)]2016ApJ...831...77L Lee, H., Lazarian, A., & Cho, J. 2016, , 831, 77\n[Lithwick & Goldreich(2001)]Lithwick2001CompressiblePlasmas\nLithwick, Y., & Goldreich, P. 2001,\n  http://dx.doi.org/10.1086/323470The Astrophysical\n  Journal, Volume 562, Issue 1, pp. 279-296., 562, 279\n\n[Liu et¬†al.(2009)Liu, Zakamska, Greene, Strauss, Krolik,\n  & Heckman]2009ApJLiu\nLiu, X., Zakamska, N.¬†L., Greene, J.¬†E., et¬†al. 2009,\n  http://dx.doi.org/10.1088/0004-637X/702/2/1098,\n  702, 1098\n\n[Loeb & Wyithe(2008)]2008PhRvL.100p1301L\nLoeb, A., & Wyithe, J.¬†S.¬†B. 2008,\n  http://dx.doi.org/10.1103/PhysRevLett.100.161301Physical\n  Review Letters, 100, 161301\n\n[Maron & Goldreich(2000)]Maron2000SimulationsTurbulence\nMaron, J., & Goldreich, P. 2000,\n  http://dx.doi.org/10.1086/321413The Astrophysical\n  Journal, Volume 554, Issue 2, pp. 1175-1196., 554, 1175\n\n[Matthaeus et¬†al.(1983)Matthaeus, Montgomery, &\n  Goldstein]1983PhRvL..51.1484MMatthaeus, W.¬†H., Montgomery, D.¬†C., & Goldstein, M.¬†L. 1983,http://dx.doi.org/10.1103/PhysRevLett.51.1484Physical\n  Review Letters, 51, 1484\n\n[Nixon & Aguado (2008) ]NA08 Nixon, M.S. & Aguado A.S., 2008,\nhttp://dx.doi.org/10.1016/B978-0-08-050625-8.50007-9Academic Press, 88.\n\n[Montgomery & Turner(1981)]1981PhFl...24..825M\nMontgomery, D., & Turner, L. 1981,\n  http://dx.doi.org/10.1063/1.863455Physics of Fluids,\n  24, 825\n\n[Pacholczyk(1970)]1970ranp.book.....P\nPacholczyk, A.¬†G. 1970, Radio astrophysics. Nonthermal processes in galactic\n  and extragalactic sources\n\n[Planck Collaboration et al.(2016)]Planck15X Planck Collaboration, Adam, R., Ade, P.¬†A.¬†R., et al. 2016, , 594, A10\n\n\n[Schnitzeler et¬†al.(2007)Schnitzeler, Katgert, & de\n  Bruyn]2007A   A...471L..21S\nSchnitzeler, D.¬†H.¬†F.¬†M., Katgert, P., & de Bruyn, A.¬†G. 2007,\n  http://dx.doi.org/10.1051/0004-6361:20077635, 471,\n  L21\n\n[Shebalin et¬†al.(1983)Shebalin, Matthaeus, &\n  Montgomery]1983JPlPh..29..525S\nShebalin, J.¬†V., Matthaeus, W.¬†H., & Montgomery, D. 1983,\n  http://dx.doi.org/10.1017/S0022377800000933Journal of\n  Plasma Physics, 29, 525\n\n[Soler et¬†al.(2013)Soler, Hennebelle, Martin,\n  Miville-Desch√™nes, Netterfield, & Fissel]Soler2013\nSoler, J.¬†D., Hennebelle, P., Martin, P.¬†G., et¬†al.\n  http://dx.doi.org/10.1088/0004-637X/774/2/1282013, 16\n\n[Takamoto & Lazarian(2016)]2016ApJ...831L..11T\nTakamoto, M., & Lazarian, A. 2016,\n  http://dx.doi.org/10.3847/2041-8205/831/2/L11,\n  831, L11\n\n[Westfold(1959)]1959ApJ...130..241W\nWestfold, K.¬†C. 1959,\n  http://dx.doi.org/10.1086/146713, 130, 241\n[Yan & Lazarian(2011)]YL11 Yan, H., & Lazarian, A. 2011, , 731, 35\n[Yan & Lazarian(2012)]YL12 Yan, H., & Lazarian, A. 2012, Numerical Modeling of Space Plasma Slows (ASTRONUM 2011), 459, 40\n[Yuen & Lazarian(2017a)]YL17 Yuen, K.¬†H., & Lazarian, A. 2017, , 837, L24\n[Yuen & Lazarian(2017b)]YL17b Yuen, K.¬†H., & Lazarian, A. 2017, arXiv:1703.03026\n\n[Zhang et al.(2016)]2016ApJ...825..154Z Zhang, J.-F., Lazarian, A., Lee, H., & Cho, J. 2016, , 825, 154\n"
        }
    ],
    [
        {
            "section_number": 1,
            "title": "INTRODUCTION",
            "summary": "Discuss the significance of studying the molecular gas kinematics and star formation properties in the strongly-lensed quasar host galaxy RXJ1131, and explain how these studies can enhance our understanding of the evolution of supermassive black holes and their host galaxies at intermediate redshifts.",
            "target_length": 600,
            "origin_content": "Many recent studies of galaxy evolution have been focused on investigating the interplay between star formation and active galactic nucleus (AGN) activity across cosmic epochs <cit.>.\nIt is currently not well-understood when and how the supermassive black holes (SMBHs) and\nstellar populations of present-day massive galaxies were assembled,\nbut it is clear that the co-moving rate and the black hole accretion rate densities both\nincreased substantially since z > 3 and reached their climax at z2, followed by\na rapid decline toward z0 <cit.>.\nA leading explanation for this decline is the decrease in molecular gas content and\nefficiency <cit.>,\nbut direct molecular gas measurements at intermediate redshift\n(0.2 < z < 1) that could confirm this explanation remain largely limited to\nspatially unresolved CO observations of\na modest sample of ‚àº30 ultra-luminous infrared galaxies <cit.>.\n\nMeanwhile, empirical scaling relations such as the\nM_ BH-relation <cit.>\nhave been established locally, suggesting a co-eval growth between local SMBHs and their host galaxies.\nAttempts to extend this relation out to higher redshifts, beyond the peak epoch\nof and AGN activity, have been made in recent years.\nThese studies find that\nhigh-z AGN host galaxies do not appear to follow the same M_ BH-relation as nearby spheroidal galaxies. <cit.>.\nYet, the M_ BH-relation remains poorly-constrained\nat intermediate redshifts due to the difficulty\nin separating the stellar component contributing to the optical emission from that of the bright AGN.\nThis stems from the limited resolving power, which restricts the dynamic range that can be achieved at positions near the AGN.\nStrong gravitational lensing provides the magnification necessary to spatially separate the AGN emission from the host galaxy stellar emission, significantly improving the dynamic range that can be achieved in studies of their host galaxies with current instruments.\n\n\n\nThe quasar RXS J113151.62-123158 (hereafter RXJ1131)\nat z_s, QSO0.658 <cit.> is a particularly well-suited source for\nstudying the evolution of molecular gas properties in quasar host galaxies and the\nconnection between SMBHs and their host galaxies at intermediate redshift\ngiven its unique lensing configuration.\nThe stellar emission in the host galaxy of RXJ1131 is lensed into\nan Einstein ring of 183 in radius\nthat is clearly separated from the quadruply imaged quasar emission <cit.>.\nThe foreground lens is an elliptical galaxy at z_L0.295 .\n<cit.> report a high spin parameter of a ‚àº 0.9 for the moderate-mass black hole in RXJ1131 <cit.>,\nwith an intrinsic bolometric luminosity of L_ bol, X1.345  ergs s<cit.>.\n\nIn this paper, we present and line observations and\nbroadband photometry spanning rest-frame UV to radio wavelengths towards RXJ1131 to\nstudy the properties of its molecular gas, dust and stellar populations.\nIn obs, we outline details of the observations and of our data reduction procedures.\nIn results, we report results for the and emission and broadband\nphotometry in RXJ1131.\nIn anal, we present lens modeling and dynamical modeling of the data and\nspectral energy distribution (SED) modeling of the photometric data.\nIn diss, we discuss\nthe ISM properties of the host galaxy of RXJ1131 and compare\nthem to other galaxy populations at low and high redshift.\nFinally, we summarize the main results and present our conclusions in sum.\nWe use a concordance ŒõCDM cosmology throughout this paper, with\nparameters from the WMAP9 results:\nH_0 = 69.32 Mpc, Œ©_ M = 0.29, and\nŒ©_Œõ = 0.71 <cit.>.\n"
        },
        {
            "section_number": 2,
            "title": "OBSERVATIONS",
            "summary": "Discuss the observational methods, instruments, and conditions used to study the molecular gas kinematics and star formation properties of the quasar host galaxy RXS J1131-1231, highlighting the specifics of the data acquisition and calibration processes across different telescopes and configurations.",
            "target_length": 1000,
            "origin_content": "¬ß.¬ß CARMA\n\nObservations of the rotational line\n(ŒΩ_ rest = 345.79599 GHz) towards RXJ1131 at z_ s, QSO0.658\nwere carried out with the (CARMA;\nProgram ID: cf0098; PI: D. Riechers) in the D array configuration.\nThe line frequency is redshifted to ŒΩ_ obs209.10443 GHz at the quasar redshift.\nObservations were carried out\non 2014 February 02 under poor 1.5 mm\nweather conditions and on 2014 February 17 under good 1.5 mm\nweather conditions.\nThis resulted in a\ntotal on-source time of 2.94 hours after flagging poor\nvisibility data.\nThe correlator setup provides a bandwidth of 3.75 GHz in\neach sideband and a\nspectral resolution of 12.5 MHz (‚àº17.9 ). The\nline was placed in the lower sideband with the local oscillator tuned to ŒΩ_ LO‚àº216 GHz. The radio quasars J1127-189 (first track) and 3C273\n(second track) were observed\nevery 15 minutes for pointing, amplitude, and phase calibration. Mars was\nobserved as the primary absolute flux calibrator and 3C279 was observed as\nthe bandpass calibrator for both tracks.\n\nGiven that the phase calibrator used for the first track was faint and was\nobserved under poor weather conditions and that the phase calibrator used for\nthe second track was far from our target source, the phase calibration is\nsubpar, with an rms scatter ‚àº50 over a baseline length of ‚àº135 m.\nWe thus conservatively estimate\na calibration accuracy of ‚àº40% based on the flux scale uncertainties,\nthe gain variations over time, and the phase scatter on the calibrated data. We\ntherefore treat the derived line intensity with caution and ensure that our physical interpretation\nof this system and the conclusion of this paper do not rely on this quantity.\n\nThe miriad package was used to calibrate the visibility data.\nThe calibrated visibility data were\nimaged and deconvolved using the CLEAN algorithm with ‚Äúnatural‚Äù weighting. This yields a synthesized clean\nbeam size of 32 √ó 19 at a position angle (PA) of 8for the lower sideband\nimage cube. The final rms noise is œÉ = 13.3 mJy beam^-1\nover a channel width of 25 MHz. An rms noise of\nœÉ = 0.83 mJy beamis reached by averaging over the\nline-free channels in both sidebands.\n\n\n\n ¬ß.¬ß PdBI\n\nObservations of the rotational line\n(ŒΩ_ rest = 230.53800 GHz)\ntowards RXJ1131\nwere carried out using the IRAM (PdBI; Program ID: S14BX; PI: D.\nRiechers).\nBased on the CARMA line redshift of z_ CO(3-2)0.655,\nthe line is redshifted to ŒΩ_ obs139.256 GHz.\nTwo observing runs were carried out on 2014 December 06 and 2015\nFebruary 05 under good weather conditions in the C and D array configurations,\nrespectively.\nThis resulted in 3.75 hours of cumulative six antenna-equivalent on-source\ntime after discarding unusable visibility data.\nThe 2 mm receivers were used to cover the redshifted line\nand the underlying continuum emission, employing a correlator setup that provides\nan effective bandwidth of 3.6 GHz (dual polarization) and a native spectral resolution of 1.95 MHz\n(‚àº 4.2 ).\nThe nearby quasars B1127-145 and B1124-186 were observed every 22 minutes\nfor pointing, secondary amplitude, and phase calibration, and B1055+018 was\nobserved as the bandpass calibrator for both tracks.\nMWC349 and 3C279 were observed as primary flux calibrators for the C and D\narray observations, respectively, yielding calibration accuracy better than 15%.\n\nThe gildas package was used to calibrate and analyze the visibility data.\nThe calibrated visibility data were imaged and deconvolved using the CLEAN algorithm with ‚Äúnatural‚Äù\nweighting. This yields a synthesized clean beam size of 444 √ó 195 (PA = 13).\nThe final rms noise is œÉ = 1.45 mJy beamover 10 MHz (21.5 ). The continuum image at ŒΩ_ cont‚àº139 GHz\nis produced by averaging over 3.16 GHz of line-free bandwidth. This\nyields an rms noise of 0.082 mJy beam^-1.\n\n\n\n ¬ß.¬ß Karl G. Jansky Very Large Array (Archival)\n\nOur analysis also uses archival data of the 4.885 GHz\nradio continuum obtained with the\nKarl G. Jansky Very Large Array (VLA; Program ID: AW741; PI: Wucknitz).\nObservations were carried out on 2008 December 29 under excellent weather\nconditions in the A array configuration for a total of ‚àº7 hours on-source time. The C-band receivers were used with a continuum mode setup,\nproviding a bandwidth of 50 MHz for the two IF bands with full polarization.\nThe nearby radio quasar J1130-149 was observed every 10 minutes for\npointing, amplitude, and phase calibration. J1331+305 was observed as the\nprimary flux calibrator, and J0319+415 was observed as the bandpass\ncalibrator, yielding ‚àº10% calibration accuracy.\nWe used aips to calibrate the visibility data.\nThe calibrated visibility data were imaged and deconvolved using\nthe CLEAN algorithm with robust = 0, which\nwas chosen to obtain a higher resolution image given high SNR.\nThis yields a synthesized clean\nbeam size of 049 √ó 035 (PA = 0.18) and a final\nrms noise of œÉ = 13 ŒºJy beam.\n\n\n\n ¬ß.¬ß HST (Archival)\n\nWe obtained an HST image taken with\nthe ACS\nusing the F555W filter (V-band)\nfrom the\nHubble Legacy Archive.\nThe details of the observations can be found\nin .\nWe apply an astrometric correction to the optical image by adopting the VLA 5 GHz map as the\nreference coordinate frame.\nWe shift the latter to the east by 05963 in R.A. and +08372 in\nDec., which is consistent with the typical astrometric precision (1^''-2^'') of\nimages from the Hubble Legacy Archive[http://hla.stsci.edu/hla_faq.\nhtml]. This astrometric correction is critical to avoid artificial spatial\noffsets between different emitting regions and to carry out our lens modeling,\nin which the absolute position of the foreground lensing galaxy is based on\nits coordinates in the high-resolution optical image.\nThe VLA image is calibrated using a well-monitored phase\ncalibrator, with absolute positional accuracy of ‚àº2 mas.\nFor this reason, the absolute alignment between the VLA image and other\ninterferometric images reported in this paper are expected to have an astrometric\nprecision better than 01, modulo uncertainties related to the SNR and phase\ninstability.\n"
        },
        {
            "section_number": 3,
            "title": "RESULTS",
            "summary": "Discuss the observed properties and kinematics of the molecular gas and star formation in the strongly-lensed quasar host galaxy RXS J1131-1231, highlighting the significance of the detected emissions, spatial distribution, and the implications for the structure and dynamics of the galaxy.",
            "target_length": 2200,
            "origin_content": "¬ß.¬ß Emission\n\nWe detect line emission towards the background source RXJ1131 in the PdBI data\nat ‚â≥ 27œÉ significance. Based on this measurement, we refine the redshift of RXJ1131 to\nz_ CO0.6541 ¬± 0.0002[This redshift is derived by fitting a double-Gaussian to\nthe de-lensed spectrum (delensed)\ninstead of the observed spectrum (CO21spec) to avoid biases in our\nredshift determination\ndue to differential lensing (see differential).\n]. The emission is spatially and kinematically resolved\nwith a highly asymmetric double-horned line profile\nas shown in CO21spec. Fitting a double Gaussian results in peak\nflux densities of 75.32.6 mJy and 24.02.0 mJy, and a FWHM of\n1799 and 25528 for the two components, respectively. The peaks are separated by\nŒî v_ sep40012 . The total integrated line flux is 20.3 ¬± 0.6 Jy .\n\nlcc[!htbp]\n\n3\nObserved Properties of RXJ1131 and its companion\n\nParameter\nUnit\nValue\n\nz_ CO(2-1)                                    0.65410.0002\n [0.5ex]\nI_ CO(2-1)         Jy km s    20.30.6\n [0.5ex]\nS_ CO(2-1)    Jy km sbeam    8.120.30\n [0.5ex]\nFWHM_ CO(2-1)     km s    1799, 25528\n [0.5ex]\nFWHM_ CO(2-1)    km s    22072\n [0.5ex]\nI_ CO(3-2)         Jy km s    35.76.9\n\n\naPeak flux density in the intensity map.\nbFrom fitting a double Gaussian to the observed spectrum (CO21spec).\ncFrom fitting a double Gaussian with a common FWHM to the de-lensed spectrum (delensed).\n\n\n\n\n\n\nWe construct a zeroth order moment map, red/blue channel maps, and\nfirst and second moment maps, as shown in CO21mom,\nusing the uv-continuum subtracted data cube over a velocity range of\nŒî v ‚àº 750 .\nThe higher-order moment maps are produced using\nunbinned channel maps with 3œÉ clipping.\nThe peak flux density is 8.120.30 Jy  beamin the intensity map.\nObserved properties of the emission line are summarized in obsprop.\n\nThe deconvolved source size FWHM obtained from fitting a single two-dimensional Gaussian\nto the integrated line emission in the image plane yields 5107√ó3707,\nwhich is consistent with that obtained by visibility-plane fitting within the uncertainties.\nSince the spatial distribution of the observed CO emission is unlikely to be fully described by a simple Gaussian\nand appears to be a superposition of at least two components (top left panel of CO21mom),\nwe also fit two Gaussians to the intensity map.\nThis yields deconvolved source sizes of\n3804√ó1904 and 3603√ó1503, separated by ‚àº22 in RA and ‚àº17 in Dec.\nThe deconvolved source sizes of both models suggest that the gravitationally lensed CO emission is more extended\nthan the optical\n‚ÄúEinstein ring‚Äù, which has a diameter of ‚àº36\n(i.e., the ‚ÄúEinstein ring‚Äù formed by CO emission is likely to have a larger diameter compared to the optical one).\nThis is consistent with the centroid position of the redshifted emission, which is along the quasar arc seen in the optical image,\nand the blueshifted emission, which is offset further to the SE (top right of CO21mom).\nTherefore, the CO-emitting region in RXJ1131 is likely to be more extended than its stellar and quasar emission.\n\n\n\nWe also place an upper limit on [HNC]21 line emission\nin the foreground galaxy at z‚àº0.295.\nAssuming a typical line width of 300 , this corresponds to a 3œÉ\nlimit of 0.35 Jy  beam.\n\n\n\n ¬ß.¬ß Emission\n\nWe detect line emission towards RXJ1131 in the CARMA data at ‚â≥ 5œÉ significance.\nThe spectrum appears to be consistent with a double-peaked profile, as shown in co32spec, where\nwe over-plot spectra of the and lines.\nWe extract the peak fluxes and their corresponding uncertainties for the blue and red wing independently.\nWe find a peak line flux of 5.131.43 Jy beamfor the blue wing, indicating a ‚â≥3œÉ detection for this component alone, and a peak line flux of 11.451.99 Jy beamfor the red wing,\nindicating a ‚àº 6œÉ detection.\nWe measure a line intensity of 35.7 ¬± 6.9 Jy (obsprop) by summing up fluxes over the FWZI\nlinewidth used to infer the line intensity.\n\nAssuming that the spatial extent of and is similar and therefore the emission is\nmagnified by the same amount, the measured line intensities\ncorrespond to a brightness temperature ratio of\nr_ 32 = T_/T_ = 0.78 ¬± 0.37.\nThe quoted error bar is derived by adding the uncertainties associated with the CO line intensities\nand those from absolute flux calibrations in quadrature.\nThis brightness temperature ratio is consistent with\nthermalized excitation within the uncertainties, as commonly observed in nuclear regions of\nnearby ULIRGs and high-z quasars <cit.>, but also\nwith the lower excitation seen in normal star-forming disks <cit.>.\n\n\n\n\n\n ¬ß.¬ß Continuum Emission\n\nNo 1.4 mm continuum emission is detected at the position of down to a 3œÉ limit of 2.49 mJy beam.\nThis is consistent with the spectrum shown in co32spec.\n\nWe detect 2.2 mm continuum emission at an\nintegrated flux density of\n1.20.2 mJy, with a peak flux of\nS_ŒΩ = 79988 ŒºJy beamcentered on the lensing galaxy (cont).\nSlightly extended emission\nalong the lensing arc is also detected.\nThis suggests that we detect emission in both\nthe foreground and the background galaxy and that the\nemission is marginally resolved along its major axis.\nWe subtract a point source model in the visibility-plane to remove the unresolved part of the\nemission, which we here assume to be dominated by the foreground galaxy. The emission\nin the residual map coincides spatially with the lensing arc. We measure a flux density\nof S_ŒΩ0.39 ¬± 0.08 mJy for this residual component.\nThis flux density is consistent with\nthe difference between the integrated and the peak flux density measured in the\noriginal continuum map (‚àº0.4 mJy).\nWe therefore adopt S_ŒΩ0.390.12 mJy as the best estimate for the 2 mm continuum flux of\nthe background galaxy (RXJ1131).\nWe here quote a conservative error bar, which is derived by adding the uncertainty\nassociated with the flux density of the\npoint-source model (Œ¥ S_ŒΩ0.088 mJy) with\nthat of the peak flux in the residual map (0.08 mJy)\nin quadrature. We caution that this does not account for the systematic uncertainties of the\nde-blending procedure, where we have assigned 100% of the point source flux to the foreground galaxy.\nWe report the peak flux in the original map\n(S_ŒΩ = 79988 ŒºJy beam) for the foreground galaxy, which\nis the best estimate possible at the resolution of our observations, but we acknowledge that a non-negligible contribution from the background source to the peak flux cannot be ruled out.\n\n\n\nThe VLA C-band continuum image in cont shows resolved emission from the\njets and the core of the foreground elliptical galaxy\nas well as emission toward the background quasar.\nMultiple peaks are seen along the arc with their centroids\ncoincident with the optical emission from the quasar.\nWe extract the flux densities for the lensing arc and the radio core in photometry.\nWe find a spectral index of Œ±^ 2mm_ 6cm = -0.020.07\nfor the foreground galaxy and Œ±^ 2mm_ 6cm = -0.350.21\nfor the background galaxy by fitting\npower-laws (S_ŒΩ‚àùŒΩ^Œ±) to their continuum fluxes at\n5 GHz and 2 mm.\nThe spectral slope derived for the background source is flatter than the typical slope of pure synchrotron emission <cit.>. This likely suggests\nthat at least a fraction of the observed 2 mm emission arises from thermal dust emission.\nThis spectral slope would be even shallower\nif the background source contributes to the unresolved fraction of the\n2 mm flux.\nIn this case, the 2 mm flux of the foreground galaxy would be lower than the value reported here and\nlead to a slope steeper than Œ±^ 2mm_ 6cm-0.02, which is flatter than\nthat typical of elliptical galaxies.\nAssuming a spectral slope of Œ±-0.7 to account for synchrotron radiation in RXJ1131, we expect\na flux density of S_ 2mm0.1220.004 mJy at 2 mm.\nThe flux excess of S_ 2mm0.270.08 mJy therefore likely arises due to thermal dust emission.\n\n\n\n ¬ß.¬ß Photometry\n\nWe compile (MIR) to broadband photometry from various\ncatalogs available on the NASA/IPAC Infrared Science\nArchive (IRSA) in photometry with aperture corrections\nwhen warranted. These data were obtained using\nthe Cerro Tololo Inter-American Observatory (CTIO) for the Two Micron All Sky Survey <cit.>,\nthe Wide-field Infrared Survey Explorer <cit.>,\nthe Infrared Astronomical Satellite\n<cit.>, and\nthe Multiband Imaging Photometer <cit.> and\nMid-infrared Infrared Array Camera <cit.> on\nthe .\nWe retrieve PBCD (level 2) Spitzer/IRAC images from the\nSpitzer Heritage Archive and perform aperture photometry on\nthe channel 1 image to extract the flux density at 3.6 Œºm\nsince it is not available from the IRSA archive.\n\nThe emission in the IRAC images is slightly extended. We thus use an\nHST image (‚àº007 resolution) to determine the\norigin of their centroids, all of which are found to be\ncentered at the position corresponding to the lensed emission from the\nbackground galaxy. To recover the diffuse background emission, we subtract a\npoint source model centered on the lensing galaxy, using the average\nFWHM found by fitting a Gaussian profile to several field stars\nwith the imexam routine of IRAF.\nWe perform aperture photometry on the residual image\nto obtain decomposed flux measurements of the background galaxy.\nThe photometry for the foreground galaxy is then obtained\nby subtracting the background emission from the\nobserved total flux. The resulting photometry in\nphotometry is obtained after performing an aperture correction\ndescribed in the IRAC Instrument Handbook[http://irsa.ipac.caltech.edu/data/SPITZER/docs/irac/iracinstrumenthandbook/] to\ncorrect for the fact that the imaging was calibrated\nusing a 12^'' aperture, which is larger than the aperture (58) we used to\nperform aperture photometry.\n\nWe fit a power-law spectrum to the\ndecomposed IRAC photometry to disentangle the background and foreground\nemission from the total flux observed in the MIPS 24  band.\nThe spectral indices corresponding to the best-fitting curves are Œ± = -1.8 and\nŒ± = -0.85 for the lensing galaxy and RXJ1131, respectively.\nThe latter\nis consistent with the mean 3.6 - 8\nspectral slope of\nŒ± = -1.07 ¬± 0.53 found for unobscured AGN\n<cit.>. An extrapolation of the fit to 24\nyields 33.96 ¬± 0.01 mJy and 25.19 ¬± 0.03 mJy\nfor the foreground galaxy and RXJ1131, respectively.\nThe uncertainties are the standard deviations of\nthe extrapolated fluxes obtained from two independent Monte Carlo\nsimulations, each of 500 iterations.\nWe incorporate the decomposed 24  data in our\nSED fitting to provide some constraints on\nthe Wien tail beyond the dust peak\nof the SED of RXJ1131.\nDetails of the SED modeling are presented in SED.\n\nExtraction of the Herschel/SPIRE photometry at 250, 350, and 500  was\ncarried out using sussextractor within the Herschel Interactive\nProcessing Environment <cit.>\non Level 2 maps obtained from the Herschel Science Archive.\nThese maps were processed by the SPIRE pipeline\nversion 13.0 within HIPE. The sussextractor task estimates\nthe flux density from an image convolved with a kernel\nderived from the SPIRE beam. The flux densities\nmeasured by sussextractor were confirmed by\nusing the Timeline Fitter, which performs photometry\nby fitting a 2D elliptical Gaussian to the Level 1 data at the\nsource position given by the output of sussextractor. The fluxes\nobtained from both methods are consistent within the uncertainties.\n\nlccc[!htbp]\n\n4\nPhotometry data\nWavelength     Frequency     Flux Density     Instrument\n\n()     (GHz)     (mJy)\n\n\n  1-4\n\n\n4cCombined/Unresolved\n\n1.25        239834      1.009 ¬± 0.090        CTIO/J-Band\n\n1.65        181692      1.448 ¬± 0.121        CTIO/H-Band\n\n2.17        138153      2.064 ¬± 0.160        CTIO/Ks-Band\n\n3.4         88174.2     7.027 ¬± 0.142        WISE/W1\n\n3.6         83275.7     5.618 ¬± 0.002       Spitzer/IRAC\n\n4.5         66620.5     7.803 ¬± 0.002       Spitzer/IRAC\n\n4.6         65172.3     8.872 ¬± 0.163       WISE/W2\n\n5.8         51688.4     10.720 ¬± 0.005      Spitzer/IRAC\n\n8.0         37474.1     14.470 ¬± 0.004      Spitzer/IRAC\n\n12          24982.7     21.960 ¬± 0.425      WISE/W3\n\n12          24982.7     <400                  IRAS\n\n22          13626.9     55.110 ¬± 1.878      WISE/W4\n\n24          12491.4     70.204 ¬± 0.026      Spitzer/MIPS\n\n25          11991.7     < 500                 IRAS\n\n60          4996.54     < 600                 IRAS\n\n100         2997.92     < 1000                IRAS\n\n250         1199.17     289.4 ¬± 9.6         Herschel/SPIRE\n\n350         856.55      168.2 ¬± 8.6         Herschel/SPIRE\n\n500         599.585     56.8 ¬± 8.8          Herschel/SPIRE\n\n1387.93     216         <2.49                 CARMA\n\n2152.82     139.256     1.23 ¬± 0.22       PdBI\n\nForeground Lensing Galaxy (deblended bands)\n [-1.5ex]\n0.555       540167      0.056 ¬± 0.006       HST-ACS/V-Band\n\n0.814       368295      0.238 ¬± 0.013       HST-ACS/I-Band\n\n1.6         187370      0.539 ¬± 0.041       HST-NICMOS(NIC2)/H-Band\n\n3.6         83275.7     0.585 ¬± 0.003    Spitzer/IRAC\n\n4.5         66620.5     1.794 ¬± 0.003    Spitzer/IRAC\n\n5.8         51688.4     3.163 ¬± 0.006    Spitzer/IRAC\n\n8.0         37474.1     4.589 ¬± 0.006    Spitzer/IRAC\n\n2152.82     139.256     0.799 ¬± 0.082       PdBI\n\n61414       4.8815      0.866 ¬± 0.027       VLA\n\nBackground Galaxy RXJ1131 (deblended bands)\n0.555       540167      0.009 ¬± 0.004    HST-ACS/V-Band\n\n0.814       368295      0.041 ¬± 0.005    HST-ACS/I-Band\n\n1.6         187370      0.133 ¬± 0.004    HST-NICMOS(NIC2)/H-Band\n\n3.6         83275.7     5.034 ¬± 0.002      Spitzer/IRAC\n\n4.5         66620.5     6.009 ¬± 0.002      Spitzer/IRAC\n\n5.8         51688.4     7.557 ¬± 0.003       Spitzer/IRAC\n\n8.0         37474.1     9.881 ¬± 0.004      Spitzer/IRAC\n\n2152.82     139.256     0.39 ¬± 0.12    PdBI\n\n61414       4.8815      1.273 ¬± 0.042       VLA\n\nThe IRAC photometry for channel 1 (3.6 ) is extracted directly from the image and\nfrom the Spitzer Heritage Archive for channels 2-4 (4.5, 5.8, and 8.0 ). The flux uncertainties quoted for radio and mm observations (PdBI, CARMA, and VLA) do not include those from absolute flux calibration.\nAll upper limits are 3œÉ.\naFlux obtained using aperture photometry after subtracting the emission of RXJ1131 from the total emission.\nbA contribution from the quasar has been removed (see C06), and thus the flux density corresponds to the host galaxy only.\ncFlux extracted from the residual map after subtracting a point-source model. For SED modeling, we use S_ 2mm0.270.08 mJy to exclude synchrotron emission (see deblend).\nThe HST photometry is adopted from C06.\n"
        },
        {
            "section_number": 4,
            "title": "ANALYSIS",
            "summary": "Analyze the kinematics and star formation properties of the strongly-lensed quasar host galaxy RXS J1131-1231 by interpreting its molecular gas dynamics, spatial extent, and differential lensing effects, while incorporating dynamical and SED modeling to estimate physical parameters such as mass and star formation rate.",
            "target_length": 4000,
            "origin_content": "¬ß.¬ß Lens Modeling\n\nAt the angular resolution of the data, the source is resolved\n‚â≥2 resolution elements.\nGiven the extent of the lensed emission (see CO21mom),\nthis implies that we do not resolve\nstructures (e.g. knots and arcs) of the lensed emission\nin our data.\nNevertheless, the high spectral\nresolution of these data provides kinematic information on\nspatial scales smaller than the beam (see CO21mom).\nHence, we reconstruct the intrinsic line profile and source-plane velocity structure\nby carrying out a parametric lens modeling over different\nchannel slices of the interferometric data using our lensing code\n(; see  for details of the code).\nOur approach follows a similar strategy as <cit.>, who reconstruct a source-plane\nvelocity gradient and constrain the gas dynamics in the z > 4 quasar host galaxy of\nPSS J2322+1944,\nwhich is also lensed into an Einstein ring configuration.\nTo ensure adequate SNRs for lens modeling, we bin the frequency channels by a factor of five\nto produce seven independent Œî v ‚àº 105 channels (dashed line in delensed)\nthat cover the full linewidth of ‚àº750 .\nlcc[htbp]\n\n3\nLens parameters constrained by models of seven velocity channels\n\n2cParameters\nMedian values\n\nOffset in RA        ()        0.004¬±0.027\n\nOffset in Dec        ()       0.003¬±0.027\n\nAxial Ratio                          0.56¬±0.16\n\nPosition Angle       (deg)           103¬±22\n\nEinstein Radius    ()       1.833¬±0.002\n\naThis corresponds to mass of M(Œ∏ < Œ∏_ E)(7.420.02)11within the Einstein radius.\nParameters describing the foreground lens are\nobtained based on the median in the preliminary models (see text for details).\nAll angular offsets are with respect to\nŒ± = 11^ h31^ m5144,\nŒ¥ = -1231583 (J2000).\n\n\n\n\n\nWe model the lens mass distribution using a singular isothermal\nellipsoid (SIE) profile, which is described by five free parameters: the\npositional offset in R.A. and Dec. relative to an arbitrary chosen\nfixed coordinate in the image, the Einstein radius, the axial ratio, and the\nposition angle.\nPositional offset between the foreground galaxy and the pre-defined coordinate is initialized\nusing the VLA radio continuum map.\nWe impose a\nuniform prior of ¬±005 in both ŒîR.A. and ŒîDec.,\nmotivated by the astrometry uncertainties in the VLA image as well as\nthe uncertainties provided by previous SIE lens model .\nWe initialize the Einstein radius based on the model parameters reported by\nand impose a uniform prior using ¬±3œÉ of their uncertainties.\nThe sources are modeled using elliptical Gaussian profiles, which are\nparameterized by six free parameters: the positional offset in R.A.\nand Dec. relative to the lens, the intrinsic flux density, the effective\nradius, the axial ratio, and the position angle. The position of each source\nis allowed to vary between ¬±15 (i.e., within the Einstein radius)\nand the effective radius is allowed to vary from 001-2^''.\n\nOur code uses an Markov Chain Monte Carlo (MCMC) approach to sample the\nposterior probability distribution function (PDF) of the model parameters.\nIn each model, we require a target acceptance rate of ‚àº0.25-0.5\nand check for chain convergence by inspecting trace plots\nand by requiring that the samples are obtained beyond at least an autocorrelation time.\nWe thus employ ‚àº50,000 samples as the initial ‚Äúburn-in‚Äù phase\nto stabilize the Markov chains (which we then discard) and\nuse the final ‚àº5,000 steps, sampled by 128 walkers, to identify\nthe posterior. Here, we\nidentify the best-fit model and the quoted uncertainties using the\nmedian and the 68% confidence intervals in the marginal PDFs.\n\nWe first obtain a preliminary lens model for each channel slice independently,\nwhere their lens parameters are allowed to vary and are initialized according\nto the aforementioned way. We obtain the final model\nby repeating the modeling over each slice but fixing their lens parameters\nto the overall median in the preliminary models,\nas listed in lens.\nThis ensures that all models share the same lens profile.\nThe magnification factors in model are determined by taking the ratio\nbetween the image plane flux and the source plane flux of each model.\n\nOur model parameters in lens, describing\nthe mass distribution of the lensing galaxy, are consistent (within the uncertainties)\nwith that of the SIE model presented by . We find a mass of\nM(Œ∏  <  Œ∏_E) = (7.47 ¬± 0.02) √ó 10^11 within the Einstein radius.\n\n\n\n  ¬ß.¬ß.¬ß Interpretation of the Source-plane Morphology\n\nThe reconstructed source locations, as represented by magenta ellipses in model, demonstrate\nan intrinsic velocity gradient across the source plane, which is\nconsistent with a kinematically-ordered disk-like galaxy.\nAdditional support to the disk conjecture\ncan be found in the double-horned line profile (CO21spec)\nand the observed (image plane) velocity field (CO21mom). Furthermore,\n also find that the reconstructed source plane emission in optical-NIR\nis best-reproduced using a n = 1 Sersic profile.\nWe thus interpret RXJ1131 as a disk galaxy.\n\nA better fit is found for the lens model of\nthe red-most channel if we add a second source component (see\ntop left panel in model). This is consistent with previous results\nreported by <cit.>, who find an optically faint companion\n(component F in their paper) ‚àº2.4 kpc in projection from the AGN host galaxy in V-band,\nand with , who find evidence for an interacting galaxy near RXJ1131.\nSpatially, the red velocity component of the CO emission\nalso consistent with this component F. It is therefore likely that we\ndetect emission in a companion galaxy.\n\n\nWe decompose the total line flux into two components:\none from RXJ1131 and the other from its companion.\nSince the companion is only detected in the red-most channel, we\nderive its intrinsic gas mass using the best-fit flux\ndensities and magnification factors obtained from the models of this channel.\nAssuming a brightness temperature ratio\nof r_ 21 = 1 between and lines and\na CO luminosity-to-H_2 mass conversion factor of\n = 0.8 , we find\na molecular gas mass of M_ gas = (1.920.09) 9 .\nFor the molecular gas mass in RXJ1131, we derive\nits intrinsic line flux over the FWZI linewidth\nusing the respective magnification\nfactors listed in model, which to\nfirst order takes into account the effect of differential lensing.\nThis yields I_ = 2.930.70 Jy ,\nwhere the uncertainty includes those on\nthe magnification factors.\nAdopting the same brightness temperature ratio and  as\nused for the companion, this corresponds to a gas mass of\nM_ gas = (1.380.33) 10 , which\nimplies a gas mass ratio of ‚àº7:1 between RXJ1131 and its companion.\n\nThe spatial resolution of the data in hand\nis a few arcsec, which implies that despite the high SNR and spectral\nresolution, constraints on the intrinsic sizes of the lensed galaxies are modest, and thus the magnification\nfactors may be under-predicted <cit.>.\n\n\n\n\n\n  ¬ß.¬ß.¬ß Spatial Extent and Differential Lensing\n\nIn the image-plane integrated line map shown in CO21mom, the redshifted component is\ncospatial with the Einstein ring that is seen in the\noptical image, with most of its apparent flux originating along the lensing arc,\nwhereas centroid of the blueshifted emission is offset to the SE of\nthe lensing arc. This suggests that the CO-emitting region in RXJ1131 is extended.\nTo further illustrate this, we show the\nchannel maps of 21.5 width and a spatial spectra map of 15 resolution in\nchanmap and spatialSpec, respectively. These figures\nshow that redshifted emission\nis present to the west, peaking toward the lensing arc (black crosses in\nchanmap), and shifts to the east with decreasing velocity\n(blue wing).\nThis is consistent with the source plane positions in our models and\nis suggestive of an extended CO emitting region.\n\n\n\n\n\nlcc[!htbp]\n\n3\nMagnification factors of various kinematic components in\n\nVelocity Range ()\nSource 1 Œº_ L\nSource 2 Œº_ L\n\n346 - 260           6.7 ¬± 2.5      7.2 ¬± 5.6\n\n238 - 153           7.6 ¬± 1.6\n [0.5ex]\n131 - 45            8.7 ¬± 2.0\n [0.5ex]\n24 - -62        4.1 ¬± 0.9\n [0.5ex]\n-84 - -170      4.2 ¬± 0.6\n [0.5ex]\n-191 - -277     4.3 ¬± 2.4\n [0.5ex]\n-300 - -385     3.1 ¬± 0.9\n [0.7ex]weighted average     4.4     0pt1\n [0.5ex]\nmedian     5.5\n\nFirst column corresponds to the rest-frame velocity ranges taken from the center of an unbinned channel\n(see delensed). Each row corresponds to a (binned) channel slice used for\nlens modeling. Source 1 is RXJ1131 and source 2 is its companion.\n\n\n\nPrevious studies of RXJ1131 find evidence for differential lensing across\nthe HST V-, I-, and H-bands, where the\nmagnification factor varies from 10.9 to 7.8 .\nThis indicates that the emission from different stellar populations\nwithin the host galaxy have various spatial extents and positions with respect to the caustic.\nThe best-fit lens models obtained here for different CO channels show that differential lensing also plays\nan important role in the observed emission, with a magnification factor (Œº_ L) that varies\nfrom 8.7 to 3.1 across different kinematic components (model).\nThe asymmetry in the line profile (CO21spec and delensed) is therefore predominantly a result of\nthe redshifted CO-emitting gas being more strongly-magnified\nthan the\nblueshifted component.\nA secondary reason is likely due to\nthe inclusion of the emission of the companion in the most redshifted velocity channels.\nThe variation in Œº_ L found across channels is consistent with the source plane\npositions relative to the caustics in model, where the red wing\nemission mainly originates near the cusp\nof the caustic and the blue wing emission is located beyond the caustics.\nIn fact, the intrinsic line flux of the redshifted and\nblueshifted emission in RXJ1131 (after subtracting a contribution from the companion)\nare I_ = 1.260.23 Jy and 1.250.23 Jy , respectively,\nimplying an intrinsically symmetric line profile (delensed). This is consistent with the symmetric source-plane\nvelocity gradient in our lens model (model and PV).\n\n\n\n ¬ß.¬ß Kinematics\n\nFitting two Gaussians with a common FWHM\nto the ‚Äúintrinsic‚Äù line profile of RXJ1131 (after correcting for lensing using\nthe magnification factors for various channels and separating the emission from RXJ1131 and its companion),\nwe find a roughly symmetric double-horned profile with a flux ratio of 1.20.4 between the peaks, which\nare separated by\nŒî v_ sep = 38745 , and each with a\nFWHM of 22072 .\nThe peak separation obtained from this ‚Äúintrinsic‚Äù line profile is\nslightly lower than that obtained from the observed spectrum (without lensing corrections).\nThis discrepancy is likely a result of differential lensing, which causes the line peak of the red wing\nto shift towards higher velocity channels, and thereby biasing the centroid of\none Gaussian to higher velocity than otherwise.\nTo facilitate a comparison (sizes) with previous works, which were observed at lower spectral resolution,\nwe also fit a single-Gaussian to the intrinsic line profiles.\nThis yields FWHMs of 600160 for RXJ1131\nand 7343 for the companion galaxy.\n\nA clear velocity gradient and a high\nvelocity dispersion (‚â≥400 ) near the central region\nare seen in CO21mom. While beam smearing is inevitably the\ndominant factor in the observed velocity dispersion\nat the spatial resolution of these data, the exceedingly\nhigh velocity dispersion may hint\nat potential perturbations from the AGN, or internal turbulence due to\ninteractions with the companion, and/or instability due to the large gas\ncontent.\nTherefore, in this scenario, RXJ1131 is\nconsistent with a disrupted disk galaxy hosting an optically\nbright quasar and in the process of merging.\n\n\n\n ¬ß.¬ß Dynamical Modeling\n\nAs discussed in caveat, we interpret RXJ1131 as a disk galaxy as it displays\na kinematically-ordered velocity gradient in the source-plane velocity map of the CO emission,\na symmetric double-horned line profile (delensed, model and, left panel of PV),\nand a disk-like morphology in the source-plane reconstruction of the optical-NIR emission\n.\nWe extract a one dimensional position-velocity (PV) profile\nby assuming that the source-plane centroids of different velocity components\nobtained from dynamical lens modeling\nare dominated by the tangential component of the\ntrue velocity vector of a rotating disk, i.e., each velocity component would\nbe seen as lying along the major axis of a rotating disk if observed with sufficiently high angular resolution\n(see right panel of PV).\nIn this process, the positions for each velocity component (plotted as data points in the right panel of PV)\nare extracted along the best-fitted major axis, which is along a PA of 121.\n\nWe then attempt to characterize the molecular gas kinematics using an\nempirically-motivated disk model <cit.>:\n\n    V = V_0 + 2/œÄ V_aarctan(R/R_t),\n\nwhere V is the observed velocity, V_0 is the velocity at dynamical center,\nV_a is the asymptotic velocity, and R_t is the ‚Äúturnover‚Äù\nradius at which the rising part of the curve begins to flatten.\nWe perform non-linear least squares fitting using an orthogonal distance\nregression to find the best-fit parameters,\ntaking into account the uncertainties in both velocity (channel width) and\ndistance offset. We also place an upper limit on R_t <15 kpc\nto keep this parameter physical <cit.>.\nThe parameter uncertainties are inferred based on a Monte Carlo simulation\nof 500 iterations, where the input parameters are perturbed\naccording to random Gaussian distributions with standard deviations\ncorresponding to their uncertainties.\nUsing this model, we find V_a = 988 ¬± 618 ,\nR_t = 10.9 ¬± 7.8 kpc, and V_0 = 0 ¬± 9 .\nHowever, since the emission is not resolved along the flat regime\nof the rotation curve, the asymptotic velocity\nand the ‚Äúturnover‚Äù radius are poorly constrained.\nIn particular, V_a and R_t are highly correlated with a\nPearson coefficient R = 0.998, and -0.400 between V_a and V_0.\n\n\n\nThe asymptotic velocity (V_a) ‚Äî an extrapolation of the model\nout to radius beyond the disk scale-length and half-light radius ‚Äî\nis not equivalent to the maximum observed velocity (V_ max),\nwhich is commonly used in literature to parameterize disk rotation.\nThe arctangent model is most commonly used in studies of the\nTully-Fisher relation, where an extrapolation to V_2.2 (velocity\nat 2.2 disk scale-length or ‚àº1.375 half-light radius,\nor ‚àº0.7R_ opt[Radius enclosing 83% of the light\ndistribution.]) is typically adopted\nas the rotation velocity (V_ max in their\nterminology), since this corresponds to the radius at which the velocity\nof a pure exponential disk peaks <cit.>.\nHere, we adopt the maximum observed velocity\nV_ rot = 303 ¬± 55 at 6 ¬± 3 kpc\nfrom the\ndynamical center as a proxy to the rotation velocity.\nThis radius corresponds to ‚àº0.6 R_e, where R_e is the half-light\nradius ‚àº10.3 kpc inferred from the HST I-band\nlens model (; converted to\nour cosmology).\nWe note that the source plane half-light radius varies substantially with\nwavelength. In particular, the half-light radius is found to be\n‚àº 4 kpc and ‚àº7 kpc in V-band\n and H-band , respectively.\nThe CO gas is thus of similar spatial\nextent as in the H and I-bands.\n\nIn the rest-frame,\nemission in the observed-frame H-band corresponds to NIR emission (‚àº1 ),\ntracing radiation from the accretion disk surrounding\nthe central AGN and also from old and evolved stellar populations;\nI-band corresponds to roughly the optical V-band, tracing stellar radiation from\nexisting, less massive (longer-lasting) stars;\nV-band corresponds to roughly U-band,  tracing radiation from massive young stars\nin the host galaxy. Hence,\nthe relative compactness observed in the V-band may be explained in part\ndue to the fact that the emission in this band is\nmore susceptible to dust extinction than in other bands and/or dominated by\na central starburst caused by higher\nconcentrations of star-forming gas towards the central regions ‚Äî owing to\ngravitational perturbations induced\nfrom interactions with the companion\n<cit.>.\nThis would be consistent with the picture that old stars form first and constitute the bulge component\nof a spiral galaxy, and that nuclear starbursts (in the inner few kpc) can be triggered\nat a later time as the progenitor disk galaxy interacts with other galaxies to form a larger bulge.\n\n\n\n ¬ß.¬ß Dynamical Mass\n\nAssuming the gas to be virialized,\nthe dynamical mass can be approximated by\nM_ dynœÉ^2 R / G,\nwhere œÉ is the velocity dispersion, or the rotational velocity in the case of a rotating disk model\n(œÉ = V_ rot sin  i).\nUsing a rotational velocity V_ rot sin  i = 303 (see dynamics),\nwe find a dynamical mass of\nM_ dyn sin^2 i (< 6 kpc) = 1.311 enclosed\nwithin the CO-emitting region in RXJ1131.\nIf we instead consider the\nline peak separation (Œî v_ sep/2 ‚àº200 ) as the rotation velocity, we find\nM_ dyn sin^2 i (< 6 kpc) = 5.810 .\nWe derive an inclination angle of 56.4 from the\nmorphological axial ratio of a/b‚àº18/325, which we estimate\nfrom the source-plane image reconstructed by  (Figure 3 in their paper).\nThis corresponds to an inclination-corrected dynamical mass of\n8.310< M_ dyn < 2510.\nOur estimate should be considered at best an upper limit since\nthe gas in RXJ1131 is unlikely to be virialized.\nIn the following sections, we use the\nlower limit (8.31.9)10 as the dynamical mass as it is\nderived in a manner similar to what is commonly used in literature\n(; ; ).\n\n\n\nUsing the velocity dispersion (œÉ = 30 ) obtained by fitting a single Gaussian to the\nde-lensed line profile of the companion and a\nhalf-light radius of R_ CO = 4.22.8 kpc from the best-fit lens model,\nwe find a dynamical mass of\nM_ dyn = (3.52.3)9 for the companion,\nassuming an inclination angle of i30.\nThe uncertainty here only includes that of the CO source size.\nOn the other hand,\nwe find M_ dyn sin^2 30 = 5.88 if we adopt the better-constrained V-band source size of ‚àº700 pc .\nSince the V-band based dynamical mass measurement is substantially lower than the gas mass,\nthe V-band emitting region may appear to be much smaller than its true extent due\nto dust obscuration.\n\nThe CO-based dynamical mass estimates correspond to a mass ratio of ‚àº24:1\nbetween RXJ1131 and the companion, with a gas mass ratio of ‚àº7:1 derived in  caveat.\nWe thus classify the system as a gas-rich,‚Äúwet‚Äù minor merger.\n\n\n\n\n ¬ß.¬ß SED Modeling\n\nWe fit dust SED models to the 24 -2.2 mm photometry\nusing a modified-blackbody (MBB)\nfunction with a power-law attached to the Wien side to account for the MIR excess due to\nemission of warm and small dust grains.\nThe IRAS 60  and 100  upper limits are included to constrain the dust peak.\nHere, we use a flux density of S_ 2mm0.270.08 mJy derived in deblend\ninstead of the deblended flux listed in photometry\nto exclude a potential contribution due to synchrotron emission (see deblend) in the dust SED modeling.\nAn uncertainty from absolute flux calibration of ‚àº15% is added in quadrature\nto the PdBI 2 mm continuum photometry in our fitting procedure.\n\n\nThe fit is performed using the code\nmbb_emcee <cit.>, which samples the posterior\ndistributions using an MCMC approach and uses instrumental\nresponse curves to perform color correction.\nThe model is described by five free parameters: the rest-frame characteristic dust\ntemperature (T_d), the emissivity index (Œ≤), the power-law index\n(Œ±), the flux normalization at 500  (f_ norm), and\nthe observed-frame wavelength at which the emission\nbecomes optically thick (Œª_0). We impose\na uniform prior with an upper limit of 100 K on T_d <cit.>,\na Gaussian prior centered around\n1.9 with a standard deviation of 0.3 on Œ≤, and a uniform prior with an upper limit of\n1000  on Œª_0.\nWe check for chain convergence by requiring that the autocorrelation\nlength of each parameter is less than the number of steps\ntaken for the burn-in phase (which are then discarded).\nHere we report the statistical means\nand the 68% confidence intervals in the marginal PDFs\nas the best-fit parameters, as listed in SED.\nThe best-fit models are shown in SED along with the broadband photometry that is listed in photometry.\n\nlccc[!htbp]\n\n4\nSED fitting results\n\n2cParameters\nWith 24\nWithout 24\n\nT_d                               (K)                    54810\n552120\n [1.05ex]\nŒ≤                                                    1.60.50.4        2.20.30.3\n [1.05ex]\nŒ±                                                   1.60.50.6        8.57.06.2\n [1.05ex]\nŒª_0    ()            559278324        365111120\n [1.05ex]\nŒª_ peak    ()            1591940          1553843\n [1.05ex]\nf_ norm, 500    (mJy)                  551313     5966\n [1.05ex]\n    (10^12 )     3.811.921.97     4.242.172.00\n [1.05ex]\nM_ d    (10^8 )        16512            1457\n\naObserved-frame wavelength where œÑ_ŒΩ = 1\nbObserved-frame wavelength of the SED peak\ncObserved-frame flux density at 500\ndRest-frame 42.5-122.5  luminosity\neDerived assuming an absorption mass coefficient of Œ∫2.64 m^2 kg^-1 at Œª = 125.0  <cit.>\nErrors reported here are ¬±1œÉ.\nand M_ d are not corrected for lensing.\n\n\n\nIn the first model, we attempt to constrain the power-law index by including\nthe 24  data. Based on the resulting posterior PDFs, we find an apparent\nIR luminosity (rest-frame 8 - 1000 ) of 8.222.752.9812 , a\nluminosity (rest-frame 42.5 - 122.5 ) of\n3.811.921.9712 , and a\ndust mass of 165128 , none of which are corrected for lensing magnification.\nFor the mass absorption coefficient, we adopt\nŒ∫ = 2.64 m^2kgat rest-frame 125.0\n<cit.>.\nThe dust mass uncertainty does not\ninclude that of the absorption coefficient.\n\nA fit including the MIR 24  photometry\nis likely an upper limit on the luminosity due solely to in the AGN host galaxy.\nIf we instead fit for a model excluding this constraint,\ntwo major consequences are immediately apparent.\nFirst, the power-law index is poorly-constrained (see SED).\nSecond, the steep power-law implies only a small contribution\nfrom the power-law regime\nto the total IR luminosity as compared to the graybody component.\nThus, the luminosity in\nthis model should, in principle, correspond to a\nlower limit on the cold dust emission.\nUsing the best-fit parameters\nfor this model, we find a total IR luminosity\n(rest-frame 8 - 1000 ) of 8.675.275.2712 ,\na luminosity of 4.242.172.0012 and a\ndust mass M_ dust of 14578 , all of which are not lensing-corrected.\nTaken at face value, this implies an FIR-to-IR luminosity ratio\nof ‚àº4938%.\n\nThe dust temperature from both models is similar to that of\nULIRGs at 0.6 < z < 1.0 (54 ¬± 5 K;\n).\nThe luminosity is comparable in both models, which is\nnot surprising given the lack of constraints in the MIR.\nFor the subsequent analysis, we adopt the physical quantities\nfrom the first model (with constraints at 24 ).\nThe choice of SED model does not affect\nthe derived star formation rate (SFR) given the similar luminosity, and\ntheir dust masses are consistent within the uncertainties.\nWe correct for lensing using the median magnification\nfactor (Œº_ L5.5)\nfrom the CO lens models. This yields a\nof (6.93.6)11 and\nan intrinsic total IR luminosity of ‚àº1.512 (5.5/Œº_ L) , implying that RXJ1131 can be classified as an ULIRG.\nAssuming a <cit.> initial\nmass function (IMF), we find a\nSFR_ FIR of 12063 using a\nstandard conversion <cit.>.\n\n\nWe derive the stellar mass of RXJ1131 by\nfitting SED models to the rest-frame UV-to-mm photometry\nusing the high-z version of the magphys code <cit.>.\nTwo sets of stellar templates  modeled using either the <cit.> or the unpublished\nCharlot & Bruzual 2007 stellar population synthesis code\nare provided in the magphys package.\nWe adopt the former set.\nTo minimize contaminations from the quasar, we only fit to the HST, Herschel, and PdBI data,\nwhere both the HST and the PdBI 2 mm photometry are de-blended from the AGN\n(see bottom section of photometry).\nThe input photometry are corrected for lensing using their respective magnification factors\nto account for differential lensing (light blue circles in SED).\nWe thus find a stellar mass of M_*2.951.320.8610 , which\nis the median value of the posterior probability distribution and\nthe uncertainties are derived from the 16^ th and 84^ th percentiles.\nWe note that the models are over-fitted with a best-fit œá^20.41\nwhich is unsurprising due to sparse sampling of the SED\ncompare to the number of free parameters.\nThe resulting dust mass and IR luminosity are consistent with those obtained\nfrom the MBB+power-law models within the uncertainties, albeit some differences\nin the assumptions behind the two methods.\nThe consistency may be attributed to the large uncertainties arising from the lack of photometric constraints on the models and the fact that the best-fit parameters from the MBB method are similar to those of the magphys method.\n"
        },
        {
            "section_number": 5,
            "title": "DISCUSSION",
            "summary": "Discuss the molecular gas kinematics, star formation properties, and systemic redshift of the strongly-lensed quasar host galaxy RXS J1131-1231, analyzing the implications of observed linewidths, gas mass fractions, star formation efficiency, and velocity offsets in the context of galaxy evolution and black hole growth.",
            "target_length": 1800,
            "origin_content": "lcc[!htbp]\n\n3\nPhysical properties of RXJ1131 and its companion\n\nParameter\nUnit\nValue\n\nr_ 32                                               0.780.37\n [0.5ex]\nFWHM_ CO(2-1), RXJ1131        22072\n [0.5ex]\nFWHM_ CO(2-1), RXJ1131        600160\n [0.5ex]\nFWHM_ CO(2-1), companion        7343\n [0.5ex]\nM_ gas, RXJ1131                 10^10    1.380.33\n\nM_ gas, companion               10^9    1.920.09\n [0.5ex]\nR_ CO, RXJ1131                  kpc                6.23.0\n [0.5ex]\nR_ CO, companion                kpc                4.22.8\n [0.5ex]\nM_ dyn, RXJ1131                 10^10    8.31.9\n [0.5ex]\nM_ dyn, companion               10^9    3.52.3\n\nf_ gas                           %                 184\n [0.5ex]\nf_ mol                           %                 3416\n [0.5ex]\nL_ IR                            10^12    ‚àº1.5\n [0.5ex]\nL_ FIR                           10^11    6.93.6\n [0.5ex]\nSFR_ FIR                         yr    12063\n [0.5ex]\nM_ dust                          10^8    ‚àº3\n [0.5ex]\nGDR                                                        5413\n [0.5ex]\nœÑ_ depl                       Myr                10225\n [0.5ex]\nM_*                                   10^10    3.01.0\n [0.5ex]\nM_ BH    10^7    ‚àº 8\n [0.5ex]\nM_ BH/M_ bulge              %                 >0.270.110.08\n\nAll the parameters have been corrected for lensing magnification. The physical parameters are derived for RXJ1131 and the companion as a single system unless otherwise stated.\naFrom fitting a double Gaussian with a common FWHM to the de-lensed spectrum.\nbFrom fitting a single Gaussian to the de-lensed spectrum.\ncExcluding systematic uncertainties.\ndExcluding uncertainties in the dynamical masses.\ne<cit.>.\n\n\n\n\n\n ¬ß.¬ß ISM Properties\n\nIn this section, we derive the gas properties of the merging system RXJ1131\nbased on and compare them with those reported by\n[The\nluminosity in  is derived based on 60  and 100  IRAS fluxes,\nand using a different definition of\n: rest-frame 40 - 500 . Following this convention,\nwe find a luminosity of\n= (8.80.4)11(Œº_ L/5.5) and\na SFR of (15070) for RXJ1131.] ‚Äî the largest sample of CO-detected ULIRGs at similar redshift\n(0.6 < z < 1.0).\nTheir results are based on spatially unresolved and 43 line observations with the\nIRAM 30-m single-dish telescope.\n\n\n\n  ¬ß.¬ß.¬ß Linewidths and Sizes\n\nThe FWHM linewidth of Œî v_ ‚àº 600160 found\nfor RXJ1131 by fitting a single Gaussian\nis considerably larger than the statistical average in the  sample\n(370 ) and\nlocal ULIRGs .\nLinewidths exceeding 500 are also commonly observed in\nhigh-z starburst galaxies\nand high-z quasar host galaxies <cit.>,\nwhich are believed to originate from mergers.\nThe wider CO linewidth observed in RXJ1131 also supports a merger picture.\n\nThe CO gas in RXJ1131 is ‚àº63 kpc in radius (in the source plane),\nwhich is more\nextended than the average of 3.52.3 kpc in a sample of disk-like U/LIRGs studied by\n<cit.>,\nbut consistent with their range of 1.1 - 9.3 kpc.\nOur CO size is also consistent with that of high-z\n(z > 1) galaxies <cit.> and\nlocal U/LIRGs in the <cit.> sample (R‚â≤10 kpc).\n\n\n\n\n  ¬ß.¬ß.¬ß Gas Mass Fractions and Gas-to-dust Ratio\n\n\nWe find a dynamical gas mass fraction of f_ gasM_ gas/M_ dyn184%\nand a baryonic gas mass fraction of f_molM_ gas/(M_ gas + M_*)3416% for the merger system (i.e., RXJ1131 and companion).\nRecent studies find that the baryonic gas fraction of starburst galaxies has decreased from f_ mol40% to ‚â≤10% between z2 and z0 <cit.>,\nand from f_mol50% to ‚àº5% between the same redshift range for\n‚Äúnormal star-forming‚Äù galaxies <cit.>[These authors use the ‚ÄúGalactic‚Äù value of\n4.6 to compute the molecular gas mass.].\nBoth the dynamical and baryonic gas mass fractions of RXJ1131+companion are thus consistent with the trend of decreasing molecular gas content since z2\nwhich has been suggested as the cause for the decline in sSFR and cosmic history towards z0 <cit.>.\n\n\nUsing the lensing-corrected dust mass, we find a galactic-scale\ngas-to-dust ratio (GDR) of\n5413.\nThis would be higher by a factor of two if we were to adopt a dust mass from the other SED fit that is unconstrained at 24 .\nThis GDR is lower than the statistical average of 206\nin the  sample but is well within the broad\nrange of values measured over their entire sample (‚àº1-770).\nOur ratio is also consistent with high-z SMGs\n<cit.> and\nlocal ULIRGs <cit.>, but lower than that of the Milky Way by\n‚àº 7œÉ <cit.>.\n\nThere are a number of systematic uncertainties associated with the derived gas-to-dust ratio, in particular\nthe mass opacity coefficient Œ∫,\nthe conversion factor, and the brightness temperature ratio r_ 21.\nIf we instead use the ‚ÄúGalactic‚Äù value, which may be more appropriate for some ULIRGs <cit.> and minor mergers <cit.>,\nthe gas mass (and thus gas-to-dust ratio) would be ‚àº6 times higher.\nWe note that this gas mass is physically possible based on the dynamical mass constraints derived in dyn.\nOn the other hand, we would also obtain a higher gas mass if\nwe were to assume sub-thermal excitation between and emission.\nWe also note that the gas-to-dust ratio derived for RXJ1131 may be biased low as the gas is likely to\nbe more extended than the optically thick dust. Consequently, the overall magnification factor\nfor the CO gas may be lower than the optically thick dust, which dominates the luminosity.\nThis would lead to an overestimation of the dust mass\nby adopting the CO magnification factor for the dust.\n\n\n\n  ¬ß.¬ß.¬ß Star Formation Efficiency and specific SFR\n\n\nTo first order, the star formation efficiency\n(SFE = /M_ gas) indicates the rate per unit solar mass of molecular gas available in a galaxy.\nUsing a wavelength range of 40 - 500  defined\nin  for the far-IR luminosity,\nwe find an SFE of 5810 M_‚äô^-1,\nwhich is on the low end among other U/LIRGs at z < 0.6\n<cit.> but consistent with those of\nlow-z spiral galaxies <cit.> and high-z disk-like\ngalaxies, which are also IR luminous galaxies with ‚àº10^12 <cit.>.\nThis suggests that the merger system is converting gas into stars at an efficiency\nsimilar to those of ‚Äúnormal‚Äù star-forming\ndisk-like galaxies rather than starburst galaxies\n<cit.>.\nThis is in agreement with its disk-like kinematic signatures and its extended molecular gas distribution.\nAssuming the continues at the current rate without gas replenishment,\nthe SFE corresponds to a\ngas depletion time of œÑ = 10225 Myr.\n\nThe specific star formation rate (sSFRSFR/M_*) of 42.62.4 Gyrderived for RXJ1131\nis ‚â≤1.5œÉ above the main sequence according to\nthe redshift-dependent ‚Äúmain sequence‚Äù relation in <cit.>.\nGiven that RXJ1131 shares similar rate, efficiency, and CO disk size as other ‚Äúmain sequence‚Äù disk galaxies,\nthe small elevation in sSFR over the main sequence at z0.7 suggests\nthat the activity in RXJ1131 may be enhanced by interactions with the companion.\n\n\nThe host galaxy of RXJ1131 is an extended disk with low star formation efficiency in a minor merger\nsystem. Therefore, removal of angular momentum of the gas via gravitational torque is likely inefficient to convert the\nentire gas disk into a massive stellar bulge.\nIn this case, the disk component may be retained upon merging with the companion.\nThis scenario is consistent with the results from recent simulations, which suggest that bulge formation maybe\nsuppressed in gas-rich mergers, thereby allowing the formation of large disk galaxies with low bulge-to-disk ratios\n<cit.>. This also supports the idea that not all mergers will transform into\nelliptical galaxies, as in the classical picture <cit.>.\n\n\n\n\n ¬ß.¬ß Systemic Redshift and Velocity Offset\n\n\n<cit.> report two sets of AGN lines observed in RXJ1131.\nThe first set of lines is at z0.654, including the narrow component of the Balmer lines, the lines, and the absorption line; the second set is at\nz_ s, QSO0.658, including the broad component of the Balmer lines and the emission line.\nUsing the CO line center redshift as the systemic redshift,\nwe find that the redshift of the first set is fully consistent with the systemic redshift. This\nsupports previous claims that [OIII] lines, tracing the narrow line region (NLR),\nare good proxies\nto the true systemic redshift <cit.>.\nOn the other hand, the second set of lines is redshifted by ‚àº715 .\n\nVelocity offsets between broad line region (BLR) and NLR lines have been reported in literature.\n<cit.> find a median offset of\n‚àº100270 between [MgII] and [OIII] lines in a\nsample of >3800 quasars,\nand <cit.> report\na mean offset of\n‚àº100210 between the broad component of\nHŒ≤ and [OIII] lines in a sample of ‚àº2600 quasars at 0.1<z<0.8,\nwhere only ‚â≤20 of them (i.e., <1%) are found to have offsets >800 and ‚àº1%\nare found to have offsets >500 [<cit.> report the fraction of objects with offset velocities greater\nthan 500, 800, 1000, 1500, 2000, and 2500 . We therefore quote the two fractions corresponding to\noffset velocities closest\nto that of RXJ1131 (‚àº715 ) in this discussion.]\nThus, large velocity offsets between BLR and NLR lines\ncomparable to that of RXJ1131 are uncommon but have been observed in some cases.\n\nThe observed velocity offset between the BLR and NLR lines may be explained by\na recoiling black hole (BH),\nwhere the BLR is moving at high velocity relative to the bulk of its host galaxy\n<cit.>.\nDepending on the initial conditions of the black hole pair (e.g., black hole mass ratio, spin-orbit orientation, spin magnitude),\nnumerical relativity simulations have shown that recoil velocities can reach up to\nv_ kick4000 for spinning BHs,\nwith typical recoil velocities of v_ kick100 - 500 <cit.>.\nSeveral sources have been proposed as recoiling BH candidates <cit.>.\nHowever, <cit.> have recently refuted\nsuch scenario for one of the candidates ‚Äî SDSS J0927+2943 ‚Äî by finding that the redshift of its\nBLR lines is indeed consistent with its CO systemic redshift.\nThis is in contrast with RXJ1131, where our CO observations confirm\nthe redshifted BLR lines compared to the CO systemic redshift.\nSince this scenario requires a coalesced BH, it would imply that RXJ1131\nis a product of a previous merger, which is not implausible and\nmight also explain the highly spinning BH in RX1131 <cit.>.\n\nAlternative scenarios\ne.g., outflow/inflow of gas in the BLR, viewing angle towards the accretion disk, and\nobscuration in the clumpy accretion disk\nare more commonly invoked to explain velocity offsets between BLR and systemic redshift.\nSince the BLR lines of RXJ1131 show positive velocity offsets with respect to its systemic redshift, it may imply that\nthe observed\nBLR line emission is dominated by the gas that is flowing into the central BH, or by the receding component of\nthe accretion disk, owing to the viewing angle or the obscuration in the accretion disk.\n<cit.> report a covering factor of 20% for the accretion disk in RXJ1131\nbased on its broad absorption line at z0.654.\nAdditionally, the centroids of the BLR lines in RXJ1131 may be biased towards longer wavelengths due to\nmicrolensing <cit.>, which may have\nmagnified the redshifted component of the compact BLR more strongly than its blueshifted component.\n\n\n\n ¬ß.¬ß The M_ BH-Relation\n\nWe find a M_ BH/M_ bulge ratio of >0.270.110.08%\nusing the black hole mass of M_ BH87 <cit.>\nand the stellar mass derived in SED as an upper limit to the bulge mass.\nThis ratio is consistent with those of other intermediate-z radio-loud AGNs <cit.>\nbut is higher than those of nearby AGNs <cit.>.\nOur results therefore support\nthe emerging picture that quasars\ngrow faster and/or earlier than their host galaxies at higher redshifts <cit.>.\nThe elevated M_ BH/M_ bulge ratio of RXJ1131 compared to local AGNs\nsuggests that the bulk of the black hole mass of RXJ1131 is largely in place while its stellar bulge is still assembling.\n"
        },
        {
            "section_number": 6,
            "title": "SUMMARY AND CONCLUSIONS",
            "summary": "Summarize the key findings and implications of the study on the molecular gas kinematics and star formation properties of the strongly-lensed quasar host galaxy RXS J1131-1231, highlighting the methodologies, results, and their significance in understanding galaxy evolution and AGN feedback.",
            "target_length": 1500,
            "origin_content": "We present PdBI and CARMA observations towards the\nquadruply-imaged quasar RXJ1131 at z_ CO0.654, making this the first\nresolved CO study at intermediate redshift.\nUsing the CO line intensities, we find a brightness temperature ratio of r_320.78 ¬± 0.37\nbetween the and lines,\nconsistent with thermalized excitation but also with the lower excitation seen in normal star-forming disks.\nWe also detect marginally resolved\n2 mm continuum emission underlying the line\nand resolved radio continuum emission at 5 GHz in archival VLA data\nin both the foreground lensing galaxy and RXJ1131.\n\nBased on our lens modeling analysis of different velocity channels,\nwe find a secondary CO-emitting source near RXJ1131 whose spatial position\nis consistent with those of an optically faint companion reported in previous optical studies\n.\nThe magnification factor inferred for the CO emission in RXJ1131 is found to\nvary from Œº_ L3 to ‚àº9 across channels. This is indicative of an extended molecular gas\ndistribution in the host galaxy of RXJ1131, where the different kinematic components\nof the gas are magnified inhomogeneously, similar to what was found for the z>4 quasar\nPSS J2322+1944 <cit.>.\nUpon correcting for lensing magnification and subtracting a contribution from the companion,\nwe find an intrinsically symmetric double-horned line profile for RXJ1131.\nThis together with a symmetric source-plane velocity gradient argues for a rotating disk in RXJ1131, in good agreement with previous findings . Physical quantities derived for RXJ1131 and the companion throughout this paper are summarized in prop.\n\nBased on the lensing-corrected line intensities,\nwe find an intrinsic gas mass of M_ gas = (1.380.33) 10 for RXJ1131\nand (1.920.09) 9 for the companion,\ncorresponding to a gas mass ratio of ‚àº7:1.\nUsing the source-plane size of R6 kpc, we find a dynamical mass of M_ dyn810 for RXJ1131.\nThe dynamical gas mass fraction of f_ gasM_ gas/M_ dyn18% and baryonic gas mass fraction of\nf_molM_ gas/(M_ gas + M_*)34% are consistent with the trend of decreasing molecular gas\ncontent since z2 <cit.>\nwhich has been suggested as the cause for the decline in sSFR and cosmic history towards z0 <cit.>.\nThe CO-based dynamical mass ratio of ‚àº24:1\nbetween RXJ1131 and the companion, and a gas mass ratio of ‚àº7:1\nsuggest that the system is a gas-rich, ‚Äúwet‚Äù minor merger.\n\nFitting dust SED models to the IR-to-mm photometry, we derive\na lensing-corrected dust mass of M_ dust38 ,\nan infrared luminosity of ‚àº 1.512 (5.5/Œº_ L) ,\nand a far-IR luminosity that corresponds to a SFR_ FIR120 .\nThese physical properties suggest that the merger system is dusty in nature with on-going activity occuring\nat a rate comparable to local ULIRGs/mergers and high-z massive disk galaxies <cit.>.\nWe also derive a stellar mass of M_*310 by fitting SED models to the\nrest-frame UV-to-mm photometry, which have been corrected for their respective magnification factors before performing the fit to account for differential lensing effect.\n\nThe source-plane distribution of the gas and stellar populations of different ages\nindicates that the CO gas is of similar spatial extent as the old and long-lasting stellar populations,\nwhereas regions of recent may be embedded within the molecular gas reservoir as a result of\ngas accumulation driven by interactions with the companion.\nBased on dynamical mass constraints, we cannot rule out the possibility that the\ncompact in the host galaxy\nmay be heavily dust-obscured.\nHence, the true extent of recent may be as extended as the molecular gas\nreservoir.\n\nWhile properties such as CO linewidth, SFR, and gas mass found in RXJ1131\nare consistent with those of local ULIRGs and high-z starburst galaxies,\nits SFE is comparable to those of nearby and high-z disk galaxies rather than\nsystems. This is in good agreement with its disk-like kinematic signatures and its extended molecular gas distribution.\nWe find a specific rate (sSFR4 Gyr) that is ‚â≤1.5œÉ higher than those of ‚Äúmain sequence‚Äù galaxies.\nThe slight elevation in sSFR over the main sequence suggests that\nthe on-going star formation activity in RXJ1131 could be enhanced by interactions with the companion.\nRecent simulations have illustrated that the disk component of a gas-rich\nprogenitor galaxy with low SFE can be\nretained upon merging since the efficiency at removing angular momentum of the gas via\ngravitational torques provided by stellar components is reduced in such a system <cit.>.\nAs such, the extended gas disk of RXJ1131 together with its low SFE may indicate\nthat the in RXJ1131 could form a\nlarger stellar bulge in the remnant disk galaxy upon coalescing.\nThis picture is in agreement with the one based on the  relation,\nwhere we find an elevated  ratio of >0.270.110.08% for\nRXJ1131 compared to the local value.\nThis suggests that the stellar bulge of RXJ1131 is still assembling in order to evolve onto the local relation.\n\nWe find that the redshift inferred from the NLR lines reported in previous studies are consistent with the  systemic redshift as measured\nfrom the CO line,\nbut that the BLR lines are redshifted by ‚àº715 .\nWe raise several plausible scenarios that may explain the observed velocity offset, outflow/inflow of gas in the BLR, kinematics of the accretion disk, geometric effects,\nmicrolensing, and a recoiling black hole from merger event.\nThe latter scenario might also explain the high black hole spin parameter of\na0.870.080.15 reported by <cit.>, but\nfurther evidence is needed to confirm or rule out this scenario.\n\n\nTheoretical studies have suggested that negative feedback from an AGN may remove a\nlarge fraction of the molecular gas from its host galaxy, thereby quenching its star formation .\nIn this study, we find that the star formation efficiency and specific SFR of RXJ1131 are comparable to those of\nz1-1.5 disk galaxies, which are not known to host quasars, and that its\nmolecular gas mass fraction is consistent with the observed cosmic decline for star-forming\ngalaxies since z2-3.\nHence, we find no evidence of negative AGN feedback on the cold molecular gas fraction\nand on the star formation activity in RXJ1131.\nFuture observations at higher resolution will allow us to better constrain the molecular gas kinematics and dynamics of\nRXJ1131 to investigate any potential interplay with the quasar on smaller scales.\nMore broadly, systematic studies of the correlations between the molecular gas fraction, stellar mass, and AGN luminosity\nat different redshifts\nwill enable us to better understand the relative importance of AGN feedback and of the\nevolution in the molecular gas mass fraction on the decline of star formation history and black hole accretion history.\n\n\nWe thank the referee for providing detailed and constructive comments that helped to improve the clarity of this manuscript.\nDR and RP acknowledge support from the National Science Foundation\nunder grant number AST-1614213 to Cornell University. RP acknowledges\nsupport through award SOSPA3-008 from the NRAO. DR acknowledges the\nhospitality at the Aspen Center for Physics and the Kavli Institute\nfor Theoretical Physics during part of the writing of this manuscript.\nThis work is based on observations carried out under project number S14BX\nwith the IRAM NOEMA Interferometer. IRAM is supported by INSU/CNRS (France), MPG (Germany) and IGN (Spain).\nSupport for CARMA construction was derived from the Gordon and Betty Moore\nFoundation, the Kenneth T. and Eileen L. Norris Foundation, the James S.\nMcDonnell Foundation, the Associates of the California Institute of\nTechnology, the University of Chicago, the states of Illinois, California, and\nMaryland, and the National Science Foundation. Ongoing CARMA development and\noperations are supported by the National Science Foundation under a\ncooperative agreement and by the CARMA consortium universities.\nThe National Radio Astronomy Observatory is a facility of the National Science\nFoundation operated under cooperative agreement by Associated\nUniversities, Inc.\nThis research made use of data obtained with Herschel, an ESA space\nobservatory with science instruments provided by European-led Principal\nInvestigator consortia and with important participation from NASA.\nThis research has made use of NASA's Astrophysics Data System Bibliographic\nServices.\nThis work is based in part on observations\nmade with the NASA/ESA Hubble Space Telescope, and obtained from the Hubble\nLegacy Archive, which is a collaboration between the Space Telescope Science\nInstitute (STScI/NASA), the Space Telescope European Coordinating Facility\n(ST-ECF/ESA) and the Canadian Astronomy Data Centre (CADC/NRC/CSA).\nThis work is based\nin part on observations made with the ,\nwhich is operated by the Jet Propulsion Laboratory, California Institute of\nTechnology under a contract with NASA.\nThis publication made use of data products from the Wide-field Infrared\nSurvey Explorer, which is a joint project of the University of California, Los\nAngeles, and the Jet Propulsion Laboratory/California Institute of Technology,\nfunded by the National Aeronautics and Space Administration.\nThis publication made use of data products from the Two Micron All Sky\nSurvey, which is a joint project of the University of Massachusetts and the\nInfrared Processing and Analysis Center/California Institute of Technology,\nfunded by the National Aeronautics and Space Administration and the National\nScience Foundation.\nThis research made use of the NASA/IPAC Extragalactic Database (NED) which\nis operated by the Jet Propulsion Laboratory, California Institute of\nTechnology, under contract with the National Aeronautics and Space\nAdministration.\nThis research made use of Astropy, a community-developed core Python package for Astronomy <cit.>.\nThis research made use of APLpy, an open-source plotting package for Python hosted at <http://aplpy.github.com>.\n\nFacilities: IRAM PdBI, CARMA, VLA, Herschel(SPIRE), WISE, IRAS, 2MASS, Spitzer(IRAC, MIPS), HST(ACS, NICMOS)\n\n\nyahapj\n"
        }
    ]
]